{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31c72a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ed7f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q decorator==5.0.9\n",
    "!pip install -q ipywidgets\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import re\n",
    "import imp\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib as dl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ede3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q cltk==1.0.22\n",
    "%pip install -q strsim\n",
    "%pip install -q leven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f812278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features.model_features' from '../src/features/model_features.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing local modules\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import text_cleanup.text_cleanup as thesisCleanUp\n",
    "import preprocessing.text_preprocessing as thesisTextPreprocessing\n",
    "import data.reader as thesisDataReader\n",
    "import utils.utils as thesisUtils\n",
    "import features.tf_idf.n_gram as thesisTfIdfNgramFeatures\n",
    "import features.count_vectorizer.n_gram as thesisCountVectorizerNgramFeatures\n",
    "import similarities.cosine as thesisCosineSimilarities\n",
    "import similarities.levenshtein as thesisLevenshteinSimilarities\n",
    "import vocabulary.vocabulary as thesisVocabulary\n",
    "import features.lexical as thesisLexicalFeatures\n",
    "import similarities.cosine as thesisCosineSimilarity\n",
    "import text_cleanup.text_cleanup as thesisTextCleanUp\n",
    "import p_aligment.p_aligment as thesisPAligment\n",
    "import features.model_features as thesisModelFeatures\n",
    "\n",
    "imp.reload(thesisTfIdfNgramFeatures)\n",
    "imp.reload(thesisLexicalFeatures)\n",
    "imp.reload(thesisCosineSimilarity)\n",
    "imp.reload(thesisCleanUp)\n",
    "imp.reload(thesisTextPreprocessing)\n",
    "imp.reload(thesisDataReader)\n",
    "imp.reload(thesisUtils)\n",
    "\n",
    "imp.reload(thesisVocabulary)\n",
    "imp.reload(thesisCosineSimilarities)\n",
    "imp.reload(thesisTextCleanUp)\n",
    "imp.reload(thesisCountVectorizerNgramFeatures)\n",
    "imp.reload(thesisPAligment)\n",
    "imp.reload(thesisLevenshteinSimilarities)\n",
    "imp.reload(thesisModelFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aee417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_poorly_similar_with_chops_corpus_without_word_processing = thesisVocabulary.create_pre_proceed_corpus_from_processed_corpus(\n",
    "    thesisDataReader.get_london_poorly_similar_with_chops_corpus(),\n",
    "    thesisVocabulary.create_london_pre_post_processing_map()\n",
    ")\n",
    "zwickau_poorly_similar_with_chops_corpus_without_word_processing = thesisVocabulary.create_pre_proceed_corpus_from_processed_corpus(\n",
    "    thesisDataReader.get_zwickau_poorly_similar_with_chops_corpus(),\n",
    "    thesisVocabulary.create_zwickau_pre_post_processing_map()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0ae6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_candidate_version_based_london_without_word_processing = thesisVocabulary.create_pre_proceed_corpus_from_processed_corpus(\n",
    "    thesisDataReader.get_burchard_candidate_version_based_on_strongly_similar_london_base(),\n",
    "    thesisVocabulary.create_london_pre_post_processing_map()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ba8d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_poorly_similar_with_chops_corpus_without_word_processing_long_p = list(filter(lambda x: len(x.split()) > 20, london_poorly_similar_with_chops_corpus_without_word_processing))\n",
    "len(london_poorly_similar_with_chops_corpus_without_word_processing_long_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e539db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p = list(filter(lambda x: len(x.split()) > 20, zwickau_poorly_similar_with_chops_corpus_without_word_processing))\n",
    "len(zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "556633ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_candidate_version_based_london_without_word_processing_long_p = list(filter(lambda x: len(x.split()) > 20, burchard_candidate_version_based_london_without_word_processing))\n",
    "len(burchard_candidate_version_based_london_without_word_processing_long_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b657d",
   "metadata": {},
   "source": [
    "# burchard candidate vs london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951a4900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df = thesisModelFeatures.create_features_df(\n",
    "    london_poorly_similar_with_chops_corpus_without_word_processing_long_p,\n",
    "    None,\n",
    "    burchard_candidate_version_based_london_without_word_processing_long_p,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f6382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: QuadraticDiscriminantAnalysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "burchard_london_tf_idf_2_5_cosine_results_long_p = thesisModelFeatures.run_models(burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc9af7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.766209</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.717269</td>\n",
       "      <td>0.746021</td>\n",
       "      <td>0.730259</td>\n",
       "      <td>0.746021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.739933</td>\n",
       "      <td>0.724673</td>\n",
       "      <td>0.724190</td>\n",
       "      <td>0.740465</td>\n",
       "      <td>0.733636</td>\n",
       "      <td>0.740465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.738877</td>\n",
       "      <td>0.725476</td>\n",
       "      <td>0.723587</td>\n",
       "      <td>0.737838</td>\n",
       "      <td>0.732074</td>\n",
       "      <td>0.737838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.726435</td>\n",
       "      <td>0.714702</td>\n",
       "      <td>0.713771</td>\n",
       "      <td>0.723799</td>\n",
       "      <td>0.720573</td>\n",
       "      <td>0.723799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.810929</td>\n",
       "      <td>0.643988</td>\n",
       "      <td>0.613237</td>\n",
       "      <td>0.693844</td>\n",
       "      <td>0.638779</td>\n",
       "      <td>0.693844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.663752</td>\n",
       "      <td>0.661012</td>\n",
       "      <td>0.659873</td>\n",
       "      <td>0.666967</td>\n",
       "      <td>0.666367</td>\n",
       "      <td>0.666967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.615215</td>\n",
       "      <td>0.580476</td>\n",
       "      <td>0.559317</td>\n",
       "      <td>0.614565</td>\n",
       "      <td>0.580480</td>\n",
       "      <td>0.614565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.564421</td>\n",
       "      <td>0.548601</td>\n",
       "      <td>0.525635</td>\n",
       "      <td>0.584835</td>\n",
       "      <td>0.548405</td>\n",
       "      <td>0.584835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.285548</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363482</td>\n",
       "      <td>0.571096</td>\n",
       "      <td>0.415228</td>\n",
       "      <td>0.571096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.560186</td>\n",
       "      <td>0.560446</td>\n",
       "      <td>0.549287</td>\n",
       "      <td>0.552027</td>\n",
       "      <td>0.550432</td>\n",
       "      <td>0.552027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               precision_macro  recall_macro  f1_macro  \\\n",
       "RandomForestClassifier                0.766209      0.719048  0.717269   \n",
       "GaussianProcessClassifier             0.739933      0.724673  0.724190   \n",
       "MLPClassifier                         0.738877      0.725476  0.723587   \n",
       "AdaBoostClassifier                    0.726435      0.714702  0.713771   \n",
       "SVM_RBF                               0.810929      0.643988  0.613237   \n",
       "DecisionTreeClassifier                0.663752      0.661012  0.659873   \n",
       "KNeighborsClassifier                  0.615215      0.580476  0.559317   \n",
       "GaussianNB                            0.564421      0.548601  0.525635   \n",
       "SVM_linear                            0.285548      0.500000  0.363482   \n",
       "QuadraticDiscriminantAnalysis         0.560186      0.560446  0.549287   \n",
       "\n",
       "                               f1_micro  f1_weighted  accuracy  \n",
       "RandomForestClassifier         0.746021     0.730259  0.746021  \n",
       "GaussianProcessClassifier      0.740465     0.733636  0.740465  \n",
       "MLPClassifier                  0.737838     0.732074  0.737838  \n",
       "AdaBoostClassifier             0.723799     0.720573  0.723799  \n",
       "SVM_RBF                        0.693844     0.638779  0.693844  \n",
       "DecisionTreeClassifier         0.666967     0.666367  0.666967  \n",
       "KNeighborsClassifier           0.614565     0.580480  0.614565  \n",
       "GaussianNB                     0.584835     0.548405  0.584835  \n",
       "SVM_linear                     0.571096     0.415228  0.571096  \n",
       "QuadraticDiscriminantAnalysis  0.552027     0.550432  0.552027  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_london_tf_idf_2_5_cosine_results_long_p[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99255bed",
   "metadata": {},
   "source": [
    "## burchard candidate vs london greed search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ff530f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.7541291291291292\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7021771771771773\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7484234234234235\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.74324324 0.75165165 0.75705706 0.75157658 0.74602102 0.7515015\n",
      " 0.7542042  0.75427928 0.74324324 0.75165165 0.75705706 0.75157658\n",
      " 0.74602102 0.7515015  0.7542042  0.75427928 0.58483483 0.5710961\n",
      " 0.5710961  0.5710961  0.5710961  0.5710961  0.5710961  0.5710961\n",
      " 0.74864865 0.74346847 0.75165165 0.74894895 0.74887387 0.75427928\n",
      " 0.75968468 0.76516517 0.74864865 0.74346847 0.75165165 0.74894895\n",
      " 0.74887387 0.75427928 0.75968468 0.76516517 0.57672673 0.57672673\n",
      " 0.57387387 0.5710961  0.5710961  0.5710961  0.5710961  0.5710961\n",
      " 0.75112613 0.74872372 0.76524024 0.76516517 0.76246246 0.76246246\n",
      " 0.75705706 0.75975976 0.75112613 0.74872372 0.76524024 0.76516517\n",
      " 0.76246246 0.76246246 0.75705706 0.75975976 0.60397898 0.59294294\n",
      " 0.5710961  0.5737988  0.5710961  0.5710961  0.5737988  0.5710961\n",
      " 0.74602102 0.76524024 0.75975976 0.75435435 0.76516517 0.77875375\n",
      " 0.77334835 0.76524024 0.74602102 0.76524024 0.75975976 0.75435435\n",
      " 0.76516517 0.77875375 0.77334835 0.76524024 0.60382883 0.60660661\n",
      " 0.58460961 0.58738739 0.5792042  0.57657658 0.5737988  0.5737988\n",
      " 0.74339339 0.76501502 0.77327327 0.76786787 0.76516517 0.75975976\n",
      " 0.75975976 0.76524024 0.74339339 0.76501502 0.77327327 0.76786787\n",
      " 0.76516517 0.75975976 0.75975976 0.76524024 0.60668168 0.61216216\n",
      " 0.60105105 0.59827327 0.59827327 0.5981982  0.59279279 0.59001502\n",
      " 0.76779279 0.76516517 0.77882883 0.78153153 0.77064565 0.77342342\n",
      " 0.76253754 0.76794294 0.76779279 0.76516517 0.77882883 0.78153153\n",
      " 0.77064565 0.77342342 0.76253754 0.76794294 0.61741742 0.62567568\n",
      " 0.60105105 0.5954955  0.60097598 0.5981982  0.58738739 0.59009009\n",
      " 0.75405405 0.75705706 0.75705706 0.75172673 0.75713213 0.76516517\n",
      " 0.75705706 0.75705706 0.75405405 0.75705706 0.75705706 0.75172673\n",
      " 0.75713213 0.76516517 0.75705706 0.75705706 0.62852853 0.63393393\n",
      " 0.62845345 0.61456456 0.61734234 0.60367868 0.5954955  0.5954955\n",
      " 0.75975976 0.77605105 0.77057057 0.76493994 0.7704955  0.76231231\n",
      " 0.75968468 0.76516517 0.75975976 0.77605105 0.77057057 0.76493994\n",
      " 0.7704955  0.76231231 0.75968468 0.76516517 0.60923423 0.63678679\n",
      " 0.63415916 0.62304805 0.62297297 0.61749249 0.60375375 0.61186186\n",
      " 0.76801802 0.76501502 0.77034535 0.75953453 0.7731982  0.76779279\n",
      " 0.77327327 0.77334835 0.76801802 0.76501502 0.77034535 0.75953453\n",
      " 0.7731982  0.76779279 0.77327327 0.77334835 0.61201201 0.64256757\n",
      " 0.64211712 0.62837838 0.63918919 0.62297297 0.62004505 0.62282282\n",
      " 0.74331832 0.74887387 0.74872372 0.74339339 0.74339339 0.74331832\n",
      " 0.7515015  0.7542042  0.74331832 0.74887387 0.74872372 0.74339339\n",
      " 0.74339339 0.74331832 0.7515015  0.7542042  0.57117117 0.5710961\n",
      " 0.5710961  0.5710961  0.5710961  0.5710961  0.5710961  0.5710961\n",
      " 0.73228228 0.76794294 0.76779279 0.76516517 0.75427928 0.76238739\n",
      " 0.75975976 0.76524024 0.73228228 0.76794294 0.76779279 0.76516517\n",
      " 0.75427928 0.76238739 0.75975976 0.76524024 0.5737988  0.57927928\n",
      " 0.5710961  0.5710961  0.5710961  0.5710961  0.5710961  0.5710961\n",
      " 0.74046547 0.76238739 0.76238739 0.75427928 0.75705706 0.76524024\n",
      " 0.76261261 0.75983483 0.74046547 0.76238739 0.76238739 0.75427928\n",
      " 0.75705706 0.76524024 0.76261261 0.75983483 0.58190691 0.59024024\n",
      " 0.5792042  0.5765015  0.5710961  0.5710961  0.5737988  0.5737988\n",
      " 0.74339339 0.75157658 0.77597598 0.76231231 0.75960961 0.77327327\n",
      " 0.75983483 0.7707958  0.74339339 0.75157658 0.77597598 0.76231231\n",
      " 0.75960961 0.77327327 0.75983483 0.7707958  0.58483483 0.59572072\n",
      " 0.58190691 0.58190691 0.58190691 0.58190691 0.5737988  0.5737988\n",
      " 0.74594595 0.75705706 0.75690691 0.76238739 0.76253754 0.78145646\n",
      " 0.75172673 0.74902402 0.74594595 0.75705706 0.75690691 0.76238739\n",
      " 0.76253754 0.78145646 0.75172673 0.74902402 0.58761261 0.58768769\n",
      " 0.59024024 0.58198198 0.59009009 0.58468468 0.5737988  0.5765015\n",
      " 0.72387387 0.76223724 0.75960961 0.75705706 0.76794294 0.76794294\n",
      " 0.76516517 0.76524024 0.72387387 0.76223724 0.75960961 0.75705706\n",
      " 0.76794294 0.76794294 0.76516517 0.76524024 0.59864865 0.60960961\n",
      " 0.60375375 0.5954955  0.5954955  0.59279279 0.58738739 0.59009009\n",
      " 0.74324324 0.7704955  0.77327327 0.77597598 0.77327327 0.77064565\n",
      " 0.77072072 0.76253754 0.74324324 0.7704955  0.77327327 0.77597598\n",
      " 0.77327327 0.77064565 0.77072072 0.76253754 0.61741742 0.62567568\n",
      " 0.62282282 0.60915916 0.61186186 0.59557057 0.5954955  0.5954955\n",
      " 0.74316817 0.76779279 0.77057057 0.75960961 0.76238739 0.76786787\n",
      " 0.75705706 0.76253754 0.74316817 0.76779279 0.77057057 0.75960961\n",
      " 0.76238739 0.76786787 0.75705706 0.76253754 0.59279279 0.62575075\n",
      " 0.62282282 0.61734234 0.62274775 0.61463964 0.60645646 0.60915916\n",
      " 0.73475976 0.77582583 0.76771772 0.77042042 0.76779279 0.7759009\n",
      " 0.77605105 0.77057057 0.73475976 0.77582583 0.76771772 0.77042042\n",
      " 0.76779279 0.7759009  0.77605105 0.77057057 0.61726727 0.63663664\n",
      " 0.62807808 0.61734234 0.61463964 0.61186186 0.62004505 0.61456456\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.92682325 0.93623929 0.93715207 0.93776089 0.9426149  0.9453477\n",
      " 0.9453477  0.9447398  0.92682325 0.93623929 0.93715207 0.93776089\n",
      " 0.9426149  0.9453477  0.9453477  0.9447398  0.65360505 0.64146081\n",
      " 0.63023395 0.61354149 0.60686562 0.59653956 0.5925928  0.59138252\n",
      " 0.97175831 0.97783366 0.98086949 0.98572626 0.98724325 0.98663719\n",
      " 0.98815787 0.9884609  0.97175831 0.97783366 0.98086949 0.98572626\n",
      " 0.98724325 0.98663719 0.98815787 0.9884609  0.72495349 0.72706733\n",
      " 0.71706272 0.69610298 0.69337939 0.68063461 0.67030948 0.66424611\n",
      " 0.98573363 0.99362255 0.9960514  0.99787234 0.9993921  0.9993921\n",
      " 0.99969605 1.         0.98573363 0.99362255 0.9960514  0.99787234\n",
      " 0.9993921  0.9993921  0.99969605 1.         0.79142765 0.81298793\n",
      " 0.79962605 0.79324123 0.79841485 0.79385926 0.78627061 0.77808234\n",
      " 0.99514046 0.99908907 1.         1.         1.         1.\n",
      " 1.         1.         0.99514046 0.99908907 1.         1.\n",
      " 1.         1.         1.         1.         0.85549599 0.88645206\n",
      " 0.88373123 0.88221148 0.88372386 0.88554205 0.88554757 0.88099751\n",
      " 0.99848301 0.99939302 1.         1.         1.         1.\n",
      " 1.         1.         0.99848301 0.99939302 1.         1.\n",
      " 1.         1.         1.         1.         0.89982223 0.93716128\n",
      " 0.93473611 0.9371622  0.94141199 0.94535599 0.94991158 0.94687759\n",
      " 0.99939302 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99939302 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.92896657 0.96417611\n",
      " 0.96418163 0.96630008 0.97146449 0.9738915  0.97692825 0.97480427\n",
      " 0.99939302 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99939302 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95870959 0.98178318\n",
      " 0.98421019 0.98238648 0.98572718 0.98633508 0.98785392 0.98633508\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97085106 0.98694575\n",
      " 0.99241227 0.99149765 0.99301557 0.9918016  0.99362255 0.99271161\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98087041 0.99301925\n",
      " 0.99392926 0.99453532 0.99544533 0.99483743 0.99514046 0.99362347\n",
      " 0.91619969 0.92196832 0.9186359  0.91985447 0.92409966 0.92713825\n",
      " 0.9280455  0.92744128 0.91619969 0.92196832 0.9186359  0.91985447\n",
      " 0.92409966 0.92713825 0.9280455  0.92744128 0.6390338  0.62536889\n",
      " 0.61839827 0.59927328 0.59411348 0.58500138 0.57893064 0.58014829\n",
      " 0.95809984 0.96750852 0.96994197 0.97327991 0.9757106  0.97753155\n",
      " 0.9775297  0.9763139  0.95809984 0.96750852 0.96994197 0.97327991\n",
      " 0.9757106  0.97753155 0.9775297  0.9763139  0.70461177 0.70400018\n",
      " 0.68882564 0.66392926 0.66150502 0.65179147 0.64237727 0.64147094\n",
      " 0.98026895 0.9872497  0.98937368 0.99301833 0.99453532 0.99605232\n",
      " 0.99605324 0.9972672  0.98026895 0.9872497  0.98937368 0.99301833\n",
      " 0.99453532 0.99605232 0.99605324 0.9972672  0.7671493  0.78809063\n",
      " 0.76685364 0.75895275 0.76169107 0.75774523 0.74925394 0.74287741\n",
      " 0.99089067 0.99878604 0.99969605 0.99969605 0.9993921  1.\n",
      " 1.         1.         0.99089067 0.99878604 0.99969605 0.99969605\n",
      " 0.9993921  1.         1.         1.         0.83059409 0.86035\n",
      " 0.8527724  0.84669614 0.85551257 0.85581008 0.85338123 0.8470047\n",
      " 0.99787602 0.99969605 0.99969697 1.         1.         1.\n",
      " 1.         1.         0.99787602 0.99969605 0.99969697 1.\n",
      " 1.         1.         1.         1.         0.87827392 0.91530994\n",
      " 0.91379018 0.91408769 0.92168094 0.92320162 0.92806024 0.92806208\n",
      " 0.9978751  1.         1.         1.         1.         1.\n",
      " 1.         1.         0.9978751  1.         1.         1.\n",
      " 1.         1.         1.         1.         0.91317952 0.94990513\n",
      " 0.94869761 0.95051395 0.96023027 0.95993184 0.96357189 0.962357\n",
      " 0.99908907 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99908907 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94505112 0.96872709\n",
      " 0.97207055 0.97419361 0.97996408 0.98269411 0.9845169  0.98239016\n",
      " 0.99939302 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99939302 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96083817 0.98208713\n",
      " 0.9845169  0.98725154 0.98755549 0.9893746  0.99089159 0.99119554\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.9772322  0.98785852\n",
      " 0.99271346 0.99241043 0.99362531 0.99392834 0.99483927 0.99483743\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7815315315315315\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.6283033033033034\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6145645645645647\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.7595345345345346\n"
     ]
    }
   ],
   "source": [
    "resp = []\n",
    "for cls in ['SVC', 'DecisionTreeClassifier', 'GaussianProcessClassifier', 'RandomForestClassifier', 'GaussianNB', 'KNeighborsClassifier', 'AdaBoostClassifier']:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df, [cls])\n",
    "    resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09c5a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.7541291291291292],\n",
       " ['DecisionTreeClassifier', 0.7021771771771773],\n",
       " ['GaussianProcessClassifier', 0.7484234234234235],\n",
       " ['RandomForestClassifier', 0.7815315315315315],\n",
       " ['GaussianNB', 0.6283033033033034],\n",
       " ['KNeighborsClassifier', 0.6145645645645647],\n",
       " ['AdaBoostClassifier', 0.7595345345345346]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa7e80",
   "metadata": {},
   "source": [
    "## random london VS random london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b113ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = np.split(\n",
    "    np.random.choice(\n",
    "        range(\n",
    "            0, \n",
    "            len(london_poorly_similar_with_chops_corpus_without_word_processing_long_p)\n",
    "        ), \n",
    "        size=len(london_poorly_similar_with_chops_corpus_without_word_processing_long_p), \n",
    "        replace=False\n",
    "    ),\n",
    "    1\n",
    ")\n",
    "random_indexes = [random_indexes[0][:78], random_indexes[0][79:]]\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f957b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_random_chunk_1 = [ london_poorly_similar_with_chops_corpus_without_word_processing_long_p[i] for i in random_indexes[0] ]\n",
    "london_random_chunk_2 = [ london_poorly_similar_with_chops_corpus_without_word_processing_long_p[i] for i in random_indexes[1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96546afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df = thesisModelFeatures.create_features_df(\n",
    "    london_random_chunk_1,\n",
    "    None,\n",
    "    london_random_chunk_2,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfed210",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_london_tf_idf_2_5_cosine_results_long_p = thesisModelFeatures.run_models(london_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_london_tf_idf_2_5_cosine_results_long_p.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60c83e",
   "metadata": {},
   "source": [
    "# burchard candidate vs zwickau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9669103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p,\n",
    "    burchard_candidate_version_based_london_without_word_processing_long_p,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a889e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>corpus_version_label</th>\n",
       "      <th>a</th>\n",
       "      <th>a</th>\n",
       "      <th>a a</th>\n",
       "      <th>a ac</th>\n",
       "      <th>a ad</th>\n",
       "      <th>a al</th>\n",
       "      <th>a ap</th>\n",
       "      <th>a b</th>\n",
       "      <th>...</th>\n",
       "      <th>zra h</th>\n",
       "      <th>zrae</th>\n",
       "      <th>zrael</th>\n",
       "      <th>zrah</th>\n",
       "      <th>zrahe</th>\n",
       "      <th>zu</th>\n",
       "      <th>zur</th>\n",
       "      <th>zuri</th>\n",
       "      <th>zurio</th>\n",
       "      <th>inner_mean_cosine_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053370</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032915</td>\n",
       "      <td>0.023764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>204.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.045568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>205.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>206.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>207.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.032233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>208.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.045106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows  49713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  corpus_version_label         a        a    a a   a ac   a ad  \\\n",
       "0      0.0                   1.0  0.009905  0.000000   0.0    0.0    0.0   \n",
       "1      1.0                   1.0  0.038287  0.018428   0.0    0.0    0.0   \n",
       "2      2.0                   1.0  0.053370  0.014449   0.0    0.0    0.0   \n",
       "3      3.0                   1.0  0.033969  0.000000   0.0    0.0    0.0   \n",
       "4      4.0                   1.0  0.032915  0.023764   0.0    0.0    0.0   \n",
       "..     ...                   ...       ...       ...   ...    ...    ...   \n",
       "370  204.0                   2.0  0.045568  0.000000   0.0    0.0    0.0   \n",
       "371  205.0                   2.0  0.043055  0.000000   0.0    0.0    0.0   \n",
       "372  206.0                   2.0  0.044101  0.000000   0.0    0.0    0.0   \n",
       "373  207.0                   2.0  0.032233  0.000000   0.0    0.0    0.0   \n",
       "374  208.0                   2.0  0.045106  0.000000   0.0    0.0    0.0   \n",
       "\n",
       "      a al   a ap   a b  ...  zra h  zrae  zrael  zrah  zrahe   zu  zur  zuri  \\\n",
       "0      0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "1      0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "2      0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "3      0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "4      0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "..     ...    ...   ...  ...    ...   ...    ...   ...    ...  ...  ...   ...   \n",
       "370    0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "371    0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "372    0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "373    0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "374    0.0    0.0   0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "\n",
       "     zurio  inner_mean_cosine_similarity_score  \n",
       "0      0.0                            0.089736  \n",
       "1      0.0                            0.169794  \n",
       "2      0.0                            0.110581  \n",
       "3      0.0                            0.117864  \n",
       "4      0.0                            0.086517  \n",
       "..     ...                                 ...  \n",
       "370    0.0                            0.231712  \n",
       "371    0.0                            0.155838  \n",
       "372    0.0                            0.255245  \n",
       "373    0.0                            0.198659  \n",
       "374    0.0                            0.157189  \n",
       "\n",
       "[375 rows x 49713 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10b12918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: QuadraticDiscriminantAnalysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p = thesisModelFeatures.run_models(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c423fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.853053</td>\n",
       "      <td>0.843722</td>\n",
       "      <td>0.845014</td>\n",
       "      <td>0.848435</td>\n",
       "      <td>0.847453</td>\n",
       "      <td>0.848435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.755550</td>\n",
       "      <td>0.739653</td>\n",
       "      <td>0.738649</td>\n",
       "      <td>0.747084</td>\n",
       "      <td>0.743223</td>\n",
       "      <td>0.747084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.749698</td>\n",
       "      <td>0.735215</td>\n",
       "      <td>0.734695</td>\n",
       "      <td>0.744523</td>\n",
       "      <td>0.739920</td>\n",
       "      <td>0.744523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.751054</td>\n",
       "      <td>0.734891</td>\n",
       "      <td>0.733459</td>\n",
       "      <td>0.741821</td>\n",
       "      <td>0.737887</td>\n",
       "      <td>0.741821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.722642</td>\n",
       "      <td>0.720208</td>\n",
       "      <td>0.717356</td>\n",
       "      <td>0.722546</td>\n",
       "      <td>0.720964</td>\n",
       "      <td>0.722546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.719491</td>\n",
       "      <td>0.695952</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.712304</td>\n",
       "      <td>0.699485</td>\n",
       "      <td>0.712304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.692289</td>\n",
       "      <td>0.663612</td>\n",
       "      <td>0.659397</td>\n",
       "      <td>0.677596</td>\n",
       "      <td>0.667183</td>\n",
       "      <td>0.677596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.666464</td>\n",
       "      <td>0.566215</td>\n",
       "      <td>0.522792</td>\n",
       "      <td>0.605690</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.605690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.677052</td>\n",
       "      <td>0.554013</td>\n",
       "      <td>0.489544</td>\n",
       "      <td>0.599929</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.599929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.278698</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357881</td>\n",
       "      <td>0.557397</td>\n",
       "      <td>0.399031</td>\n",
       "      <td>0.557397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               precision_macro  recall_macro  f1_macro  \\\n",
       "AdaBoostClassifier                    0.853053      0.843722  0.845014   \n",
       "GaussianProcessClassifier             0.755550      0.739653  0.738649   \n",
       "RandomForestClassifier                0.749698      0.735215  0.734695   \n",
       "MLPClassifier                         0.751054      0.734891  0.733459   \n",
       "DecisionTreeClassifier                0.722642      0.720208  0.717356   \n",
       "SVM_RBF                               0.719491      0.695952  0.690971   \n",
       "QuadraticDiscriminantAnalysis         0.692289      0.663612  0.659397   \n",
       "GaussianNB                            0.666464      0.566215  0.522792   \n",
       "KNeighborsClassifier                  0.677052      0.554013  0.489544   \n",
       "SVM_linear                            0.278698      0.500000  0.357881   \n",
       "\n",
       "                               f1_micro  f1_weighted  accuracy  \n",
       "AdaBoostClassifier             0.848435     0.847453  0.848435  \n",
       "GaussianProcessClassifier      0.747084     0.743223  0.747084  \n",
       "RandomForestClassifier         0.744523     0.739920  0.744523  \n",
       "MLPClassifier                  0.741821     0.737887  0.741821  \n",
       "DecisionTreeClassifier         0.722546     0.720964  0.722546  \n",
       "SVM_RBF                        0.712304     0.699485  0.712304  \n",
       "QuadraticDiscriminantAnalysis  0.677596     0.667183  0.677596  \n",
       "GaussianNB                     0.605690     0.545000  0.605690  \n",
       "KNeighborsClassifier           0.599929     0.517000  0.599929  \n",
       "SVM_linear                     0.557397     0.399031  0.557397  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce14d3f",
   "metadata": {},
   "source": [
    "## burchard candidate vs zwickau greed search cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73561508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.768421052631579\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7571123755334283\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7524182076813657\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.71187767 0.72560455 0.7440256  0.74665718 0.73342817 0.73349929\n",
      " 0.73890469 0.73897582 0.71187767 0.72560455 0.7440256  0.74665718\n",
      " 0.73342817 0.73349929 0.73890469 0.73897582 0.56002845 0.56536273\n",
      " 0.56536273 0.56002845 0.56002845 0.55739687 0.56002845 0.55739687\n",
      " 0.72510669 0.72283073 0.73086771 0.73349929 0.74153627 0.74416785\n",
      " 0.73086771 0.73605974 0.72510669 0.72283073 0.73086771 0.73349929\n",
      " 0.74153627 0.74416785 0.73086771 0.73605974 0.57901849 0.57361309\n",
      " 0.57076814 0.57339972 0.56536273 0.56266003 0.56536273 0.56273115\n",
      " 0.71991465 0.73364154 0.72290185 0.73093883 0.73357041 0.73627312\n",
      " 0.73620199 0.73883357 0.71991465 0.73364154 0.72290185 0.73093883\n",
      " 0.73357041 0.73627312 0.73620199 0.73883357 0.57091038 0.58691323\n",
      " 0.6002845  0.6029872  0.58961593 0.58954481 0.59480797 0.59224751\n",
      " 0.71201991 0.7254623  0.73890469 0.74694168 0.73883357 0.74153627\n",
      " 0.74950213 0.74687055 0.71201991 0.7254623  0.73890469 0.74694168\n",
      " 0.73883357 0.74153627 0.74950213 0.74687055 0.59765292 0.63492176\n",
      " 0.61358464 0.6215505  0.59210526 0.61621622 0.61095306 0.60832148\n",
      " 0.73051209 0.7173542  0.74139403 0.73876245 0.74672831 0.7497155\n",
      " 0.74687055 0.74679943 0.73051209 0.7173542  0.74139403 0.73876245\n",
      " 0.74672831 0.7497155  0.74687055 0.74679943 0.62688478 0.65064011\n",
      " 0.66159317 0.65106686 0.65099573 0.65092461 0.65647226 0.64587482\n",
      " 0.72290185 0.71756757 0.7470128  0.72560455 0.72837838 0.73093883\n",
      " 0.75220484 0.74957326 0.72290185 0.71756757 0.7470128  0.72560455\n",
      " 0.72837838 0.73093883 0.75220484 0.74957326 0.64039829 0.65611664\n",
      " 0.65348506 0.64544808 0.65604552 0.66422475 0.66955903 0.66159317\n",
      " 0.71465149 0.74153627 0.75490754 0.75227596 0.75761024 0.74708393\n",
      " 0.7443101  0.74950213 0.71465149 0.74153627 0.75490754 0.75227596\n",
      " 0.75761024 0.74708393 0.7443101  0.74950213 0.66152205 0.65874822\n",
      " 0.66130868 0.65355619 0.65881935 0.66152205 0.67482219 0.66415363\n",
      " 0.73321479 0.73897582 0.75227596 0.74687055 0.7443101  0.74964438\n",
      " 0.75768137 0.74943101 0.73321479 0.73897582 0.75227596 0.74687055\n",
      " 0.7443101  0.74964438 0.75768137 0.74943101 0.62446657 0.6559744\n",
      " 0.67467994 0.65611664 0.67219061 0.67738265 0.685633   0.6802276\n",
      " 0.70945946 0.73349929 0.75746799 0.76827881 0.75746799 0.75497866\n",
      " 0.76031294 0.76024182 0.70945946 0.73349929 0.75746799 0.76827881\n",
      " 0.75746799 0.75497866 0.76031294 0.76024182 0.65113798 0.6616643\n",
      " 0.66692745 0.66941679 0.67489331 0.66948791 0.66692745 0.66429587\n",
      " 0.71458037 0.73876245 0.74395448 0.73847795 0.7254623  0.73349929\n",
      " 0.74153627 0.73890469 0.71458037 0.73876245 0.74395448 0.73847795\n",
      " 0.7254623  0.73349929 0.74153627 0.73890469 0.55199147 0.56266003\n",
      " 0.56806543 0.56273115 0.56273115 0.55739687 0.55739687 0.55739687\n",
      " 0.72809388 0.73335704 0.74957326 0.73890469 0.75227596 0.75476529\n",
      " 0.74943101 0.75739687 0.72809388 0.73335704 0.74957326 0.73890469\n",
      " 0.75227596 0.75476529 0.74943101 0.75739687 0.57866287 0.57880512\n",
      " 0.57887624 0.57617354 0.56806543 0.56536273 0.56273115 0.56273115\n",
      " 0.72283073 0.73876245 0.74409673 0.75497866 0.75753912 0.76009957\n",
      " 0.7628734  0.75476529 0.72283073 0.73876245 0.74409673 0.75497866\n",
      " 0.75753912 0.76009957 0.7628734  0.75476529 0.61621622 0.61621622\n",
      " 0.59231863 0.59480797 0.58684211 0.5841394  0.57866287 0.5841394\n",
      " 0.71721195 0.74416785 0.74950213 0.74687055 0.74935989 0.75206259\n",
      " 0.75469417 0.75739687 0.71721195 0.74416785 0.74950213 0.74687055\n",
      " 0.74935989 0.75206259 0.75469417 0.75739687 0.59217639 0.62681366\n",
      " 0.6083926  0.61081081 0.61635846 0.60547653 0.59480797 0.60284495\n",
      " 0.72532006 0.73335704 0.75184922 0.75483642 0.74672831 0.74679943\n",
      " 0.76280228 0.75483642 0.72532006 0.73335704 0.75184922 0.75483642\n",
      " 0.74672831 0.74679943 0.76280228 0.75483642 0.62446657 0.64829303\n",
      " 0.64302987 0.62709815 0.63499289 0.64032717 0.64288762 0.62972973\n",
      " 0.68805121 0.72809388 0.73349929 0.74423898 0.75490754 0.7628734\n",
      " 0.75234708 0.77083926 0.68805121 0.72809388 0.73349929 0.74423898\n",
      " 0.75490754 0.7628734  0.75234708 0.77083926 0.61386913 0.64573257\n",
      " 0.65633001 0.64274538 0.6428165  0.64295875 0.62702703 0.62987198\n",
      " 0.73058321 0.72837838 0.74950213 0.75220484 0.75206259 0.74935989\n",
      " 0.75746799 0.75746799 0.73058321 0.72837838 0.74950213 0.75220484\n",
      " 0.75206259 0.74935989 0.75746799 0.75746799 0.62681366 0.65640114\n",
      " 0.65355619 0.64295875 0.65640114 0.66692745 0.66699858 0.664367\n",
      " 0.69871977 0.71472262 0.73065434 0.73086771 0.73349929 0.73620199\n",
      " 0.73627312 0.74943101 0.69871977 0.71472262 0.73065434 0.73086771\n",
      " 0.73349929 0.73620199 0.73627312 0.74943101 0.63755334 0.664367\n",
      " 0.65647226 0.6616643  0.68300142 0.68826458 0.68819346 0.67766714\n",
      " 0.70931721 0.74423898 0.73357041 0.74153627 0.74423898 0.74950213\n",
      " 0.74146515 0.74687055 0.70931721 0.74423898 0.73357041 0.74153627\n",
      " 0.74423898 0.74950213 0.74146515 0.74687055 0.65128023 0.66714083\n",
      " 0.63229018 0.64829303 0.66152205 0.68278805 0.69054054 0.67211949\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.94874019 0.96118729 0.9674126  0.96977947 0.97214809 0.97274244\n",
      " 0.97185311 0.97511193 0.94874019 0.96118729 0.9674126  0.96977947\n",
      " 0.97214809 0.97274244 0.97185311 0.97511193 0.69569382 0.69894738\n",
      " 0.69568943 0.67525065 0.66812986 0.65480133 0.65036258 0.64680965\n",
      " 0.97511369 0.98874247 0.99140783 0.99140783 0.99466753 0.99466753\n",
      " 0.99466665 0.99525925 0.97511369 0.98874247 0.99140783 0.99140783\n",
      " 0.99466753 0.99466753 0.99466665 0.99525925 0.78458115 0.8112347\n",
      " 0.82042649 0.81242867 0.80975805 0.79731006 0.80295595 0.80117729\n",
      " 0.99111109 0.99703615 0.99822222 0.99851895 0.9982231  0.99881657\n",
      " 0.99881657 0.99852071 0.99111109 0.99703615 0.99822222 0.99851895\n",
      " 0.9982231  0.99881657 0.99881657 0.99852071 0.86666637 0.9102172\n",
      " 0.91378329 0.91822116 0.92029656 0.91940811 0.92148263 0.92651485\n",
      " 0.9946649  0.99940741 0.99970326 0.99970414 0.99970414 0.99970414\n",
      " 1.         0.99940828 0.9946649  0.99940741 0.99970326 0.99970414\n",
      " 0.99970414 0.99970414 1.         0.99940828 0.91348217 0.95022036\n",
      " 0.95970625 0.96385528 0.97127017 0.96948888 0.97215511 0.97659649\n",
      " 0.99762875 0.99940653 1.         1.         1.         1.\n",
      " 1.         1.         0.99762875 0.99940653 1.         1.\n",
      " 1.         1.         1.         1.         0.94163784 0.97422348\n",
      " 0.98044704 0.98755641 0.99022615 0.9920013  0.9934841  0.99496515\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96504311 0.99081875\n",
      " 0.99437606 0.99674556 0.99703966 0.9973364  0.99881657 0.99911243\n",
      " 0.99970326 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99970326 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97777992 0.99674381\n",
      " 0.99881657 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98725879 0.99792812\n",
      " 0.99940741 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98963005 0.99851895\n",
      " 0.99940741 1.         1.         1.         1.         1.\n",
      " 0.94459379 0.96207399 0.96562692 0.96533896 0.96859252 0.9700762\n",
      " 0.97007445 0.96889014 0.94459379 0.96207399 0.96562692 0.96533896\n",
      " 0.96859252 0.9700762  0.97007445 0.96889014 0.6755544  0.6737775\n",
      " 0.66756361 0.65274086 0.64503801 0.63407195 0.6243025  0.61807543\n",
      " 0.97332976 0.98636771 0.98755289 0.98755377 0.98933331 0.99081523\n",
      " 0.99110846 0.99318473 0.97332976 0.98636771 0.98755289 0.98755377\n",
      " 0.98933331 0.99081523 0.99110846 0.99318473 0.76976718 0.7827981\n",
      " 0.79525574 0.78487788 0.77954103 0.76502028 0.76888136 0.76058943\n",
      " 0.98667059 0.9931821  0.99644356 0.99644356 0.99762875 0.99762962\n",
      " 0.99851983 0.99881657 0.98667059 0.9931821  0.99644356 0.99644356\n",
      " 0.99762875 0.99762962 0.99851983 0.99881657 0.8539357  0.88473478\n",
      " 0.89037715 0.89215055 0.89629343 0.89006198 0.89333222 0.89184679\n",
      " 0.99348147 0.99733201 0.99822134 0.99911155 0.99911155 0.99970414\n",
      " 0.99970414 0.99940828 0.99348147 0.99733201 0.99822134 0.99911155\n",
      " 0.99911155 0.99970414 0.99970414 0.99940828 0.89809141 0.93747652\n",
      " 0.94459379 0.94696504 0.94933278 0.95377768 0.95792671 0.95644479\n",
      " 0.99525749 0.99911067 0.99970326 1.         0.99970414 1.\n",
      " 1.         1.         0.99525749 0.99911067 0.99970326 1.\n",
      " 0.99970414 1.         1.         1.         0.92415764 0.9617755\n",
      " 0.97126227 0.976298   0.98192808 0.98281829 0.98578038 0.98726318\n",
      " 0.99792636 1.         0.99970414 0.99970414 0.99970414 1.\n",
      " 1.         1.         0.99792636 1.         0.99970414 0.99970414\n",
      " 0.99970414 1.         1.         1.         0.95615859 0.98518866\n",
      " 0.98904096 0.99111373 0.99377908 0.99467017 0.99674205 0.99674293\n",
      " 0.99940741 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99940741 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97214984 0.99170544\n",
      " 0.99555686 0.99763138 0.99851895 0.99822397 0.99940828 0.99911243\n",
      " 0.99970414 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99970414 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98251804 0.99703703\n",
      " 0.99792724 0.99940828 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98755816 0.99822134\n",
      " 0.99970414 0.99970414 1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708392603129445\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.6331436699857753\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.5999288762446657\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.9123044096728309\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_greed_rearch_resp = []\n",
    "for cls in ['SVC', 'DecisionTreeClassifier', 'GaussianProcessClassifier', 'RandomForestClassifier', 'GaussianNB', 'KNeighborsClassifier', 'AdaBoostClassifier']:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df, [cls])\n",
    "    burchard_zwickau_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "319ee97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.768421052631579],\n",
       " ['DecisionTreeClassifier', 0.7571123755334283],\n",
       " ['GaussianProcessClassifier', 0.7524182076813657],\n",
       " ['RandomForestClassifier', 0.7708392603129445],\n",
       " ['GaussianNB', 0.6331436699857753],\n",
       " ['KNeighborsClassifier', 0.5999288762446657],\n",
       " ['AdaBoostClassifier', 0.9123044096728309]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_greed_rearch_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bcfc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## random zwickau VS random zwickau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c07005",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = np.split(\n",
    "    np.random.choice(\n",
    "        range(\n",
    "            0, \n",
    "            len(zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p)\n",
    "        ), \n",
    "        size=len(zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p), \n",
    "        replace=False\n",
    "    ),\n",
    "    2\n",
    ")\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8517c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwickau_random_chunk_1 = [ zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p[i] for i in random_indexes[0] ]\n",
    "zwickau_random_chunk_2 = [ zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p[i] for i in random_indexes[1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwickau_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_random_chunk_1,\n",
    "    zwickau_random_chunk_2,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb27c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwickau_zwickau_tf_idf_2_5_cosine_results_long_p = thesisModelFeatures.run_models(zwickau_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwickau_zwickau_tf_idf_2_5_cosine_results_long_p.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f73442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068dd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a712cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5 has been classified as  2.0 and should be  0.0\n",
      "Row 7 has been classified as  2.0 and should be  0.0\n",
      "Row 9 has been classified as  2.0 and should be  0.0\n",
      "Row 15 has been classified as  2.0 and should be  0.0\n",
      "Row 170 has been classified as  0.0 and should be  2.0\n",
      "Row 172 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.8378378378378378\n",
      "Row 20 has been classified as  2.0 and should be  0.0\n",
      "Row 23 has been classified as  2.0 and should be  0.0\n",
      "Row 179 has been classified as  0.0 and should be  2.0\n",
      "Row 182 has been classified as  0.0 and should be  2.0\n",
      "Row 188 has been classified as  0.0 and should be  2.0\n",
      "Row 190 has been classified as  0.0 and should be  2.0\n",
      "Row 192 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.8108108108108109\n",
      "Row 33 has been classified as  2.0 and should be  0.0\n",
      "Row 35 has been classified as  2.0 and should be  0.0\n",
      "Row 36 has been classified as  2.0 and should be  0.0\n",
      "Row 40 has been classified as  2.0 and should be  0.0\n",
      "Row 41 has been classified as  2.0 and should be  0.0\n",
      "Row 42 has been classified as  2.0 and should be  0.0\n",
      "Row 43 has been classified as  2.0 and should be  0.0\n",
      "Row 44 has been classified as  2.0 and should be  0.0\n",
      "Row 202 has been classified as  0.0 and should be  2.0\n",
      "Row 203 has been classified as  0.0 and should be  2.0\n",
      "Row 204 has been classified as  0.0 and should be  2.0\n",
      "Row 216 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.6756756756756757\n",
      "Row 54 has been classified as  2.0 and should be  0.0\n",
      "Row 55 has been classified as  2.0 and should be  0.0\n",
      "Row 57 has been classified as  2.0 and should be  0.0\n",
      "Row 226 has been classified as  0.0 and should be  2.0\n",
      "Row 227 has been classified as  0.0 and should be  2.0\n",
      "Row 236 has been classified as  0.0 and should be  2.0\n",
      "Row 240 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.8108108108108109\n",
      "Row 68 has been classified as  2.0 and should be  0.0\n",
      "Row 69 has been classified as  2.0 and should be  0.0\n",
      "Row 73 has been classified as  2.0 and should be  0.0\n",
      "Row 74 has been classified as  2.0 and should be  0.0\n",
      "Row 76 has been classified as  2.0 and should be  0.0\n",
      "Row 241 has been classified as  0.0 and should be  2.0\n",
      "Row 245 has been classified as  0.0 and should be  2.0\n",
      "Row 247 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.7837837837837838\n",
      "Row 81 has been classified as  2.0 and should be  0.0\n",
      "Row 82 has been classified as  2.0 and should be  0.0\n",
      "Row 84 has been classified as  2.0 and should be  0.0\n",
      "Row 85 has been classified as  2.0 and should be  0.0\n",
      "Row 86 has been classified as  2.0 and should be  0.0\n",
      "Row 88 has been classified as  2.0 and should be  0.0\n",
      "Row 89 has been classified as  2.0 and should be  0.0\n",
      "Row 91 has been classified as  2.0 and should be  0.0\n",
      "Row 92 has been classified as  2.0 and should be  0.0\n",
      "Row 93 has been classified as  2.0 and should be  0.0\n",
      "Row 263 has been classified as  0.0 and should be  2.0\n",
      "Row 270 has been classified as  0.0 and should be  2.0\n",
      "Row 272 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.6486486486486487\n",
      "Row 97 has been classified as  2.0 and should be  0.0\n",
      "Row 107 has been classified as  2.0 and should be  0.0\n",
      "Row 298 has been classified as  0.0 and should be  2.0\n",
      "Row 301 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.8888888888888888\n",
      "Row 113 has been classified as  2.0 and should be  0.0\n",
      "Row 114 has been classified as  2.0 and should be  0.0\n",
      "Row 116 has been classified as  2.0 and should be  0.0\n",
      "Row 119 has been classified as  2.0 and should be  0.0\n",
      "Row 121 has been classified as  2.0 and should be  0.0\n",
      "Row 122 has been classified as  2.0 and should be  0.0\n",
      "Row 123 has been classified as  2.0 and should be  0.0\n",
      "Row 124 has been classified as  2.0 and should be  0.0\n",
      "Row 307 has been classified as  0.0 and should be  2.0\n",
      "Row 309 has been classified as  0.0 and should be  2.0\n",
      "Row 311 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.6944444444444444\n",
      "Row 127 has been classified as  2.0 and should be  0.0\n",
      "Row 129 has been classified as  2.0 and should be  0.0\n",
      "Row 131 has been classified as  2.0 and should be  0.0\n",
      "Row 133 has been classified as  2.0 and should be  0.0\n",
      "Row 137 has been classified as  2.0 and should be  0.0\n",
      "Row 141 has been classified as  2.0 and should be  0.0\n",
      "Row 332 has been classified as  0.0 and should be  2.0\n",
      "Row 340 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.7777777777777778\n",
      "Row 142 has been classified as  2.0 and should be  0.0\n",
      "Row 145 has been classified as  2.0 and should be  0.0\n",
      "Row 147 has been classified as  2.0 and should be  0.0\n",
      "Row 149 has been classified as  2.0 and should be  0.0\n",
      "Row 152 has been classified as  2.0 and should be  0.0\n",
      "Row 153 has been classified as  2.0 and should be  0.0\n",
      "Row 154 has been classified as  2.0 and should be  0.0\n",
      "Row 155 has been classified as  2.0 and should be  0.0\n",
      "Row 156 has been classified as  2.0 and should be  0.0\n",
      "Row 349 has been classified as  0.0 and should be  2.0\n",
      "Row 362 has been classified as  0.0 and should be  2.0\n",
      "score is: 0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "wrong_redictions = thesisModelFeatures.get_model_wrong_prediction(burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac257ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2.0, 0.0, 5),\n",
       "  (2.0, 0.0, 7),\n",
       "  (2.0, 0.0, 9),\n",
       "  (2.0, 0.0, 15),\n",
       "  (0.0, 2.0, 170),\n",
       "  (0.0, 2.0, 172)],\n",
       " [(2.0, 0.0, 20),\n",
       "  (2.0, 0.0, 23),\n",
       "  (0.0, 2.0, 179),\n",
       "  (0.0, 2.0, 182),\n",
       "  (0.0, 2.0, 188),\n",
       "  (0.0, 2.0, 190),\n",
       "  (0.0, 2.0, 192)],\n",
       " [(2.0, 0.0, 33),\n",
       "  (2.0, 0.0, 35),\n",
       "  (2.0, 0.0, 36),\n",
       "  (2.0, 0.0, 40),\n",
       "  (2.0, 0.0, 41),\n",
       "  (2.0, 0.0, 42),\n",
       "  (2.0, 0.0, 43),\n",
       "  (2.0, 0.0, 44),\n",
       "  (0.0, 2.0, 202),\n",
       "  (0.0, 2.0, 203),\n",
       "  (0.0, 2.0, 204),\n",
       "  (0.0, 2.0, 216)],\n",
       " [(2.0, 0.0, 54),\n",
       "  (2.0, 0.0, 55),\n",
       "  (2.0, 0.0, 57),\n",
       "  (0.0, 2.0, 226),\n",
       "  (0.0, 2.0, 227),\n",
       "  (0.0, 2.0, 236),\n",
       "  (0.0, 2.0, 240)],\n",
       " [(2.0, 0.0, 68),\n",
       "  (2.0, 0.0, 69),\n",
       "  (2.0, 0.0, 73),\n",
       "  (2.0, 0.0, 74),\n",
       "  (2.0, 0.0, 76),\n",
       "  (0.0, 2.0, 241),\n",
       "  (0.0, 2.0, 245),\n",
       "  (0.0, 2.0, 247)],\n",
       " [(2.0, 0.0, 81),\n",
       "  (2.0, 0.0, 82),\n",
       "  (2.0, 0.0, 84),\n",
       "  (2.0, 0.0, 85),\n",
       "  (2.0, 0.0, 86),\n",
       "  (2.0, 0.0, 88),\n",
       "  (2.0, 0.0, 89),\n",
       "  (2.0, 0.0, 91),\n",
       "  (2.0, 0.0, 92),\n",
       "  (2.0, 0.0, 93),\n",
       "  (0.0, 2.0, 263),\n",
       "  (0.0, 2.0, 270),\n",
       "  (0.0, 2.0, 272)],\n",
       " [(2.0, 0.0, 97), (2.0, 0.0, 107), (0.0, 2.0, 298), (0.0, 2.0, 301)],\n",
       " [(2.0, 0.0, 113),\n",
       "  (2.0, 0.0, 114),\n",
       "  (2.0, 0.0, 116),\n",
       "  (2.0, 0.0, 119),\n",
       "  (2.0, 0.0, 121),\n",
       "  (2.0, 0.0, 122),\n",
       "  (2.0, 0.0, 123),\n",
       "  (2.0, 0.0, 124),\n",
       "  (0.0, 2.0, 307),\n",
       "  (0.0, 2.0, 309),\n",
       "  (0.0, 2.0, 311)],\n",
       " [(2.0, 0.0, 127),\n",
       "  (2.0, 0.0, 129),\n",
       "  (2.0, 0.0, 131),\n",
       "  (2.0, 0.0, 133),\n",
       "  (2.0, 0.0, 137),\n",
       "  (2.0, 0.0, 141),\n",
       "  (0.0, 2.0, 332),\n",
       "  (0.0, 2.0, 340)],\n",
       " [(2.0, 0.0, 142),\n",
       "  (2.0, 0.0, 145),\n",
       "  (2.0, 0.0, 147),\n",
       "  (2.0, 0.0, 149),\n",
       "  (2.0, 0.0, 152),\n",
       "  (2.0, 0.0, 153),\n",
       "  (2.0, 0.0, 154),\n",
       "  (2.0, 0.0, 155),\n",
       "  (2.0, 0.0, 156),\n",
       "  (0.0, 2.0, 349),\n",
       "  (0.0, 2.0, 362)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_redictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0339c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "12\n",
      "7\n",
      "8\n",
      "13\n",
      "4\n",
      "11\n",
      "8\n",
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in wrong_redictions:\n",
    "    s += len(i)\n",
    "    print(len(i))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set([ result[2] for iteration in wrong_redictions for result in iteration ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060141c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
