{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b7ece8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ffbaac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'similarities.cosine' from '../src/similarities/cosine.py'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import data.reader as dataReader\n",
    "import utils.utils as thesisUtils\n",
    "import similarities.cosine as thesisCosineSimilarity\n",
    "import vocabulary.vocabulary as thesisVocabulary\n",
    "import features.model_features as thesisModelFeatures\n",
    "\n",
    "import imp\n",
    "imp.reload(dataReader)\n",
    "imp.reload(thesisUtils)\n",
    "imp.reload(thesisVocabulary)\n",
    "imp.reload(thesisModelFeatures)\n",
    "imp.reload(thesisCosineSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1390ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_corpus = dataReader.CorpusByNewLine.london()\n",
    "zwickau_corpus = dataReader.CorpusByNewLine.zwickau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd785d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_zwickau_similarities = thesisCosineSimilarity.CrossVersionSimilarity5Gram(london_corpus, zwickau_corpus)\n",
    "london_zwickau_similarities.calculate()\n",
    "\n",
    "zwickau_london_similarities = thesisCosineSimilarity.CrossVersionSimilarity5Gram(zwickau_corpus, london_corpus)\n",
    "zwickau_london_similarities.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0907f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_zwickau_similarities.save()\n",
    "zwickau_london_similarities.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2d1770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n"
     ]
    }
   ],
   "source": [
    "burchard_corpus_lz = dataReader.BurchardCorpus(london_corpus, zwickau_corpus)\n",
    "burchard_corpus_zl = dataReader.BurchardCorpus(zwickau_corpus, london_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "943d8407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n"
     ]
    }
   ],
   "source": [
    "london_leftovers = dataReader.LeftoversCorpus(london_corpus, zwickau_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25668a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../computed_data/corpus/london/london_poorly_similar_with_chops_new_generation_6.txt\", \"w\") as text_file:\n",
    "#     text_file.write('\\n'.join([i[0] for i in london_leftovers.corpus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../computed_data/corpus/london/london_poorly_similar_with_chops_new_generation_4.txt\", \"w\") as text_file:\n",
    "#     text_file.write('\\n'.join(dataReader.LeftoversCorpus(london_corpus, zwickau_corpus).corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import p_aligment.p_aligment as thesisPAligment\n",
    "# import pandas as pd\n",
    "# imp.reload(thesisPAligment)\n",
    "# thesisPAligment.create_p_aligment_df_with_chop_by_london(pd.read_csv('../computed_data/p_aligment/by_new_line/london_zwickau_breslau.csv').drop(['Unnamed: 0'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4342b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n"
     ]
    }
   ],
   "source": [
    "zwickau_leftovers = dataReader.LeftoversCorpus(zwickau_corpus, london_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e14776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i[0] for i in zwickau_leftovers.corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14d3a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../computed_data/corpus/zwickau/zwickau_poorly_similar_with_chops_new_generation_4.txt\", \"w\") as text_file:\n",
    "#     text_file.write('\\n'.join([i[1] for i in london_leftovers.corpus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e43c6c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n"
     ]
    }
   ],
   "source": [
    "lf = dataReader.LeftoversCorpus(london_corpus, zwickau_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0cd86271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n"
     ]
    }
   ],
   "source": [
    "with open(\"../computed_data/corpus/zwickau/zwickau_poorly_similar_with_chops_new_generation_8.txt\", \"w\") as text_file:\n",
    "    text_file.write('\\n'.join(dataReader.LeftoversCorpus(zwickau_corpus, london_corpus).corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fac042c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: len(x.split()) > 20, dataReader.LeftoversCorpus(london_corpus, zwickau_corpus).corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "038c7dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/zwickau_london_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n",
      "loading data: /Users/sasha.kruglyak/thesis/src/similarities/saved_similarities/london_zwickau_TfidfVectorizer(analyzer='char',ngram_range=(5,5))\n"
     ]
    }
   ],
   "source": [
    "zwickau_leftofvers_long = list(filter(lambda x: len(x.split()) > 20, dataReader.LeftoversCorpus(zwickau_corpus, london_corpus).corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de9f3c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zwickau_leftofvers_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ef2e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: len(x.split()) > 20, burchard_corpus_lz.corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84804e8d",
   "metadata": {},
   "source": [
    "# verify a new created zwickau leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56d6e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    list(filter(lambda x: len(x.split()) > 20, burchard_corpus_lz.corpus)),\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4dc61d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p = thesisModelFeatures.run_models(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78e9a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       " SVM_linear                        0.293810      0.500000  0.370096  0.587619   \n",
       " SVM_RBF                           0.747899      0.649048  0.634857  0.700476   \n",
       " DecisionTreeClassifier            0.724525      0.724762  0.721385  0.729286   \n",
       " GaussianProcessClassifier         0.710851      0.687262  0.687785  0.706429   \n",
       " RandomForestClassifier            0.754526      0.709643  0.711089  0.740159   \n",
       " MLPClassifier                     0.713081      0.690714  0.690890  0.706587   \n",
       " GaussianNB                        0.628596      0.529167  0.466058  0.599206   \n",
       " KNeighborsClassifier              0.698802      0.549881  0.482861  0.624206   \n",
       " AdaBoostClassifier                0.805553      0.793690  0.796080  0.805079   \n",
       " XGBClassifier                     0.825755      0.812143  0.815890  0.825317   \n",
       " \n",
       "                            f1_weighted  accuracy  \n",
       " SVM_linear                    0.435047  0.587619  \n",
       " SVM_RBF                       0.661740  0.700476  \n",
       " DecisionTreeClassifier        0.729071  0.729286  \n",
       " GaussianProcessClassifier     0.700188  0.706429  \n",
       " RandomForestClassifier        0.726679  0.740159  \n",
       " MLPClassifier                 0.701952  0.706587  \n",
       " GaussianNB                    0.512433  0.599206  \n",
       " KNeighborsClassifier          0.530702  0.624206  \n",
       " AdaBoostClassifier            0.803349  0.805079  \n",
       " XGBClassifier                 0.822931  0.825317  ,\n",
       " [{'fit_time': array([ 8.13248277,  9.76491523, 10.27105784,  9.27832413,  8.66782022,\n",
       "           7.14873791, 10.27855897,  7.13016796,  6.72881269,  7.08582807]),\n",
       "   'score_time': array([0.8314302 , 1.28602862, 0.85391212, 1.5655179 , 0.96161103,\n",
       "          0.90371704, 0.79509902, 0.80229616, 0.71713734, 0.79472518]),\n",
       "   'test_precision_macro': array([0.29166667, 0.29166667, 0.29166667, 0.29166667, 0.28571429,\n",
       "          0.28571429, 0.3       , 0.3       , 0.3       , 0.3       ]),\n",
       "   'test_recall_macro': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "   'test_f1_macro': array([0.36842105, 0.36842105, 0.36842105, 0.36842105, 0.36363636,\n",
       "          0.36363636, 0.375     , 0.375     , 0.375     , 0.375     ]),\n",
       "   'test_f1_micro': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ]),\n",
       "   'test_f1_weighted': array([0.42982456, 0.42982456, 0.42982456, 0.42982456, 0.41558442,\n",
       "          0.41558442, 0.45      , 0.45      , 0.45      , 0.45      ]),\n",
       "   'test_accuracy': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ])},\n",
       "  {'fit_time': array([ 6.95103192, 11.28121281,  7.13695407,  8.06582308,  7.14154506,\n",
       "           6.987988  ,  7.49258399,  7.05099988,  7.02448726,  7.27922511]),\n",
       "   'score_time': array([1.62484193, 1.23035121, 1.35515594, 1.37077975, 1.52986598,\n",
       "          1.128824  , 1.20489597, 1.46382594, 1.19134474, 1.23029399]),\n",
       "   'test_precision_macro': array([0.77339901, 0.79464286, 0.79464286, 0.63636364, 0.62731481,\n",
       "          0.74425287, 0.66091954, 0.7542735 , 0.81818182, 0.875     ]),\n",
       "   'test_recall_macro': array([0.67619048, 0.70952381, 0.70952381, 0.54285714, 0.59166667,\n",
       "          0.64166667, 0.5952381 , 0.70238095, 0.57142857, 0.75      ]),\n",
       "   'test_f1_macro': array([0.67272727, 0.71251109, 0.71251109, 0.48148148, 0.57909343,\n",
       "          0.62585034, 0.58      , 0.70860315, 0.51388889, 0.76190476]),\n",
       "   'test_f1_micro': array([0.72222222, 0.75      , 0.75      , 0.61111111, 0.62857143,\n",
       "          0.68571429, 0.65714286, 0.74285714, 0.65714286, 0.8       ]),\n",
       "   'test_f1_weighted': array([0.69393939, 0.72981366, 0.72981366, 0.52469136, 0.59970926,\n",
       "          0.64723032, 0.616     , 0.72858464, 0.56666667, 0.78095238]),\n",
       "   'test_accuracy': array([0.72222222, 0.75      , 0.75      , 0.61111111, 0.62857143,\n",
       "          0.68571429, 0.65714286, 0.74285714, 0.65714286, 0.8       ])},\n",
       "  {'fit_time': array([0.48183298, 0.63789487, 0.49687886, 0.46294284, 0.65594196,\n",
       "          0.63674426, 0.61343884, 0.47390199, 0.635782  , 0.65551591]),\n",
       "   'score_time': array([0.16980886, 0.15416908, 0.16391492, 0.15482497, 0.15547609,\n",
       "          0.15624785, 0.15300727, 0.15402198, 0.15201616, 0.15195107]),\n",
       "   'test_precision_macro': array([0.63125   , 0.6875    , 0.74350649, 0.65714286, 0.70833333,\n",
       "          0.70833333, 0.70723684, 0.81085526, 0.79370629, 0.79738562]),\n",
       "   'test_recall_macro': array([0.63333333, 0.67142857, 0.73809524, 0.65714286, 0.70833333,\n",
       "          0.70833333, 0.71428571, 0.82142857, 0.78571429, 0.80952381]),\n",
       "   'test_f1_macro': array([0.631786  , 0.67407407, 0.74017642, 0.65714286, 0.70833333,\n",
       "          0.70833333, 0.70833333, 0.7993448 , 0.78897502, 0.79735318]),\n",
       "   'test_f1_micro': array([0.63888889, 0.69444444, 0.75      , 0.66666667, 0.71428571,\n",
       "          0.71428571, 0.71428571, 0.8       , 0.8       , 0.8       ]),\n",
       "   'test_f1_weighted': array([0.64030947, 0.68765432, 0.74859663, 0.66666667, 0.71428571,\n",
       "          0.71428571, 0.71666667, 0.801638  , 0.79862188, 0.80198511]),\n",
       "   'test_accuracy': array([0.63888889, 0.69444444, 0.75      , 0.66666667, 0.71428571,\n",
       "          0.71428571, 0.71428571, 0.8       , 0.8       , 0.8       ])},\n",
       "  {'fit_time': array([30.04860783, 29.86444283, 29.50433612, 29.56209993, 31.85710001,\n",
       "          33.24461174, 30.36709094, 30.99840522, 27.64646697, 30.51586795]),\n",
       "   'score_time': array([0.70995116, 0.70066309, 0.69246387, 0.69545603, 0.70778298,\n",
       "          0.68519306, 0.68731523, 0.69283772, 0.69144297, 0.69587517]),\n",
       "   'test_precision_macro': array([0.74350649, 0.77142857, 0.65714286, 0.52727273, 0.59803922,\n",
       "          0.6486014 , 0.76630435, 0.675     , 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.73809524, 0.77142857, 0.65714286, 0.52380952, 0.6       ,\n",
       "          0.64166667, 0.75      , 0.67857143, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.74017642, 0.77142857, 0.65714286, 0.51839465, 0.59703947,\n",
       "          0.64285714, 0.75524476, 0.67619849, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.75      , 0.77777778, 0.66666667, 0.55555556, 0.6       ,\n",
       "          0.65714286, 0.77142857, 0.68571429, 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.74859663, 0.77777778, 0.66666667, 0.54069119, 0.60197368,\n",
       "          0.65306122, 0.76783217, 0.68730025, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.75      , 0.77777778, 0.66666667, 0.55555556, 0.6       ,\n",
       "          0.65714286, 0.77142857, 0.68571429, 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.64303303, 0.50098395, 0.50952101, 0.50600171, 0.51419306,\n",
       "          0.50075078, 0.50691104, 0.51934123, 0.51575804, 0.50573611]),\n",
       "   'score_time': array([0.16369104, 0.15990996, 0.15822887, 0.15749407, 0.16009188,\n",
       "          0.15767908, 0.16382504, 0.15927792, 0.16154075, 0.15884995]),\n",
       "   'test_precision_macro': array([0.77591973, 0.75      , 0.75      , 0.66666667, 0.76785714,\n",
       "          0.76      , 0.67132867, 0.76630435, 0.73333333, 0.90384615]),\n",
       "   'test_recall_macro': array([0.76190476, 0.72857143, 0.72857143, 0.62857143, 0.675     ,\n",
       "          0.71666667, 0.66666667, 0.75      , 0.61904762, 0.82142857]),\n",
       "   'test_f1_macro': array([0.76623377, 0.73333333, 0.73333333, 0.625     , 0.66856061,\n",
       "          0.72      , 0.66838932, 0.75524476, 0.60268318, 0.83811286]),\n",
       "   'test_f1_micro': array([0.77777778, 0.75      , 0.75      , 0.66666667, 0.71428571,\n",
       "          0.74285714, 0.68571429, 0.77142857, 0.68571429, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.77489177, 0.74444444, 0.74444444, 0.64583333, 0.68614719,\n",
       "          0.73142857, 0.68354866, 0.76783217, 0.63900929, 0.84921369]),\n",
       "   'test_accuracy': array([0.77777778, 0.75      , 0.75      , 0.66666667, 0.71428571,\n",
       "          0.74285714, 0.68571429, 0.77142857, 0.68571429, 0.85714286])},\n",
       "  {'fit_time': array([119.67335081, 120.97543812, 127.89593697, 117.79102492,\n",
       "          105.649755  , 104.86992192, 115.58846283,  87.43782806,\n",
       "          101.66429687, 109.44666004]),\n",
       "   'score_time': array([0.20084715, 0.20921016, 0.19766498, 0.21060896, 0.25562191,\n",
       "          0.24514413, 0.20371509, 0.28112912, 0.20662093, 0.20564198]),\n",
       "   'test_precision_macro': array([0.71571906, 0.77142857, 0.63125   , 0.54285714, 0.59803922,\n",
       "          0.68115942, 0.76190476, 0.70723684, 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.7047619 , 0.77142857, 0.63333333, 0.54285714, 0.6       ,\n",
       "          0.66666667, 0.76190476, 0.71428571, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.70779221, 0.77142857, 0.631786  , 0.54285714, 0.59703947,\n",
       "          0.66838932, 0.76190476, 0.70833333, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.72222222, 0.77777778, 0.63888889, 0.55555556, 0.6       ,\n",
       "          0.68571429, 0.77142857, 0.71428571, 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.71861472, 0.77777778, 0.64030947, 0.55555556, 0.60197368,\n",
       "          0.67921742, 0.77142857, 0.71666667, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.72222222, 0.77777778, 0.63888889, 0.55555556, 0.6       ,\n",
       "          0.68571429, 0.77142857, 0.71428571, 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.34233379, 0.26396132, 0.24140215, 0.2412312 , 0.24191618,\n",
       "          0.24387932, 0.24311018, 0.24142885, 0.24258089, 0.24233222]),\n",
       "   'score_time': array([0.17705393, 0.16452289, 0.16346002, 0.1638999 , 0.18884397,\n",
       "          0.16407084, 0.16352391, 0.1641171 , 0.16417909, 0.16408968]),\n",
       "   'test_precision_macro': array([0.54411765, 0.8       , 0.46181818, 0.54411765, 0.68145161,\n",
       "          0.8030303 , 0.61666667, 0.5530303 , 0.81818182, 0.46354167]),\n",
       "   'test_recall_macro': array([0.50952381, 0.53333333, 0.46666667, 0.50952381, 0.575     ,\n",
       "          0.56666667, 0.55952381, 0.51190476, 0.57142857, 0.48809524]),\n",
       "   'test_f1_macro': array([0.42245989, 0.4375    , 0.45819398, 0.42245989, 0.53044376,\n",
       "          0.49500555, 0.53044376, 0.43287037, 0.51388889, 0.4173141 ]),\n",
       "   'test_f1_micro': array([0.58333333, 0.61111111, 0.5       , 0.58333333, 0.62857143,\n",
       "          0.62857143, 0.62857143, 0.6       , 0.65714286, 0.57142857]),\n",
       "   'test_f1_weighted': array([0.47326203, 0.48958333, 0.48327759, 0.47326203, 0.56110865,\n",
       "          0.53210718, 0.57337461, 0.49444444, 0.56666667, 0.4772475 ]),\n",
       "   'test_accuracy': array([0.58333333, 0.61111111, 0.5       , 0.58333333, 0.62857143,\n",
       "          0.62857143, 0.62857143, 0.6       , 0.65714286, 0.57142857])},\n",
       "  {'fit_time': array([0.1715169 , 0.17961907, 0.17756701, 0.17832494, 0.17761993,\n",
       "          0.17703795, 0.1744101 , 0.17438102, 0.177737  , 0.17489195]),\n",
       "   'score_time': array([0.28900313, 0.26787996, 0.28659821, 0.275949  , 0.26633024,\n",
       "          0.30023313, 0.29190612, 0.27050185, 0.33044004, 0.30168414]),\n",
       "   'test_precision_macro': array([0.80882353, 0.54411765, 0.828125  , 0.8       , 0.64367816,\n",
       "          0.63020833, 0.5530303 , 0.5530303 , 0.80882353, 0.81818182]),\n",
       "   'test_recall_macro': array([0.56666667, 0.50952381, 0.63333333, 0.53333333, 0.58333333,\n",
       "          0.54166667, 0.51190476, 0.51190476, 0.53571429, 0.57142857]),\n",
       "   'test_f1_macro': array([0.49946524, 0.42245989, 0.60675273, 0.4375    , 0.55782313,\n",
       "          0.47649573, 0.43287037, 0.43287037, 0.44848485, 0.51388889]),\n",
       "   'test_f1_micro': array([0.63888889, 0.58333333, 0.69444444, 0.61111111, 0.62857143,\n",
       "          0.6       , 0.6       , 0.6       , 0.62857143, 0.65714286]),\n",
       "   'test_f1_weighted': array([0.54349376, 0.47326203, 0.63770275, 0.48958333, 0.58309038,\n",
       "          0.51282051, 0.49444444, 0.49444444, 0.51151515, 0.56666667]),\n",
       "   'test_accuracy': array([0.63888889, 0.58333333, 0.69444444, 0.61111111, 0.62857143,\n",
       "          0.6       , 0.6       , 0.6       , 0.62857143, 0.65714286])},\n",
       "  {'fit_time': array([3.82325673, 3.82824016, 3.82937598, 3.84501791, 3.85710192,\n",
       "          3.82645011, 3.83387899, 3.88771296, 3.79207706, 3.79033184]),\n",
       "   'score_time': array([0.21553516, 0.21239996, 0.21026993, 0.21637917, 0.21021891,\n",
       "          0.20968199, 0.21088171, 0.22800398, 0.21130919, 0.21037793]),\n",
       "   'test_precision_macro': array([0.80194805, 0.8       , 0.8361204 , 0.77591973, 0.73848684,\n",
       "          0.79605263, 0.82971014, 0.82236842, 0.80492424, 0.85      ]),\n",
       "   'test_recall_macro': array([0.7952381 , 0.8047619 , 0.81904762, 0.76190476, 0.74166667,\n",
       "          0.8       , 0.80952381, 0.83333333, 0.77380952, 0.79761905]),\n",
       "   'test_f1_macro': array([0.797915  , 0.80173092, 0.82467532, 0.76623377, 0.73945409,\n",
       "          0.79735318, 0.81643357, 0.825     , 0.78222222, 0.80978261]),\n",
       "   'test_f1_micro': array([0.80555556, 0.80555556, 0.83333333, 0.77777778, 0.74285714,\n",
       "          0.8       , 0.82857143, 0.82857143, 0.8       , 0.82857143]),\n",
       "   'test_f1_weighted': array([0.80446405, 0.80632048, 0.83116883, 0.77489177, 0.7437079 ,\n",
       "          0.8006617 , 0.82587413, 0.83      , 0.79466667, 0.82173913]),\n",
       "   'test_accuracy': array([0.80555556, 0.80555556, 0.83333333, 0.77777778, 0.74285714,\n",
       "          0.8       , 0.82857143, 0.82857143, 0.8       , 0.82857143])},\n",
       "  {'fit_time': array([11.67603922, 11.52124476, 11.52879691, 11.45270205, 11.49822903,\n",
       "          11.42713904, 11.30101299, 11.49037313, 11.33125138, 11.48187208]),\n",
       "   'score_time': array([0.52308798, 0.45705819, 0.45539618, 0.45921683, 0.43964529,\n",
       "          0.44122505, 0.43684888, 0.43990493, 0.44082475, 0.44104695]),\n",
       "   'test_precision_macro': array([0.77591973, 0.86038961, 0.8361204 , 0.65551839, 0.77097902,\n",
       "          0.77097902, 0.8548951 , 0.91608392, 0.85      , 0.96666667]),\n",
       "   'test_recall_macro': array([0.76190476, 0.85238095, 0.81904762, 0.64761905, 0.75833333,\n",
       "          0.75833333, 0.8452381 , 0.9047619 , 0.79761905, 0.97619048]),\n",
       "   'test_f1_macro': array([0.76623377, 0.85565357, 0.82467532, 0.64935065, 0.76190476,\n",
       "          0.76190476, 0.84926787, 0.90956072, 0.80978261, 0.9705635 ]),\n",
       "   'test_f1_micro': array([0.77777778, 0.86111111, 0.83333333, 0.66666667, 0.77142857,\n",
       "          0.77142857, 0.85714286, 0.91428571, 0.82857143, 0.97142857]),\n",
       "   'test_f1_weighted': array([0.77489177, 0.86033146, 0.83116883, 0.66233766, 0.76870748,\n",
       "          0.76870748, 0.85615848, 0.91369509, 0.82173913, 0.97157275]),\n",
       "   'test_accuracy': array([0.77777778, 0.86111111, 0.83333333, 0.66666667, 0.77142857,\n",
       "          0.77142857, 0.85714286, 0.91428571, 0.82857143, 0.97142857])}])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a93166ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.7262698412698413\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7487301587301587\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7064285714285714\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.74007937 0.72873016 0.73142857 0.72857143 0.73142857 0.73714286\n",
      " 0.72865079 0.74563492 0.74007937 0.72873016 0.73142857 0.72857143\n",
      " 0.73142857 0.73714286 0.72865079 0.74563492 0.59063492 0.59047619\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.74       0.73436508 0.7315873  0.72587302 0.7315873  0.74293651\n",
      " 0.74277778 0.74293651 0.74       0.73436508 0.7315873  0.72587302\n",
      " 0.7315873  0.74293651 0.74277778 0.74293651 0.60761905 0.59912698\n",
      " 0.59055556 0.58769841 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.73150794 0.73436508 0.74015873 0.74015873 0.72880952 0.7402381\n",
      " 0.72031746 0.73444444 0.73150794 0.73436508 0.74015873 0.74015873\n",
      " 0.72880952 0.7402381  0.72031746 0.73444444 0.62444444 0.6018254\n",
      " 0.59619048 0.58761905 0.59047619 0.58769841 0.58761905 0.59047619\n",
      " 0.72031746 0.71174603 0.72603175 0.74015873 0.73150794 0.73444444\n",
      " 0.72880952 0.73722222 0.72031746 0.71174603 0.72603175 0.74015873\n",
      " 0.73150794 0.73444444 0.72880952 0.73722222 0.63015873 0.61880952\n",
      " 0.61031746 0.6018254  0.60460317 0.59611111 0.59888889 0.60166667\n",
      " 0.73714286 0.7231746  0.72587302 0.72865079 0.7315873  0.7315873\n",
      " 0.7315873  0.72611111 0.73714286 0.7231746  0.72587302 0.72865079\n",
      " 0.7315873  0.7315873  0.7315873  0.72611111 0.64428571 0.63293651\n",
      " 0.62738095 0.6215873  0.61309524 0.61309524 0.61015873 0.61301587\n",
      " 0.73166667 0.72309524 0.73452381 0.72873016 0.7202381  0.72873016\n",
      " 0.74285714 0.74579365 0.73166667 0.72309524 0.73452381 0.72873016\n",
      " 0.7202381  0.72873016 0.74285714 0.74579365 0.62730159 0.63007937\n",
      " 0.6384127  0.63       0.62992063 0.61865079 0.61849206 0.62412698\n",
      " 0.70611111 0.72015873 0.71714286 0.72579365 0.72579365 0.7315873\n",
      " 0.73738095 0.7402381  0.70611111 0.72015873 0.71714286 0.72579365\n",
      " 0.72579365 0.7315873  0.73738095 0.7402381  0.63619048 0.6415873\n",
      " 0.63       0.63007937 0.62722222 0.62714286 0.63277778 0.62714286\n",
      " 0.72015873 0.72293651 0.72857143 0.73722222 0.7315873  0.73452381\n",
      " 0.73460317 0.73174603 0.72015873 0.72293651 0.72857143 0.73722222\n",
      " 0.7315873  0.73452381 0.73460317 0.73174603 0.65555556 0.65833333\n",
      " 0.63285714 0.63293651 0.63563492 0.63555556 0.63261905 0.63833333\n",
      " 0.7231746  0.72285714 0.73150794 0.74007937 0.74285714 0.72880952\n",
      " 0.72896825 0.73174603 0.7231746  0.72285714 0.73150794 0.74007937\n",
      " 0.74285714 0.72880952 0.72896825 0.73174603 0.63293651 0.6552381\n",
      " 0.64126984 0.63833333 0.63547619 0.64412698 0.64968254 0.64126984\n",
      " 0.72579365 0.7231746  0.74       0.73706349 0.74277778 0.74\n",
      " 0.74849206 0.75126984 0.72579365 0.7231746  0.74       0.73706349\n",
      " 0.74277778 0.74       0.74849206 0.75126984 0.59904762 0.58761905\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.74865079 0.73436508 0.73706349 0.73134921 0.73134921 0.73134921\n",
      " 0.73992063 0.74285714 0.74865079 0.73436508 0.73706349 0.73134921\n",
      " 0.73134921 0.73134921 0.73992063 0.74285714 0.59896825 0.59325397\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.73444444 0.73150794 0.74563492 0.73714286 0.72865079 0.73722222\n",
      " 0.73436508 0.73722222 0.73444444 0.73150794 0.74563492 0.73714286\n",
      " 0.72865079 0.73722222 0.73436508 0.73722222 0.61293651 0.59619048\n",
      " 0.59047619 0.59047619 0.59047619 0.58761905 0.58761905 0.58761905\n",
      " 0.72896825 0.73730159 0.72873016 0.73436508 0.73714286 0.73714286\n",
      " 0.72865079 0.73428571 0.72896825 0.73730159 0.72873016 0.73436508\n",
      " 0.73714286 0.73714286 0.72865079 0.73428571 0.63       0.61587302\n",
      " 0.60444444 0.59896825 0.59896825 0.59611111 0.5931746  0.59039683\n",
      " 0.72880952 0.71730159 0.7315873  0.72865079 0.74007937 0.74\n",
      " 0.73428571 0.7315873  0.72880952 0.71730159 0.7315873  0.72865079\n",
      " 0.74007937 0.74       0.73428571 0.7315873  0.64388889 0.61857143\n",
      " 0.60730159 0.61015873 0.6102381  0.61015873 0.60444444 0.60452381\n",
      " 0.74309524 0.73714286 0.74277778 0.73436508 0.74293651 0.74301587\n",
      " 0.73436508 0.74015873 0.74309524 0.73714286 0.74277778 0.73436508\n",
      " 0.74293651 0.74301587 0.73436508 0.74015873 0.63571429 0.62992063\n",
      " 0.62714286 0.62420635 0.62714286 0.62150794 0.62142857 0.61865079\n",
      " 0.71190476 0.73444444 0.73142857 0.73436508 0.73730159 0.74015873\n",
      " 0.73722222 0.74579365 0.71190476 0.73444444 0.73142857 0.73436508\n",
      " 0.73730159 0.74015873 0.73722222 0.74579365 0.66952381 0.64968254\n",
      " 0.63277778 0.63571429 0.63571429 0.63007937 0.63007937 0.62444444\n",
      " 0.73436508 0.74587302 0.76563492 0.75420635 0.74849206 0.74571429\n",
      " 0.74579365 0.74293651 0.73436508 0.74587302 0.76563492 0.75420635\n",
      " 0.74849206 0.74571429 0.74579365 0.74293651 0.62730159 0.63849206\n",
      " 0.63277778 0.64126984 0.64119048 0.63277778 0.64412698 0.63\n",
      " 0.73436508 0.73730159 0.75706349 0.76261905 0.75992063 0.75428571\n",
      " 0.75134921 0.74571429 0.73436508 0.73730159 0.75706349 0.76261905\n",
      " 0.75992063 0.75428571 0.75134921 0.74571429 0.63857143 0.64420635\n",
      " 0.64698413 0.65269841 0.65261905 0.64698413 0.65246032 0.65539683\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.89829952 0.90866801 0.91086729 0.91651387 0.91839869 0.91839869\n",
      " 0.91746318 0.91714576 0.89829952 0.90866801 0.91086729 0.91651387\n",
      " 0.91839869 0.91839869 0.91746318 0.91714576 0.6691607  0.62899391\n",
      " 0.61173281 0.6045149  0.60011928 0.59509966 0.59353325 0.59133889\n",
      " 0.95009661 0.96485085 0.9683011  0.97238619 0.97552887 0.97709331\n",
      " 0.97803375 0.97615386 0.95009661 0.96485085 0.9683011  0.97238619\n",
      " 0.97552887 0.97709331 0.97803375 0.97615386 0.73758404 0.70463418\n",
      " 0.68894344 0.66916662 0.66194574 0.65285188 0.65191637 0.64595532\n",
      " 0.97834428 0.99027227 0.99372351 0.99560537 0.99591984 0.99780269\n",
      " 0.99748921 0.99748921 0.97834428 0.99027227 0.99372351 0.99560537\n",
      " 0.99591984 0.99780269 0.99748921 0.99748921 0.80507581 0.79347607\n",
      " 0.78530195 0.77337296 0.76427022 0.75987461 0.75989038 0.75235504\n",
      " 0.99121173 0.99811616 0.99937107 1.         0.99968553 1.\n",
      " 1.         1.         0.99121173 0.99811616 0.99937107 1.\n",
      " 0.99968553 1.         1.         1.         0.86596873 0.87162812\n",
      " 0.86723152 0.85686599 0.86377142 0.86283393 0.86065239 0.85562785\n",
      " 0.99623627 1.         0.99937107 1.         1.         1.\n",
      " 1.         1.         0.99623627 1.         0.99937107 1.\n",
      " 1.         1.         1.         1.         0.903329   0.92436663\n",
      " 0.92718894 0.92969973 0.9322125  0.93848899 0.93849688 0.93598608\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.93910708 0.95448434\n",
      " 0.95888291 0.9645354  0.97332564 0.97364011 0.97772422 0.97960805\n",
      " 0.99937205 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99937205 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96390745 0.98274285\n",
      " 0.98179649 0.98587863 0.99058773 0.9912137  0.99215611 0.99215611\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97207468 0.98775951\n",
      " 0.99466395 0.99654877 0.99686126 0.99686225 0.99811715 0.99843063\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98274088 0.99560734\n",
      " 0.99780367 0.99811814 0.99905956 0.99937205 0.99937304 0.99905759\n",
      " 0.89329272 0.89769031 0.89800576 0.90145798 0.90428028 0.90490527\n",
      " 0.90679009 0.9052148  0.89329272 0.89769031 0.89800576 0.90145798\n",
      " 0.90428028 0.90490527 0.90679009 0.9052148  0.65126871 0.61737939\n",
      " 0.60294454 0.59541216 0.59102147 0.59008103 0.58945506 0.58914158\n",
      " 0.93598017 0.95292581 0.9573234  0.95669447 0.96203052 0.962968\n",
      " 0.9661097  0.96516827 0.93598017 0.95292581 0.9573234  0.95669447\n",
      " 0.96203052 0.962968   0.9661097  0.96516827 0.71309418 0.68297944\n",
      " 0.65629522 0.63777331 0.6321287  0.63087281 0.62836793 0.61926914\n",
      " 0.97018592 0.98587863 0.98933085 0.99121468 0.9912137  0.99027326\n",
      " 0.99278405 0.993412   0.97018592 0.98587863 0.98933085 0.99121468\n",
      " 0.9912137  0.99027326 0.99278405 0.993412   0.77524398 0.76647148\n",
      " 0.7441819  0.72628103 0.72189823 0.72221171 0.72221565 0.71688551\n",
      " 0.98807594 0.9971777  0.99811814 0.99905956 0.99905858 0.99968652\n",
      " 0.99937304 0.99968652 0.98807594 0.9971777  0.99811814 0.99905956\n",
      " 0.99905858 0.99968652 0.99937304 0.99968652 0.84055224 0.83773092\n",
      " 0.83301295 0.8204649  0.8182597  0.81700972 0.8185919  0.81388577\n",
      " 0.99498235 0.99968553 1.         1.         1.         1.\n",
      " 1.         1.         0.99498235 0.99968553 1.         1.\n",
      " 1.         1.         1.         1.         0.88167524 0.89957118\n",
      " 0.89988072 0.89611896 0.90208198 0.89768636 0.90240039 0.90302636\n",
      " 0.99780269 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99780269 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.92623864 0.94350663\n",
      " 0.94193726 0.94507798 0.94853315 0.9482177  0.95293074 0.95763786\n",
      " 0.9987451  1.         1.         1.         1.         1.\n",
      " 1.         1.         0.9987451  1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94822559 0.96547978\n",
      " 0.96955797 0.9758394  0.9799166  0.98179945 0.9852566  0.98494213\n",
      " 0.99905858 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99905858 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96705309 0.97929359\n",
      " 0.98462175 0.98995682 0.99215512 0.99372055 0.99592082 0.99529485\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97803277 0.99215315\n",
      " 0.99560241 0.99717277 0.99811518 0.99780071 0.99905858 0.99905858\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656349206349206\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.613015873015873\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6242063492063493\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.8703968253968254\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_greed_rearch_resp = []\n",
    "for cls in ['SVC', 'DecisionTreeClassifier', 'GaussianProcessClassifier', 'RandomForestClassifier', 'GaussianNB', 'KNeighborsClassifier', 'AdaBoostClassifier']:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df, [cls])\n",
    "    burchard_zwickau_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15001566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df_by_zl = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    list(filter(lambda x: len(x.split()) > 20, burchard_corpus_zl.corpus)),\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a4d8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p_by_zl = thesisModelFeatures.run_models(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df_by_zl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40c234e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       " SVM_linear                        0.293214      0.500000  0.369617  0.586429   \n",
       " SVM_RBF                           0.748904      0.621071  0.602430  0.673810   \n",
       " DecisionTreeClassifier            0.688514      0.679881  0.677720  0.688492   \n",
       " GaussianProcessClassifier         0.711243      0.683095  0.684108  0.702143   \n",
       " RandomForestClassifier            0.757688      0.697381  0.698811  0.727540   \n",
       " MLPClassifier                     0.713932      0.686548  0.687125  0.705000   \n",
       " GaussianNB                        0.646911      0.527262  0.467682  0.595000   \n",
       " KNeighborsClassifier              0.693926      0.555238  0.495901  0.625873   \n",
       " AdaBoostClassifier                0.786987      0.765952  0.767423  0.781508   \n",
       " XGBClassifier                     0.813956      0.788333  0.792804  0.807143   \n",
       " \n",
       "                            f1_weighted  accuracy  \n",
       " SVM_linear                    0.433623  0.586429  \n",
       " SVM_RBF                       0.630755  0.673810  \n",
       " DecisionTreeClassifier        0.686110  0.688492  \n",
       " GaussianProcessClassifier     0.695814  0.702143  \n",
       " RandomForestClassifier        0.713524  0.727540  \n",
       " MLPClassifier                 0.698710  0.705000  \n",
       " GaussianNB                    0.512376  0.595000  \n",
       " KNeighborsClassifier          0.540473  0.625873  \n",
       " AdaBoostClassifier            0.776693  0.781508  \n",
       " XGBClassifier                 0.801836  0.807143  ,\n",
       " [{'fit_time': array([ 8.809726  , 13.24176812, 14.39685106, 13.80628204, 13.67162585,\n",
       "          11.27201891,  8.80110312,  8.12089777,  8.09791398,  8.6662128 ]),\n",
       "   'score_time': array([1.40084386, 1.62270093, 1.706424  , 1.51704311, 1.51014519,\n",
       "          0.94268703, 0.97780085, 0.96101904, 1.01138496, 0.965276  ]),\n",
       "   'test_precision_macro': array([0.29166667, 0.29166667, 0.29166667, 0.28571429, 0.28571429,\n",
       "          0.28571429, 0.3       , 0.3       , 0.3       , 0.3       ]),\n",
       "   'test_recall_macro': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "   'test_f1_macro': array([0.36842105, 0.36842105, 0.36842105, 0.36363636, 0.36363636,\n",
       "          0.36363636, 0.375     , 0.375     , 0.375     , 0.375     ]),\n",
       "   'test_f1_micro': array([0.58333333, 0.58333333, 0.58333333, 0.57142857, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ]),\n",
       "   'test_f1_weighted': array([0.42982456, 0.42982456, 0.42982456, 0.41558442, 0.41558442,\n",
       "          0.41558442, 0.45      , 0.45      , 0.45      , 0.45      ]),\n",
       "   'test_accuracy': array([0.58333333, 0.58333333, 0.58333333, 0.57142857, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ])},\n",
       "  {'fit_time': array([8.78543997, 8.68855786, 9.16204   , 8.93769598, 8.69927192,\n",
       "          8.94139791, 8.78845286, 8.68367887, 8.57525206, 8.665483  ]),\n",
       "   'score_time': array([1.52935314, 1.47422314, 1.47573519, 1.47579503, 1.51407623,\n",
       "          1.51298118, 1.4244442 , 1.39228797, 1.46593189, 1.4083221 ]),\n",
       "   'test_precision_macro': array([0.85      , 0.75      , 0.77339901, 0.8030303 , 0.67857143,\n",
       "          0.62731481, 0.48776224, 0.83870968, 0.81818182, 0.86206897]),\n",
       "   'test_recall_macro': array([0.7       , 0.64285714, 0.67619048, 0.56666667, 0.61666667,\n",
       "          0.59166667, 0.48809524, 0.64285714, 0.57142857, 0.71428571]),\n",
       "   'test_f1_macro': array([0.69747899, 0.6302521 , 0.67272727, 0.49500555, 0.60227273,\n",
       "          0.57909343, 0.48751077, 0.62606838, 0.51388889, 0.72      ]),\n",
       "   'test_f1_micro': array([0.75      , 0.69444444, 0.72222222, 0.62857143, 0.65714286,\n",
       "          0.62857143, 0.51428571, 0.71428571, 0.65714286, 0.77142857]),\n",
       "   'test_f1_weighted': array([0.71848739, 0.65592904, 0.69393939, 0.53210718, 0.62337662,\n",
       "          0.59970926, 0.51093885, 0.66239316, 0.56666667, 0.744     ]),\n",
       "   'test_accuracy': array([0.75      , 0.69444444, 0.72222222, 0.62857143, 0.65714286,\n",
       "          0.62857143, 0.51428571, 0.71428571, 0.65714286, 0.77142857])},\n",
       "  {'fit_time': array([0.4716959 , 0.68382311, 0.4949038 , 0.46623015, 0.6564858 ,\n",
       "          0.68724513, 0.58094716, 0.49344587, 0.62351894, 0.52021074]),\n",
       "   'score_time': array([0.15735483, 0.15865684, 0.15606022, 0.1537087 , 0.15332508,\n",
       "          0.15268683, 0.15202999, 0.15182734, 0.15274692, 0.15412927]),\n",
       "   'test_precision_macro': array([0.71571906, 0.78909091, 0.5487013 , 0.57352941, 0.67857143,\n",
       "          0.59166667, 0.67234848, 0.75328947, 0.73251748, 0.82971014]),\n",
       "   'test_recall_macro': array([0.7047619 , 0.75238095, 0.54761905, 0.575     , 0.675     ,\n",
       "          0.59166667, 0.6547619 , 0.76190476, 0.72619048, 0.80952381]),\n",
       "   'test_f1_macro': array([0.70779221, 0.75919732, 0.52741313, 0.57002457, 0.67619849,\n",
       "          0.59166667, 0.65777778, 0.74201474, 0.72868217, 0.81643357]),\n",
       "   'test_f1_micro': array([0.72222222, 0.77777778, 0.52777778, 0.57142857, 0.68571429,\n",
       "          0.6       , 0.68571429, 0.74285714, 0.74285714, 0.82857143]),\n",
       "   'test_f1_weighted': array([0.71861472, 0.7703456 , 0.52522523, 0.57353457, 0.68412832,\n",
       "          0.6       , 0.67733333, 0.74496314, 0.74108527, 0.82587413]),\n",
       "   'test_accuracy': array([0.72222222, 0.77777778, 0.52777778, 0.57142857, 0.68571429,\n",
       "          0.6       , 0.68571429, 0.74285714, 0.74285714, 0.82857143])},\n",
       "  {'fit_time': array([29.50856614, 29.42287326, 29.99293065, 29.81859398, 27.61916399,\n",
       "          29.69545197, 30.15336919, 29.66235065, 27.28874874, 27.33731413]),\n",
       "   'score_time': array([0.69559979, 0.69120693, 0.76606321, 0.68042207, 0.68241787,\n",
       "          0.68954206, 0.67877603, 0.68187428, 0.67507124, 0.68708873]),\n",
       "   'test_precision_macro': array([0.75      , 0.80194805, 0.6875    , 0.52622378, 0.65151515,\n",
       "          0.62335526, 0.54575163, 0.80492424, 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.72857143, 0.7952381 , 0.69047619, 0.525     , 0.63333333,\n",
       "          0.625     , 0.54761905, 0.77380952, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.73333333, 0.797915  , 0.6884343 , 0.52380952, 0.63286713,\n",
       "          0.62365591, 0.53947368, 0.78222222, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.75      , 0.80555556, 0.69444444, 0.54285714, 0.65714286,\n",
       "          0.62857143, 0.54285714, 0.8       , 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.74444444, 0.80446405, 0.69564647, 0.53741497, 0.64635365,\n",
       "          0.62980031, 0.54736842, 0.79466667, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.75      , 0.80555556, 0.69444444, 0.54285714, 0.65714286,\n",
       "          0.62857143, 0.54285714, 0.8       , 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.66386795, 0.52195024, 0.51273799, 0.52048087, 0.52641988,\n",
       "          0.51619172, 0.50882101, 0.52194619, 0.51566505, 0.51647282]),\n",
       "   'score_time': array([0.162498  , 0.15867186, 0.16823387, 0.16127491, 0.15828586,\n",
       "          0.16079712, 0.15752816, 0.15850091, 0.15799689, 0.15852308]),\n",
       "   'test_precision_macro': array([0.81481481, 0.875     , 0.72363636, 0.52622378, 0.76785714,\n",
       "          0.62      , 0.60294118, 0.90384615, 0.83870968, 0.90384615]),\n",
       "   'test_recall_macro': array([0.74285714, 0.84285714, 0.6952381 , 0.525     , 0.675     ,\n",
       "          0.6       , 0.60714286, 0.82142857, 0.64285714, 0.82142857]),\n",
       "   'test_f1_macro': array([0.75      , 0.85185185, 0.69899666, 0.52380952, 0.66856061,\n",
       "          0.59555556, 0.59703947, 0.83811286, 0.62606838, 0.83811286]),\n",
       "   'test_f1_micro': array([0.77777778, 0.86111111, 0.72222222, 0.54285714, 0.71428571,\n",
       "          0.62857143, 0.6       , 0.85714286, 0.71428571, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.76388889, 0.85802469, 0.712932  , 0.53741497, 0.68614719,\n",
       "          0.61206349, 0.60394737, 0.84921369, 0.66239316, 0.84921369]),\n",
       "   'test_accuracy': array([0.77777778, 0.86111111, 0.72222222, 0.54285714, 0.71428571,\n",
       "          0.62857143, 0.6       , 0.85714286, 0.71428571, 0.85714286])},\n",
       "  {'fit_time': array([ 97.83643484, 104.27473164, 101.99858999, 100.82933593,\n",
       "           94.84115195, 100.8001318 ,  93.90945005, 103.60210395,\n",
       "          106.2455287 ,  99.00494409]),\n",
       "   'score_time': array([0.24120021, 0.22198033, 0.20870709, 0.20489502, 0.21615505,\n",
       "          0.21698499, 0.20149589, 0.20907688, 0.22019506, 0.23438573]),\n",
       "   'test_precision_macro': array([0.75      , 0.77142857, 0.71826625, 0.52622378, 0.65151515,\n",
       "          0.65      , 0.54575163, 0.80492424, 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.72857143, 0.77142857, 0.72380952, 0.525     , 0.63333333,\n",
       "          0.65      , 0.54761905, 0.77380952, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.73333333, 0.77142857, 0.71875   , 0.52380952, 0.63286713,\n",
       "          0.65      , 0.53947368, 0.78222222, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.75      , 0.77777778, 0.72222222, 0.54285714, 0.65714286,\n",
       "          0.65714286, 0.54285714, 0.8       , 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.74444444, 0.77777778, 0.72395833, 0.53741497, 0.64635365,\n",
       "          0.65714286, 0.54736842, 0.79466667, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.75      , 0.77777778, 0.72222222, 0.54285714, 0.65714286,\n",
       "          0.65714286, 0.54285714, 0.8       , 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.41555882, 0.24354815, 0.24266005, 0.29207587, 0.24009323,\n",
       "          0.24022198, 0.24979925, 0.23956108, 0.2389431 , 0.23875594]),\n",
       "   'score_time': array([0.176682  , 0.16529894, 0.16427708, 0.16329002, 0.16499496,\n",
       "          0.165272  , 0.164536  , 0.16372705, 0.16424489, 0.16370106]),\n",
       "   'test_precision_macro': array([0.8       , 0.8       , 0.48846154, 0.39919355, 0.68145161,\n",
       "          0.68145161, 0.42857143, 0.80882353, 0.828125  , 0.5530303 ]),\n",
       "   'test_recall_macro': array([0.53333333, 0.53333333, 0.49047619, 0.45833333, 0.575     ,\n",
       "          0.575     , 0.45238095, 0.53571429, 0.60714286, 0.51190476]),\n",
       "   'test_f1_macro': array([0.4375    , 0.4375    , 0.47914894, 0.38596491, 0.53044376,\n",
       "          0.53044376, 0.42176871, 0.44848485, 0.572697  , 0.43287037]),\n",
       "   'test_f1_micro': array([0.61111111, 0.61111111, 0.52777778, 0.51428571, 0.62857143,\n",
       "          0.62857143, 0.51428571, 0.62857143, 0.68571429, 0.6       ]),\n",
       "   'test_f1_weighted': array([0.48958333, 0.48958333, 0.50567376, 0.42606516, 0.56110865,\n",
       "          0.56110865, 0.46802721, 0.51151515, 0.61664817, 0.49444444]),\n",
       "   'test_accuracy': array([0.61111111, 0.61111111, 0.52777778, 0.51428571, 0.62857143,\n",
       "          0.62857143, 0.51428571, 0.62857143, 0.68571429, 0.6       ])},\n",
       "  {'fit_time': array([0.16900182, 0.17252922, 0.17727304, 0.17692614, 0.17510509,\n",
       "          0.17524099, 0.17733502, 0.17387605, 0.17670107, 0.17494917]),\n",
       "   'score_time': array([0.27289224, 0.25956774, 0.27150106, 0.27514005, 0.25461698,\n",
       "          0.27371001, 0.2638123 , 0.25521994, 0.27045703, 0.27481604]),\n",
       "   'test_precision_macro': array([0.80882353, 0.63636364, 0.828125  , 0.79411765, 0.67857143,\n",
       "          0.54032258, 0.46354167, 0.5530303 , 0.81818182, 0.81818182]),\n",
       "   'test_recall_macro': array([0.56666667, 0.54285714, 0.63333333, 0.53333333, 0.61666667,\n",
       "          0.51666667, 0.48809524, 0.51190476, 0.57142857, 0.57142857]),\n",
       "   'test_f1_macro': array([0.49946524, 0.48148148, 0.60675273, 0.43287037, 0.60227273,\n",
       "          0.45820433, 0.4173141 , 0.43287037, 0.51388889, 0.51388889]),\n",
       "   'test_f1_micro': array([0.63888889, 0.61111111, 0.69444444, 0.6       , 0.65714286,\n",
       "          0.57142857, 0.57142857, 0.6       , 0.65714286, 0.65714286]),\n",
       "   'test_f1_weighted': array([0.54349376, 0.52469136, 0.63770275, 0.47685185, 0.62337662,\n",
       "          0.49358691, 0.4772475 , 0.49444444, 0.56666667, 0.56666667]),\n",
       "   'test_accuracy': array([0.63888889, 0.61111111, 0.69444444, 0.6       , 0.65714286,\n",
       "          0.57142857, 0.57142857, 0.6       , 0.65714286, 0.65714286])},\n",
       "  {'fit_time': array([3.8207922 , 3.82078981, 3.83458376, 3.83986402, 3.816396  ,\n",
       "          3.84396791, 3.88373709, 3.82826185, 3.74954605, 3.77142787]),\n",
       "   'score_time': array([0.22082877, 0.21324611, 0.21212006, 0.21292496, 0.20927382,\n",
       "          0.21257901, 0.21165109, 0.21243691, 0.21118689, 0.20994711]),\n",
       "   'test_precision_macro': array([0.74375   , 0.89632107, 0.8361204 , 0.59166667, 0.82679739,\n",
       "          0.70833333, 0.8548951 , 0.82142857, 0.76149425, 0.82905983]),\n",
       "   'test_recall_macro': array([0.74761905, 0.87619048, 0.81904762, 0.59166667, 0.83333333,\n",
       "          0.70833333, 0.8452381 , 0.82142857, 0.6547619 , 0.76190476]),\n",
       "   'test_f1_macro': array([0.74508261, 0.88311688, 0.82467532, 0.59166667, 0.82730263,\n",
       "          0.70833333, 0.84926787, 0.82142857, 0.65      , 0.773358  ]),\n",
       "   'test_f1_micro': array([0.75      , 0.88888889, 0.83333333, 0.6       , 0.82857143,\n",
       "          0.71428571, 0.85714286, 0.82857143, 0.71428571, 0.8       ]),\n",
       "   'test_f1_weighted': array([0.75098348, 0.88744589, 0.83116883, 0.6       , 0.82941729,\n",
       "          0.71428571, 0.85615848, 0.82857143, 0.68      , 0.78889917]),\n",
       "   'test_accuracy': array([0.75      , 0.88888889, 0.83333333, 0.6       , 0.82857143,\n",
       "          0.71428571, 0.85714286, 0.82857143, 0.71428571, 0.8       ])},\n",
       "  {'fit_time': array([11.24297309, 11.29769707, 11.33322024, 11.089607  , 11.29851699,\n",
       "          11.208426  , 11.14120412, 11.37079501, 11.24093914, 13.23200178]),\n",
       "   'score_time': array([0.46415901, 0.46598697, 0.45987177, 0.4490571 , 0.44354105,\n",
       "          0.44478607, 0.43931985, 0.4608798 , 0.44150281, 0.44629502]),\n",
       "   'test_precision_macro': array([0.8125    , 0.89632107, 0.8125    , 0.73504274, 0.77097902,\n",
       "          0.70833333, 0.76630435, 0.82971014, 0.80787037, 1.        ]),\n",
       "   'test_recall_macro': array([0.78571429, 0.87619048, 0.78571429, 0.68333333, 0.75833333,\n",
       "          0.70833333, 0.75      , 0.80952381, 0.72619048, 1.        ]),\n",
       "   'test_f1_macro': array([0.79259259, 0.88311688, 0.79259259, 0.68297101, 0.76190476,\n",
       "          0.70833333, 0.75524476, 0.81643357, 0.73484848, 1.        ]),\n",
       "   'test_f1_micro': array([0.80555556, 0.88888889, 0.80555556, 0.71428571, 0.77142857,\n",
       "          0.71428571, 0.77142857, 0.82857143, 0.77142857, 1.        ]),\n",
       "   'test_f1_weighted': array([0.80123457, 0.88744589, 0.80123457, 0.69720497, 0.76870748,\n",
       "          0.71428571, 0.76783217, 0.82587413, 0.75454545, 1.        ]),\n",
       "   'test_accuracy': array([0.80555556, 0.88888889, 0.80555556, 0.71428571, 0.77142857,\n",
       "          0.71428571, 0.77142857, 0.82857143, 0.77142857, 1.        ])}])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p_by_zl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9d276e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.7262698412698413\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7496825396825397\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7064285714285714\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.74007937 0.72873016 0.73142857 0.72857143 0.73142857 0.73714286\n",
      " 0.72865079 0.74563492 0.74007937 0.72873016 0.73142857 0.72857143\n",
      " 0.73142857 0.73714286 0.72865079 0.74563492 0.59063492 0.59047619\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.74       0.73436508 0.7315873  0.72587302 0.7315873  0.74293651\n",
      " 0.74277778 0.74293651 0.74       0.73436508 0.7315873  0.72587302\n",
      " 0.7315873  0.74293651 0.74277778 0.74293651 0.60761905 0.59912698\n",
      " 0.59055556 0.58769841 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.73150794 0.73436508 0.74015873 0.74015873 0.72880952 0.7402381\n",
      " 0.72031746 0.73444444 0.73150794 0.73436508 0.74015873 0.74015873\n",
      " 0.72880952 0.7402381  0.72031746 0.73444444 0.62444444 0.6018254\n",
      " 0.59619048 0.58761905 0.59047619 0.58769841 0.58761905 0.59047619\n",
      " 0.72031746 0.71174603 0.72603175 0.74015873 0.73150794 0.73444444\n",
      " 0.72880952 0.73722222 0.72031746 0.71174603 0.72603175 0.74015873\n",
      " 0.73150794 0.73444444 0.72880952 0.73722222 0.63015873 0.61880952\n",
      " 0.61031746 0.6018254  0.60460317 0.59611111 0.59888889 0.60166667\n",
      " 0.73714286 0.7231746  0.72587302 0.72865079 0.7315873  0.7315873\n",
      " 0.7315873  0.72611111 0.73714286 0.7231746  0.72587302 0.72865079\n",
      " 0.7315873  0.7315873  0.7315873  0.72611111 0.64428571 0.63293651\n",
      " 0.62738095 0.6215873  0.61309524 0.61309524 0.61015873 0.61301587\n",
      " 0.73166667 0.72309524 0.73452381 0.72873016 0.7202381  0.72873016\n",
      " 0.74285714 0.74579365 0.73166667 0.72309524 0.73452381 0.72873016\n",
      " 0.7202381  0.72873016 0.74285714 0.74579365 0.62730159 0.63007937\n",
      " 0.6384127  0.63       0.62992063 0.61865079 0.61849206 0.62412698\n",
      " 0.70611111 0.72015873 0.71714286 0.72579365 0.72579365 0.7315873\n",
      " 0.73738095 0.7402381  0.70611111 0.72015873 0.71714286 0.72579365\n",
      " 0.72579365 0.7315873  0.73738095 0.7402381  0.63619048 0.6415873\n",
      " 0.63       0.63007937 0.62722222 0.62714286 0.63277778 0.62714286\n",
      " 0.72015873 0.72293651 0.72857143 0.73722222 0.7315873  0.73452381\n",
      " 0.73460317 0.73174603 0.72015873 0.72293651 0.72857143 0.73722222\n",
      " 0.7315873  0.73452381 0.73460317 0.73174603 0.65555556 0.65833333\n",
      " 0.63285714 0.63293651 0.63563492 0.63555556 0.63261905 0.63833333\n",
      " 0.7231746  0.72285714 0.73150794 0.74007937 0.74285714 0.72880952\n",
      " 0.72896825 0.73174603 0.7231746  0.72285714 0.73150794 0.74007937\n",
      " 0.74285714 0.72880952 0.72896825 0.73174603 0.63293651 0.6552381\n",
      " 0.64126984 0.63833333 0.63547619 0.64412698 0.64968254 0.64126984\n",
      " 0.72579365 0.7231746  0.74       0.73706349 0.74277778 0.74\n",
      " 0.74849206 0.75126984 0.72579365 0.7231746  0.74       0.73706349\n",
      " 0.74277778 0.74       0.74849206 0.75126984 0.59904762 0.58761905\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.74865079 0.73436508 0.73706349 0.73134921 0.73134921 0.73134921\n",
      " 0.73992063 0.74285714 0.74865079 0.73436508 0.73706349 0.73134921\n",
      " 0.73134921 0.73134921 0.73992063 0.74285714 0.59896825 0.59325397\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.73444444 0.73150794 0.74563492 0.73714286 0.72865079 0.73722222\n",
      " 0.73436508 0.73722222 0.73444444 0.73150794 0.74563492 0.73714286\n",
      " 0.72865079 0.73722222 0.73436508 0.73722222 0.61293651 0.59619048\n",
      " 0.59047619 0.59047619 0.59047619 0.58761905 0.58761905 0.58761905\n",
      " 0.72896825 0.73730159 0.72873016 0.73436508 0.73714286 0.73714286\n",
      " 0.72865079 0.73428571 0.72896825 0.73730159 0.72873016 0.73436508\n",
      " 0.73714286 0.73714286 0.72865079 0.73428571 0.63       0.61587302\n",
      " 0.60444444 0.59896825 0.59896825 0.59611111 0.5931746  0.59039683\n",
      " 0.72880952 0.71730159 0.7315873  0.72865079 0.74007937 0.74\n",
      " 0.73428571 0.7315873  0.72880952 0.71730159 0.7315873  0.72865079\n",
      " 0.74007937 0.74       0.73428571 0.7315873  0.64388889 0.61857143\n",
      " 0.60730159 0.61015873 0.6102381  0.61015873 0.60444444 0.60452381\n",
      " 0.74309524 0.73714286 0.74277778 0.73436508 0.74293651 0.74301587\n",
      " 0.73436508 0.74015873 0.74309524 0.73714286 0.74277778 0.73436508\n",
      " 0.74293651 0.74301587 0.73436508 0.74015873 0.63571429 0.62992063\n",
      " 0.62714286 0.62420635 0.62714286 0.62150794 0.62142857 0.61865079\n",
      " 0.71190476 0.73444444 0.73142857 0.73436508 0.73730159 0.74015873\n",
      " 0.73722222 0.74579365 0.71190476 0.73444444 0.73142857 0.73436508\n",
      " 0.73730159 0.74015873 0.73722222 0.74579365 0.66952381 0.64968254\n",
      " 0.63277778 0.63571429 0.63571429 0.63007937 0.63007937 0.62444444\n",
      " 0.73436508 0.74587302 0.76563492 0.75420635 0.74849206 0.74571429\n",
      " 0.74579365 0.74293651 0.73436508 0.74587302 0.76563492 0.75420635\n",
      " 0.74849206 0.74571429 0.74579365 0.74293651 0.62730159 0.63849206\n",
      " 0.63277778 0.64126984 0.64119048 0.63277778 0.64412698 0.63\n",
      " 0.73436508 0.73730159 0.75706349 0.76261905 0.75992063 0.75428571\n",
      " 0.75134921 0.74571429 0.73436508 0.73730159 0.75706349 0.76261905\n",
      " 0.75992063 0.75428571 0.75134921 0.74571429 0.63857143 0.64420635\n",
      " 0.64698413 0.65269841 0.65261905 0.64698413 0.65246032 0.65539683\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.89829952 0.90866801 0.91086729 0.91651387 0.91839869 0.91839869\n",
      " 0.91746318 0.91714576 0.89829952 0.90866801 0.91086729 0.91651387\n",
      " 0.91839869 0.91839869 0.91746318 0.91714576 0.6691607  0.62899391\n",
      " 0.61173281 0.6045149  0.60011928 0.59509966 0.59353325 0.59133889\n",
      " 0.95009661 0.96485085 0.9683011  0.97238619 0.97552887 0.97709331\n",
      " 0.97803375 0.97615386 0.95009661 0.96485085 0.9683011  0.97238619\n",
      " 0.97552887 0.97709331 0.97803375 0.97615386 0.73758404 0.70463418\n",
      " 0.68894344 0.66916662 0.66194574 0.65285188 0.65191637 0.64595532\n",
      " 0.97834428 0.99027227 0.99372351 0.99560537 0.99591984 0.99780269\n",
      " 0.99748921 0.99748921 0.97834428 0.99027227 0.99372351 0.99560537\n",
      " 0.99591984 0.99780269 0.99748921 0.99748921 0.80507581 0.79347607\n",
      " 0.78530195 0.77337296 0.76427022 0.75987461 0.75989038 0.75235504\n",
      " 0.99121173 0.99811616 0.99937107 1.         0.99968553 1.\n",
      " 1.         1.         0.99121173 0.99811616 0.99937107 1.\n",
      " 0.99968553 1.         1.         1.         0.86596873 0.87162812\n",
      " 0.86723152 0.85686599 0.86377142 0.86283393 0.86065239 0.85562785\n",
      " 0.99623627 1.         0.99937107 1.         1.         1.\n",
      " 1.         1.         0.99623627 1.         0.99937107 1.\n",
      " 1.         1.         1.         1.         0.903329   0.92436663\n",
      " 0.92718894 0.92969973 0.9322125  0.93848899 0.93849688 0.93598608\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.93910708 0.95448434\n",
      " 0.95888291 0.9645354  0.97332564 0.97364011 0.97772422 0.97960805\n",
      " 0.99937205 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99937205 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96390745 0.98274285\n",
      " 0.98179649 0.98587863 0.99058773 0.9912137  0.99215611 0.99215611\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97207468 0.98775951\n",
      " 0.99466395 0.99654877 0.99686126 0.99686225 0.99811715 0.99843063\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98274088 0.99560734\n",
      " 0.99780367 0.99811814 0.99905956 0.99937205 0.99937304 0.99905759\n",
      " 0.89329272 0.89769031 0.89800576 0.90145798 0.90428028 0.90490527\n",
      " 0.90679009 0.9052148  0.89329272 0.89769031 0.89800576 0.90145798\n",
      " 0.90428028 0.90490527 0.90679009 0.9052148  0.65126871 0.61737939\n",
      " 0.60294454 0.59541216 0.59102147 0.59008103 0.58945506 0.58914158\n",
      " 0.93598017 0.95292581 0.9573234  0.95669447 0.96203052 0.962968\n",
      " 0.9661097  0.96516827 0.93598017 0.95292581 0.9573234  0.95669447\n",
      " 0.96203052 0.962968   0.9661097  0.96516827 0.71309418 0.68297944\n",
      " 0.65629522 0.63777331 0.6321287  0.63087281 0.62836793 0.61926914\n",
      " 0.97018592 0.98587863 0.98933085 0.99121468 0.9912137  0.99027326\n",
      " 0.99278405 0.993412   0.97018592 0.98587863 0.98933085 0.99121468\n",
      " 0.9912137  0.99027326 0.99278405 0.993412   0.77524398 0.76647148\n",
      " 0.7441819  0.72628103 0.72189823 0.72221171 0.72221565 0.71688551\n",
      " 0.98807594 0.9971777  0.99811814 0.99905956 0.99905858 0.99968652\n",
      " 0.99937304 0.99968652 0.98807594 0.9971777  0.99811814 0.99905956\n",
      " 0.99905858 0.99968652 0.99937304 0.99968652 0.84055224 0.83773092\n",
      " 0.83301295 0.8204649  0.8182597  0.81700972 0.8185919  0.81388577\n",
      " 0.99498235 0.99968553 1.         1.         1.         1.\n",
      " 1.         1.         0.99498235 0.99968553 1.         1.\n",
      " 1.         1.         1.         1.         0.88167524 0.89957118\n",
      " 0.89988072 0.89611896 0.90208198 0.89768636 0.90240039 0.90302636\n",
      " 0.99780269 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99780269 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.92623864 0.94350663\n",
      " 0.94193726 0.94507798 0.94853315 0.9482177  0.95293074 0.95763786\n",
      " 0.9987451  1.         1.         1.         1.         1.\n",
      " 1.         1.         0.9987451  1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94822559 0.96547978\n",
      " 0.96955797 0.9758394  0.9799166  0.98179945 0.9852566  0.98494213\n",
      " 0.99905858 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99905858 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96705309 0.97929359\n",
      " 0.98462175 0.98995682 0.99215512 0.99372055 0.99592082 0.99529485\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97803277 0.99215315\n",
      " 0.99560241 0.99717277 0.99811518 0.99780071 0.99905858 0.99905858\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656349206349206\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.613015873015873\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6242063492063493\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.8646825396825397\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_greed_rearch_resp_by_zl = []\n",
    "for cls in ['SVC', 'DecisionTreeClassifier', 'GaussianProcessClassifier', 'RandomForestClassifier', 'GaussianNB', 'KNeighborsClassifier', 'AdaBoostClassifier']:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df, [cls])\n",
    "    burchard_zwickau_greed_rearch_resp_by_zl.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc601a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
