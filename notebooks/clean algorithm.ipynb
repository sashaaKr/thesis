{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b7ece8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2ffbaac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'similarities.cosine' from '../src/similarities/cosine.py'>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import data.reader as dataReader\n",
    "import utils.utils as thesisUtils\n",
    "import similarities.cosine as thesisCosineSimilarity\n",
    "import vocabulary.vocabulary as thesisVocabulary\n",
    "import features.model_features as thesisModelFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import sys\n",
    "import imp\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "imp.reload(dataReader)\n",
    "imp.reload(thesisUtils)\n",
    "imp.reload(thesisVocabulary)\n",
    "imp.reload(thesisModelFeatures)\n",
    "imp.reload(thesisCosineSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1390ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_corpus = dataReader.CorpusByNewLine.london()\n",
    "zwickau_corpus = dataReader.CorpusByNewLine.zwickau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd785d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_zwickau_similarities = thesisCosineSimilarity.CrossVersionSimilarity5Gram(london_corpus, zwickau_corpus)\n",
    "london_zwickau_similarities.calculate()\n",
    "\n",
    "zwickau_london_similarities = thesisCosineSimilarity.CrossVersionSimilarity5Gram(zwickau_corpus, london_corpus)\n",
    "zwickau_london_similarities.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0907f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_zwickau_similarities.save()\n",
    "zwickau_london_similarities.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "db2d1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_corpus_lz = dataReader.BurchardCorpus(london_corpus, zwickau_corpus)\n",
    "burchard_corpus_zl = dataReader.BurchardCorpus(zwickau_corpus, london_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "943d8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_leftovers = dataReader.LeftoversCorpus(london_corpus, zwickau_corpus)\n",
    "zwickau_leftovers = dataReader.LeftoversCorpus(zwickau_corpus, london_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fac042c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "print(len(london_leftovers.corpus_for_predictions()))\n",
    "print(len(zwickau_leftovers.corpus_for_predictions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10b946be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_p(corpus):\n",
    "    return list(filter(lambda x: len(x.split()) > 20, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "44c8ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_burchard_corpus_with_predictions(burchard_corpus, wrong_predictions_by_london, wrong_predictions_by_zwickau):\n",
    "    is_burchard = True\n",
    "    temp_corpus = [ [p, is_burchard, is_burchard] for p in burchard_corpus ]\n",
    "    \n",
    "    for prediction in wrong_predictions_by_london:\n",
    "        temp_corpus[prediction.index][1] = False\n",
    "    for prediction in wrong_predictions_by_zwickau:\n",
    "        temp_corpus[prediction.index][2] = False\n",
    "\n",
    "    return temp_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038c7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_leftofvers_long = filter_short_p(london_leftovers.corpus) # list(filter(lambda x: len(x.split()) > 20, london_leftovers.corpus))\n",
    "zwickau_leftofvers_long = filter_short_p(zwickau_leftovers.corpus) # list(filter(lambda x: len(x.split()) > 20, zwickau_leftovers.corpus))\n",
    "burchard_lz_corpus_long = filter_short_p(burchard_corpus_lz.corpus) # list(filter(lambda x: len(x.split()) > 20, burchard_corpus_lz.corpus))\n",
    "burchard_zl_corpus_long = filter_short_p(burchard_corpus_zl.corpus) # list(filter(lambda x: len(x.split()) > 20, burchard_corpus_zl.corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "850d283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london_best_result_1: 0.794069069069069\n",
      "london_best_result_2: 0.7718468468468469\n",
      "london_classifier_total_result: 0.782957957957958\n"
     ]
    }
   ],
   "source": [
    "london_best_result_1 = np.amax([i[1] for i in burchard_lz_london_greed_rearch_resp])\n",
    "print(f'london_best_result_1: {london_best_result_1}')\n",
    "\n",
    "london_best_result_2 = np.amax([i[1] for i in burchard_zl_london_greed_rearch_resp])\n",
    "print(f'london_best_result_2: {london_best_result_2}')\n",
    "\n",
    "london_classifier_total_result = (london_best_result_1 + london_best_result_2) / 2\n",
    "print(f'london_classifier_total_result: {london_classifier_total_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9875afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zwickau_best_result_1: 0.8646825396825397\n",
      "zwickau_best_result_2: 0.8326984126984126\n",
      "zwickau_classifier_total_result: 0.8486904761904761\n"
     ]
    }
   ],
   "source": [
    "zwickau_best_result_1 = np.amax([i[1] for i in burchard_lz_zwickau_greed_rearch_resp])\n",
    "print(f'zwickau_best_result_1: {zwickau_best_result_1}')\n",
    "\n",
    "zwickau_best_result_2 = np.amax([i[1] for i in burchard_zl_zwickau_greed_rearch_resp])\n",
    "print(f'zwickau_best_result_2: {zwickau_best_result_2}')\n",
    "\n",
    "zwickau_classifier_total_result = (zwickau_best_result_1 + zwickau_best_result_2) / 2\n",
    "print(f'zwickau_classifier_total_result: {zwickau_classifier_total_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0b4c5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to classifier ability to distinguish between 2 version, version candidate to be closer to burchard is: london\n"
     ]
    }
   ],
   "source": [
    "more_original_version = 'not found'\n",
    "if london_classifier_total_result < zwickau_classifier_total_result: more_original_version = 'london'\n",
    "elif zwickau_classifier_total_result < london_classifier_total_result: more_original_version = 'zwickau'\n",
    "\n",
    "print(f'Due to classifier ability to distinguish between 2 version, version candidate to be closer to burchard is: {more_original_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_lz_zwickau_features_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    burchard_lz_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")\n",
    "burchard_zl_zwickau_features_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    burchard_zl_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")\n",
    "burchard_lz_london_features_df = thesisModelFeatures.create_features_df(\n",
    "    london_leftofvers_long,\n",
    "    None,\n",
    "    burchard_lz_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")\n",
    "burchard_zl_london_features_df = thesisModelFeatures.create_features_df(\n",
    "    london_leftofvers_long,\n",
    "    None,\n",
    "    burchard_zl_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "69285f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is: 0.8055555555555556\n",
      "score is: 0.8888888888888888\n",
      "score is: 0.8888888888888888\n",
      "score is: 0.7777777777777778\n",
      "score is: 0.8571428571428571\n",
      "score is: 0.8571428571428571\n",
      "score is: 0.8571428571428571\n",
      "score is: 0.9142857142857143\n",
      "score is: 0.9142857142857143\n",
      "score is: 0.8857142857142857\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_zwickau_wrong_predictions_experiment = thesisModelFeatures.GetModelStratifiedKFoldWrongPredictionExperiment(\n",
    "    burchard_lz_zwickau_features_df, \n",
    "    AdaBoostClassifier(learning_rate=1, n_estimators=2000)\n",
    ")\n",
    "burchard_lz_zwickau_wrong_predictions_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a1420bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is: 0.8055555555555556\n",
      "score is: 0.9444444444444444\n",
      "score is: 0.8055555555555556\n",
      "score is: 0.7714285714285715\n",
      "score is: 0.8285714285714286\n",
      "score is: 0.8\n",
      "score is: 0.8\n",
      "score is: 0.8857142857142857\n",
      "score is: 0.8\n",
      "score is: 0.8857142857142857\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_zwickau_wrong_predictions_experiment = thesisModelFeatures.GetModelStratifiedKFoldWrongPredictionExperiment(\n",
    "    burchard_zl_zwickau_features_df, \n",
    "    AdaBoostClassifier(learning_rate=1, n_estimators=2000)\n",
    ")\n",
    "burchard_zl_zwickau_wrong_predictions_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6bb38ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is: 0.8918918918918919\n",
      "score is: 0.7567567567567568\n",
      "score is: 0.7837837837837838\n",
      "score is: 0.8378378378378378\n",
      "score is: 0.8648648648648649\n",
      "score is: 0.75\n",
      "score is: 0.8611111111111112\n",
      "score is: 0.75\n",
      "score is: 0.6944444444444444\n",
      "score is: 0.75\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_london_wrong_predictions_experiment = thesisModelFeatures.GetModelStratifiedKFoldWrongPredictionExperiment(\n",
    "    burchard_lz_london_features_df, \n",
    "    xgb.XGBClassifier(gamma = 0.4, max_depth = 9, min_child_weight = 3)\n",
    ")\n",
    "burchard_lz_london_wrong_predictions_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "03856ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is: 0.8378378378378378\n",
      "score is: 0.8108108108108109\n",
      "score is: 0.7027027027027027\n",
      "score is: 0.7837837837837838\n",
      "score is: 0.8333333333333334\n",
      "score is: 0.6666666666666666\n",
      "score is: 0.8611111111111112\n",
      "score is: 0.7777777777777778\n",
      "score is: 0.6944444444444444\n",
      "score is: 0.75\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_london_wrong_predictions_experiment = thesisModelFeatures.GetModelStratifiedKFoldWrongPredictionExperiment(\n",
    "    burchard_zl_london_features_df, \n",
    "    RandomForestClassifier(criterion = \"entropy\" , max_depth=12, n_estimators=200, random_state=0)\n",
    ")\n",
    "burchard_zl_london_wrong_predictions_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1dbb63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_corpus_lz_truly_predicted = burchard_corpus_lz.get_burchard_predicted_truly(\n",
    "    burchard_lz_london_wrong_predictions_experiment.get_burchard_wrong_predictions(),\n",
    "    burchard_lz_london_wrong_predictions_experiment.get_burchard_wrong_predictions()\n",
    ")\n",
    "burchard_corpus_zl_truly_predicted = burchard_corpus_zl.get_burchard_predicted_truly(\n",
    "    burchard_lz_london_wrong_predictions_experiment.get_burchard_wrong_predictions(),\n",
    "    burchard_lz_london_wrong_predictions_experiment.get_burchard_wrong_predictions()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ada89",
   "metadata": {},
   "source": [
    "##### burchard paragraphs that was identify as burchard from london and zwickau side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "58e1fb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 128, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truly_predicted_from_both_sides = []\n",
    "for i in burchard_corpus_lz_truly_predicted:\n",
    "    predicted_from_another_side = any(x for x in burchard_corpus_zl_truly_predicted if x['index'] == i['index'])\n",
    "    if predicted_from_another_side: truly_predicted_from_both_sides.append(i['index'])\n",
    "print(truly_predicted_from_both_sides)\n",
    "len(truly_predicted_from_both_sides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740047d",
   "metadata": {},
   "source": [
    "##### london leftovers predicted as burchard from london and zwickau side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "470daffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 18, 20, 28, 35, 42, 43, 44, 52, 54, 58, 65, 76, 77, 82, 84, 85, 88, 93, 107, 113, 114, 116, 119, 121, 122, 123, 127, 130, 131, 132, 133, 137, 141, 142, 145, 147, 149, 152, 154, 155]\n"
     ]
    }
   ],
   "source": [
    "print([i['index'] for i in london_leftovers.leftovers_predicted_falsy(\n",
    "    burchard_lz_london_wrong_predictions_experiment.get_london_wrong_predictions(),\n",
    "    burchard_zl_london_wrong_predictions_experiment.get_london_wrong_predictions()\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: we can run zwickau_burcrhard classifier on london texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954c7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc82b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b269f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best models\n",
    "# run models predictions on 2 burchard candidate version\n",
    "# from results of predictions make assumption of real burchard\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84804e8d",
   "metadata": {},
   "source": [
    "# zwickau burchard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d6e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_zwickau_features_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    burchard_lz_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc61d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_zwickau_result = thesisModelFeatures.run_models(\n",
    "    burchard_lz_zwickau_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78e9a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       " SVM_linear                        0.293810      0.500000  0.370096  0.587619   \n",
       " SVM_RBF                           0.747899      0.649048  0.634857  0.700476   \n",
       " DecisionTreeClassifier            0.712525      0.711667  0.707613  0.715238   \n",
       " GaussianProcessClassifier         0.710851      0.687262  0.687785  0.706429   \n",
       " RandomForestClassifier            0.744441      0.707024  0.709057  0.734444   \n",
       " MLPClassifier                     0.712422      0.685952  0.686963  0.703730   \n",
       " GaussianNB                        0.628596      0.529167  0.466058  0.599206   \n",
       " KNeighborsClassifier              0.698802      0.549881  0.482861  0.624206   \n",
       " AdaBoostClassifier                0.805553      0.793690  0.796080  0.805079   \n",
       " XGBClassifier                     0.825755      0.812143  0.815890  0.825317   \n",
       " \n",
       "                            f1_weighted  accuracy  \n",
       " SVM_linear                    0.435047  0.587619  \n",
       " SVM_RBF                       0.661740  0.700476  \n",
       " DecisionTreeClassifier        0.714894  0.715238  \n",
       " GaussianProcessClassifier     0.700188  0.706429  \n",
       " RandomForestClassifier        0.723394  0.734444  \n",
       " MLPClassifier                 0.698473  0.703730  \n",
       " GaussianNB                    0.512433  0.599206  \n",
       " KNeighborsClassifier          0.530702  0.624206  \n",
       " AdaBoostClassifier            0.803349  0.805079  \n",
       " XGBClassifier                 0.822931  0.825317  ,\n",
       " [{'fit_time': array([6.73721099, 6.75308323, 5.09024286, 8.29933071, 6.42180014,\n",
       "          5.7917459 , 5.01456428, 4.87041497, 4.92713499, 5.15070295]),\n",
       "   'score_time': array([0.83462381, 0.65968108, 0.66562605, 0.82860518, 0.71915007,\n",
       "          0.67758393, 0.67308378, 0.6713109 , 0.68647814, 0.70973229]),\n",
       "   'test_precision_macro': array([0.29166667, 0.29166667, 0.29166667, 0.29166667, 0.28571429,\n",
       "          0.28571429, 0.3       , 0.3       , 0.3       , 0.3       ]),\n",
       "   'test_recall_macro': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "   'test_f1_macro': array([0.36842105, 0.36842105, 0.36842105, 0.36842105, 0.36363636,\n",
       "          0.36363636, 0.375     , 0.375     , 0.375     , 0.375     ]),\n",
       "   'test_f1_micro': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ]),\n",
       "   'test_f1_weighted': array([0.42982456, 0.42982456, 0.42982456, 0.42982456, 0.41558442,\n",
       "          0.41558442, 0.45      , 0.45      , 0.45      , 0.45      ]),\n",
       "   'test_accuracy': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ])},\n",
       "  {'fit_time': array([5.50178909, 5.35396791, 5.40202498, 5.47111702, 5.59311891,\n",
       "          5.57697296, 5.46829987, 5.44393229, 5.462219  , 5.97571898]),\n",
       "   'score_time': array([1.03556514, 1.02697396, 1.01403022, 1.02307296, 0.99048328,\n",
       "          1.07733607, 0.99184418, 0.99769592, 0.98782206, 1.000314  ]),\n",
       "   'test_precision_macro': array([0.77339901, 0.79464286, 0.79464286, 0.63636364, 0.62731481,\n",
       "          0.74425287, 0.66091954, 0.7542735 , 0.81818182, 0.875     ]),\n",
       "   'test_recall_macro': array([0.67619048, 0.70952381, 0.70952381, 0.54285714, 0.59166667,\n",
       "          0.64166667, 0.5952381 , 0.70238095, 0.57142857, 0.75      ]),\n",
       "   'test_f1_macro': array([0.67272727, 0.71251109, 0.71251109, 0.48148148, 0.57909343,\n",
       "          0.62585034, 0.58      , 0.70860315, 0.51388889, 0.76190476]),\n",
       "   'test_f1_micro': array([0.72222222, 0.75      , 0.75      , 0.61111111, 0.62857143,\n",
       "          0.68571429, 0.65714286, 0.74285714, 0.65714286, 0.8       ]),\n",
       "   'test_f1_weighted': array([0.69393939, 0.72981366, 0.72981366, 0.52469136, 0.59970926,\n",
       "          0.64723032, 0.616     , 0.72858464, 0.56666667, 0.78095238]),\n",
       "   'test_accuracy': array([0.72222222, 0.75      , 0.75      , 0.61111111, 0.62857143,\n",
       "          0.68571429, 0.65714286, 0.74285714, 0.65714286, 0.8       ])},\n",
       "  {'fit_time': array([0.49505496, 0.62799621, 0.49395013, 0.44946003, 0.63612914,\n",
       "          0.6312089 , 0.60023808, 0.49779105, 0.62957835, 0.64928818]),\n",
       "   'score_time': array([0.15727615, 0.15374899, 0.15464997, 0.15710902, 0.155334  ,\n",
       "          0.15398598, 0.15399289, 0.15345097, 0.15524673, 0.15367103]),\n",
       "   'test_precision_macro': array([0.62662338, 0.65      , 0.6875    , 0.6875    , 0.70833333,\n",
       "          0.67857143, 0.71732026, 0.71732026, 0.82971014, 0.82236842]),\n",
       "   'test_recall_macro': array([0.62380952, 0.65238095, 0.67142857, 0.69047619, 0.70833333,\n",
       "          0.675     , 0.72619048, 0.72619048, 0.80952381, 0.83333333]),\n",
       "   'test_f1_macro': array([0.62469928, 0.63861004, 0.67407407, 0.6884343 , 0.70833333,\n",
       "          0.67619849, 0.71217105, 0.71217105, 0.81643357, 0.825     ]),\n",
       "   'test_f1_micro': array([0.63888889, 0.63888889, 0.69444444, 0.69444444, 0.71428571,\n",
       "          0.68571429, 0.71428571, 0.71428571, 0.82857143, 0.82857143]),\n",
       "   'test_f1_weighted': array([0.6368618 , 0.64028314, 0.68765432, 0.69564647, 0.71428571,\n",
       "          0.68412832, 0.71710526, 0.71710526, 0.82587413, 0.83      ]),\n",
       "   'test_accuracy': array([0.63888889, 0.63888889, 0.69444444, 0.69444444, 0.71428571,\n",
       "          0.68571429, 0.71428571, 0.71428571, 0.82857143, 0.82857143])},\n",
       "  {'fit_time': array([29.34931087, 29.38121486, 29.31713414, 29.38309312, 29.51274514,\n",
       "          29.51356816, 29.45293522, 29.47301507, 27.17317915, 28.05560017]),\n",
       "   'score_time': array([0.69323802, 0.69502997, 0.69162488, 0.69220591, 0.68499804,\n",
       "          0.6827867 , 0.68102574, 0.67863894, 0.68032694, 0.70140076]),\n",
       "   'test_precision_macro': array([0.74350649, 0.77142857, 0.65714286, 0.52727273, 0.59803922,\n",
       "          0.6486014 , 0.76630435, 0.675     , 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.73809524, 0.77142857, 0.65714286, 0.52380952, 0.6       ,\n",
       "          0.64166667, 0.75      , 0.67857143, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.74017642, 0.77142857, 0.65714286, 0.51839465, 0.59703947,\n",
       "          0.64285714, 0.75524476, 0.67619849, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.75      , 0.77777778, 0.66666667, 0.55555556, 0.6       ,\n",
       "          0.65714286, 0.77142857, 0.68571429, 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.74859663, 0.77777778, 0.66666667, 0.54069119, 0.60197368,\n",
       "          0.65306122, 0.76783217, 0.68730025, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.75      , 0.77777778, 0.66666667, 0.55555556, 0.6       ,\n",
       "          0.65714286, 0.77142857, 0.68571429, 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.62563992, 0.52152205, 0.52041173, 0.51832104, 0.51735306,\n",
       "          0.532161  , 0.51612282, 0.53801632, 0.51986003, 0.52445698]),\n",
       "   'score_time': array([0.16173697, 0.1618731 , 0.16726398, 0.15892982, 0.15984011,\n",
       "          0.16067505, 0.16027904, 0.15922093, 0.16217208, 0.16054893]),\n",
       "   'test_precision_macro': array([0.78909091, 0.77591973, 0.68506494, 0.71428571, 0.69      ,\n",
       "          0.62      , 0.675     , 0.82971014, 0.76149425, 0.90384615]),\n",
       "   'test_recall_macro': array([0.75238095, 0.76190476, 0.68095238, 0.65238095, 0.65833333,\n",
       "          0.6       , 0.67857143, 0.80952381, 0.6547619 , 0.82142857]),\n",
       "   'test_f1_macro': array([0.75919732, 0.76623377, 0.68243785, 0.64862467, 0.65777778,\n",
       "          0.59555556, 0.67619849, 0.81643357, 0.65      , 0.83811286]),\n",
       "   'test_f1_micro': array([0.77777778, 0.77777778, 0.69444444, 0.69444444, 0.68571429,\n",
       "          0.62857143, 0.68571429, 0.82857143, 0.71428571, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.7703456 , 0.77489177, 0.69272922, 0.66977226, 0.67174603,\n",
       "          0.61206349, 0.68730025, 0.82587413, 0.68      , 0.84921369]),\n",
       "   'test_accuracy': array([0.77777778, 0.77777778, 0.69444444, 0.69444444, 0.68571429,\n",
       "          0.62857143, 0.68571429, 0.82857143, 0.71428571, 0.85714286])},\n",
       "  {'fit_time': array([ 98.58367515,  95.00215912,  77.04335737, 100.2287221 ,\n",
       "           81.35309005,  95.49278903, 104.32991219,  96.3588531 ,\n",
       "           99.19093919,  74.78671098]),\n",
       "   'score_time': array([0.21103382, 0.23968673, 0.21811676, 0.21398568, 0.20919299,\n",
       "          0.20078373, 0.21686101, 0.21325612, 0.20280766, 0.20976591]),\n",
       "   'test_precision_macro': array([0.78909091, 0.74375   , 0.60681115, 0.54285714, 0.59803922,\n",
       "          0.68115942, 0.76630435, 0.675     , 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.75238095, 0.74761905, 0.60952381, 0.54285714, 0.6       ,\n",
       "          0.66666667, 0.75      , 0.67857143, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.75919732, 0.74508261, 0.60625   , 0.54285714, 0.59703947,\n",
       "          0.66838932, 0.75524476, 0.67619849, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.77777778, 0.75      , 0.61111111, 0.55555556, 0.6       ,\n",
       "          0.68571429, 0.77142857, 0.68571429, 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.7703456 , 0.75098348, 0.61354167, 0.55555556, 0.60197368,\n",
       "          0.67921742, 0.76783217, 0.68730025, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.77777778, 0.75      , 0.61111111, 0.55555556, 0.6       ,\n",
       "          0.68571429, 0.77142857, 0.68571429, 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.35785103, 0.25175714, 0.24424314, 0.24538398, 0.31775379,\n",
       "          0.24523807, 0.24261522, 0.24380016, 0.24515891, 0.24202704]),\n",
       "   'score_time': array([0.18475008, 0.16623998, 0.16518784, 0.165874  , 0.16592789,\n",
       "          0.16482091, 0.16598082, 0.16522789, 0.16523194, 0.16681075]),\n",
       "   'test_precision_macro': array([0.54411765, 0.8       , 0.46181818, 0.54411765, 0.68145161,\n",
       "          0.8030303 , 0.61666667, 0.5530303 , 0.81818182, 0.46354167]),\n",
       "   'test_recall_macro': array([0.50952381, 0.53333333, 0.46666667, 0.50952381, 0.575     ,\n",
       "          0.56666667, 0.55952381, 0.51190476, 0.57142857, 0.48809524]),\n",
       "   'test_f1_macro': array([0.42245989, 0.4375    , 0.45819398, 0.42245989, 0.53044376,\n",
       "          0.49500555, 0.53044376, 0.43287037, 0.51388889, 0.4173141 ]),\n",
       "   'test_f1_micro': array([0.58333333, 0.61111111, 0.5       , 0.58333333, 0.62857143,\n",
       "          0.62857143, 0.62857143, 0.6       , 0.65714286, 0.57142857]),\n",
       "   'test_f1_weighted': array([0.47326203, 0.48958333, 0.48327759, 0.47326203, 0.56110865,\n",
       "          0.53210718, 0.57337461, 0.49444444, 0.56666667, 0.4772475 ]),\n",
       "   'test_accuracy': array([0.58333333, 0.61111111, 0.5       , 0.58333333, 0.62857143,\n",
       "          0.62857143, 0.62857143, 0.6       , 0.65714286, 0.57142857])},\n",
       "  {'fit_time': array([0.16924   , 0.1711669 , 0.17581296, 0.17024493, 0.17159128,\n",
       "          0.17644811, 0.17705989, 0.17384672, 0.17238688, 0.17145491]),\n",
       "   'score_time': array([0.23273611, 0.26956797, 0.24135017, 0.27134109, 0.26253891,\n",
       "          0.28145099, 0.27184677, 0.27246618, 0.26438713, 0.25954485]),\n",
       "   'test_precision_macro': array([0.80882353, 0.54411765, 0.828125  , 0.8       , 0.64367816,\n",
       "          0.63020833, 0.5530303 , 0.5530303 , 0.80882353, 0.81818182]),\n",
       "   'test_recall_macro': array([0.56666667, 0.50952381, 0.63333333, 0.53333333, 0.58333333,\n",
       "          0.54166667, 0.51190476, 0.51190476, 0.53571429, 0.57142857]),\n",
       "   'test_f1_macro': array([0.49946524, 0.42245989, 0.60675273, 0.4375    , 0.55782313,\n",
       "          0.47649573, 0.43287037, 0.43287037, 0.44848485, 0.51388889]),\n",
       "   'test_f1_micro': array([0.63888889, 0.58333333, 0.69444444, 0.61111111, 0.62857143,\n",
       "          0.6       , 0.6       , 0.6       , 0.62857143, 0.65714286]),\n",
       "   'test_f1_weighted': array([0.54349376, 0.47326203, 0.63770275, 0.48958333, 0.58309038,\n",
       "          0.51282051, 0.49444444, 0.49444444, 0.51151515, 0.56666667]),\n",
       "   'test_accuracy': array([0.63888889, 0.58333333, 0.69444444, 0.61111111, 0.62857143,\n",
       "          0.6       , 0.6       , 0.6       , 0.62857143, 0.65714286])},\n",
       "  {'fit_time': array([3.83346295, 3.84931207, 3.83596992, 3.8448801 , 3.87045002,\n",
       "          3.86228299, 3.88861299, 3.88752007, 3.76662302, 3.79043603]),\n",
       "   'score_time': array([0.21628189, 0.21296477, 0.21227384, 0.21412683, 0.21201491,\n",
       "          0.21371174, 0.21029305, 0.21135712, 0.21067905, 0.21132803]),\n",
       "   'test_precision_macro': array([0.80194805, 0.8       , 0.8361204 , 0.77591973, 0.73848684,\n",
       "          0.79605263, 0.82971014, 0.82236842, 0.80492424, 0.85      ]),\n",
       "   'test_recall_macro': array([0.7952381 , 0.8047619 , 0.81904762, 0.76190476, 0.74166667,\n",
       "          0.8       , 0.80952381, 0.83333333, 0.77380952, 0.79761905]),\n",
       "   'test_f1_macro': array([0.797915  , 0.80173092, 0.82467532, 0.76623377, 0.73945409,\n",
       "          0.79735318, 0.81643357, 0.825     , 0.78222222, 0.80978261]),\n",
       "   'test_f1_micro': array([0.80555556, 0.80555556, 0.83333333, 0.77777778, 0.74285714,\n",
       "          0.8       , 0.82857143, 0.82857143, 0.8       , 0.82857143]),\n",
       "   'test_f1_weighted': array([0.80446405, 0.80632048, 0.83116883, 0.77489177, 0.7437079 ,\n",
       "          0.8006617 , 0.82587413, 0.83      , 0.79466667, 0.82173913]),\n",
       "   'test_accuracy': array([0.80555556, 0.80555556, 0.83333333, 0.77777778, 0.74285714,\n",
       "          0.8       , 0.82857143, 0.82857143, 0.8       , 0.82857143])},\n",
       "  {'fit_time': array([11.47759891, 11.77786875, 11.17946219, 11.00999594, 11.16229415,\n",
       "          11.05001283, 11.18581891, 11.47982693, 11.27713084, 11.15276003]),\n",
       "   'score_time': array([0.488662  , 0.46455407, 0.46307182, 0.46003509, 0.44324303,\n",
       "          0.44199109, 0.44367623, 0.44246984, 0.44782329, 0.44769907]),\n",
       "   'test_precision_macro': array([0.77591973, 0.86038961, 0.8361204 , 0.65551839, 0.77097902,\n",
       "          0.77097902, 0.8548951 , 0.91608392, 0.85      , 0.96666667]),\n",
       "   'test_recall_macro': array([0.76190476, 0.85238095, 0.81904762, 0.64761905, 0.75833333,\n",
       "          0.75833333, 0.8452381 , 0.9047619 , 0.79761905, 0.97619048]),\n",
       "   'test_f1_macro': array([0.76623377, 0.85565357, 0.82467532, 0.64935065, 0.76190476,\n",
       "          0.76190476, 0.84926787, 0.90956072, 0.80978261, 0.9705635 ]),\n",
       "   'test_f1_micro': array([0.77777778, 0.86111111, 0.83333333, 0.66666667, 0.77142857,\n",
       "          0.77142857, 0.85714286, 0.91428571, 0.82857143, 0.97142857]),\n",
       "   'test_f1_weighted': array([0.77489177, 0.86033146, 0.83116883, 0.66233766, 0.76870748,\n",
       "          0.76870748, 0.85615848, 0.91369509, 0.82173913, 0.97157275]),\n",
       "   'test_accuracy': array([0.77777778, 0.86111111, 0.83333333, 0.66666667, 0.77142857,\n",
       "          0.77142857, 0.85714286, 0.91428571, 0.82857143, 0.97142857])}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_lz_zwickau_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8bcefcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.293810</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.370096</td>\n",
       "      <td>0.587619</td>\n",
       "      <td>0.435047</td>\n",
       "      <td>0.587619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.649048</td>\n",
       "      <td>0.634857</td>\n",
       "      <td>0.700476</td>\n",
       "      <td>0.661740</td>\n",
       "      <td>0.700476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.712525</td>\n",
       "      <td>0.711667</td>\n",
       "      <td>0.707613</td>\n",
       "      <td>0.715238</td>\n",
       "      <td>0.714894</td>\n",
       "      <td>0.715238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.710851</td>\n",
       "      <td>0.687262</td>\n",
       "      <td>0.687785</td>\n",
       "      <td>0.706429</td>\n",
       "      <td>0.700188</td>\n",
       "      <td>0.706429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.744441</td>\n",
       "      <td>0.707024</td>\n",
       "      <td>0.709057</td>\n",
       "      <td>0.734444</td>\n",
       "      <td>0.723394</td>\n",
       "      <td>0.734444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.712422</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.686963</td>\n",
       "      <td>0.703730</td>\n",
       "      <td>0.698473</td>\n",
       "      <td>0.703730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.628596</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>0.466058</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.512433</td>\n",
       "      <td>0.599206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.698802</td>\n",
       "      <td>0.549881</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.624206</td>\n",
       "      <td>0.530702</td>\n",
       "      <td>0.624206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.805553</td>\n",
       "      <td>0.793690</td>\n",
       "      <td>0.796080</td>\n",
       "      <td>0.805079</td>\n",
       "      <td>0.803349</td>\n",
       "      <td>0.805079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.825755</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.815890</td>\n",
       "      <td>0.825317</td>\n",
       "      <td>0.822931</td>\n",
       "      <td>0.825317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "SVM_linear                        0.293810      0.500000  0.370096  0.587619   \n",
       "SVM_RBF                           0.747899      0.649048  0.634857  0.700476   \n",
       "DecisionTreeClassifier            0.712525      0.711667  0.707613  0.715238   \n",
       "GaussianProcessClassifier         0.710851      0.687262  0.687785  0.706429   \n",
       "RandomForestClassifier            0.744441      0.707024  0.709057  0.734444   \n",
       "MLPClassifier                     0.712422      0.685952  0.686963  0.703730   \n",
       "GaussianNB                        0.628596      0.529167  0.466058  0.599206   \n",
       "KNeighborsClassifier              0.698802      0.549881  0.482861  0.624206   \n",
       "AdaBoostClassifier                0.805553      0.793690  0.796080  0.805079   \n",
       "XGBClassifier                     0.825755      0.812143  0.815890  0.825317   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "SVM_linear                    0.435047  0.587619  \n",
       "SVM_RBF                       0.661740  0.700476  \n",
       "DecisionTreeClassifier        0.714894  0.715238  \n",
       "GaussianProcessClassifier     0.700188  0.706429  \n",
       "RandomForestClassifier        0.723394  0.734444  \n",
       "MLPClassifier                 0.698473  0.703730  \n",
       "GaussianNB                    0.512433  0.599206  \n",
       "KNeighborsClassifier          0.530702  0.624206  \n",
       "AdaBoostClassifier            0.803349  0.805079  \n",
       "XGBClassifier                 0.822931  0.825317  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_lz_zwickau_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a93166ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.7262698412698413\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7492857142857142\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7064285714285714\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.74007937 0.72873016 0.73142857 0.72857143 0.73142857 0.73714286\n",
      " 0.72865079 0.74563492 0.74007937 0.72873016 0.73142857 0.72857143\n",
      " 0.73142857 0.73714286 0.72865079 0.74563492 0.59063492 0.59047619\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.74       0.73436508 0.7315873  0.72587302 0.7315873  0.74293651\n",
      " 0.74277778 0.74293651 0.74       0.73436508 0.7315873  0.72587302\n",
      " 0.7315873  0.74293651 0.74277778 0.74293651 0.60761905 0.59912698\n",
      " 0.59055556 0.58769841 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.73150794 0.73436508 0.74015873 0.74015873 0.72880952 0.7402381\n",
      " 0.72031746 0.73444444 0.73150794 0.73436508 0.74015873 0.74015873\n",
      " 0.72880952 0.7402381  0.72031746 0.73444444 0.62444444 0.6018254\n",
      " 0.59619048 0.58761905 0.59047619 0.58769841 0.58761905 0.59047619\n",
      " 0.72031746 0.71174603 0.72603175 0.74015873 0.73150794 0.73444444\n",
      " 0.72880952 0.73722222 0.72031746 0.71174603 0.72603175 0.74015873\n",
      " 0.73150794 0.73444444 0.72880952 0.73722222 0.63015873 0.61880952\n",
      " 0.61031746 0.6018254  0.60460317 0.59611111 0.59888889 0.60166667\n",
      " 0.73714286 0.7231746  0.72587302 0.72865079 0.7315873  0.7315873\n",
      " 0.7315873  0.72611111 0.73714286 0.7231746  0.72587302 0.72865079\n",
      " 0.7315873  0.7315873  0.7315873  0.72611111 0.64428571 0.63293651\n",
      " 0.62738095 0.6215873  0.61309524 0.61309524 0.61015873 0.61301587\n",
      " 0.73166667 0.72309524 0.73452381 0.72873016 0.7202381  0.72873016\n",
      " 0.74285714 0.74579365 0.73166667 0.72309524 0.73452381 0.72873016\n",
      " 0.7202381  0.72873016 0.74285714 0.74579365 0.62730159 0.63007937\n",
      " 0.6384127  0.63       0.62992063 0.61865079 0.61849206 0.62412698\n",
      " 0.70611111 0.72015873 0.71714286 0.72579365 0.72579365 0.7315873\n",
      " 0.73738095 0.7402381  0.70611111 0.72015873 0.71714286 0.72579365\n",
      " 0.72579365 0.7315873  0.73738095 0.7402381  0.63619048 0.6415873\n",
      " 0.63       0.63007937 0.62722222 0.62714286 0.63277778 0.62714286\n",
      " 0.72015873 0.72293651 0.72857143 0.73722222 0.7315873  0.73452381\n",
      " 0.73460317 0.73174603 0.72015873 0.72293651 0.72857143 0.73722222\n",
      " 0.7315873  0.73452381 0.73460317 0.73174603 0.65555556 0.65833333\n",
      " 0.63285714 0.63293651 0.63563492 0.63555556 0.63261905 0.63833333\n",
      " 0.7231746  0.72285714 0.73150794 0.74007937 0.74285714 0.72880952\n",
      " 0.72896825 0.73174603 0.7231746  0.72285714 0.73150794 0.74007937\n",
      " 0.74285714 0.72880952 0.72896825 0.73174603 0.63293651 0.6552381\n",
      " 0.64126984 0.63833333 0.63547619 0.64412698 0.64968254 0.64126984\n",
      " 0.72579365 0.7231746  0.74       0.73706349 0.74277778 0.74\n",
      " 0.74849206 0.75126984 0.72579365 0.7231746  0.74       0.73706349\n",
      " 0.74277778 0.74       0.74849206 0.75126984 0.59904762 0.58761905\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.74865079 0.73436508 0.73706349 0.73134921 0.73134921 0.73134921\n",
      " 0.73992063 0.74285714 0.74865079 0.73436508 0.73706349 0.73134921\n",
      " 0.73134921 0.73134921 0.73992063 0.74285714 0.59896825 0.59325397\n",
      " 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905 0.58761905\n",
      " 0.73444444 0.73150794 0.74563492 0.73714286 0.72865079 0.73722222\n",
      " 0.73436508 0.73722222 0.73444444 0.73150794 0.74563492 0.73714286\n",
      " 0.72865079 0.73722222 0.73436508 0.73722222 0.61293651 0.59619048\n",
      " 0.59047619 0.59047619 0.59047619 0.58761905 0.58761905 0.58761905\n",
      " 0.72896825 0.73730159 0.72873016 0.73436508 0.73714286 0.73714286\n",
      " 0.72865079 0.73428571 0.72896825 0.73730159 0.72873016 0.73436508\n",
      " 0.73714286 0.73714286 0.72865079 0.73428571 0.63       0.61587302\n",
      " 0.60444444 0.59896825 0.59896825 0.59611111 0.5931746  0.59039683\n",
      " 0.72880952 0.71730159 0.7315873  0.72865079 0.74007937 0.74\n",
      " 0.73428571 0.7315873  0.72880952 0.71730159 0.7315873  0.72865079\n",
      " 0.74007937 0.74       0.73428571 0.7315873  0.64388889 0.61857143\n",
      " 0.60730159 0.61015873 0.6102381  0.61015873 0.60444444 0.60452381\n",
      " 0.74309524 0.73714286 0.74277778 0.73436508 0.74293651 0.74301587\n",
      " 0.73436508 0.74015873 0.74309524 0.73714286 0.74277778 0.73436508\n",
      " 0.74293651 0.74301587 0.73436508 0.74015873 0.63571429 0.62992063\n",
      " 0.62714286 0.62420635 0.62714286 0.62150794 0.62142857 0.61865079\n",
      " 0.71190476 0.73444444 0.73142857 0.73436508 0.73730159 0.74015873\n",
      " 0.73722222 0.74579365 0.71190476 0.73444444 0.73142857 0.73436508\n",
      " 0.73730159 0.74015873 0.73722222 0.74579365 0.66952381 0.64968254\n",
      " 0.63277778 0.63571429 0.63571429 0.63007937 0.63007937 0.62444444\n",
      " 0.73436508 0.74587302 0.76563492 0.75420635 0.74849206 0.74571429\n",
      " 0.74579365 0.74293651 0.73436508 0.74587302 0.76563492 0.75420635\n",
      " 0.74849206 0.74571429 0.74579365 0.74293651 0.62730159 0.63849206\n",
      " 0.63277778 0.64126984 0.64119048 0.63277778 0.64412698 0.63\n",
      " 0.73436508 0.73730159 0.75706349 0.76261905 0.75992063 0.75428571\n",
      " 0.75134921 0.74571429 0.73436508 0.73730159 0.75706349 0.76261905\n",
      " 0.75992063 0.75428571 0.75134921 0.74571429 0.63857143 0.64420635\n",
      " 0.64698413 0.65269841 0.65261905 0.64698413 0.65246032 0.65539683\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.89829952 0.90866801 0.91086729 0.91651387 0.91839869 0.91839869\n",
      " 0.91746318 0.91714576 0.89829952 0.90866801 0.91086729 0.91651387\n",
      " 0.91839869 0.91839869 0.91746318 0.91714576 0.6691607  0.62899391\n",
      " 0.61173281 0.6045149  0.60011928 0.59509966 0.59353325 0.59133889\n",
      " 0.95009661 0.96485085 0.9683011  0.97238619 0.97552887 0.97709331\n",
      " 0.97803375 0.97615386 0.95009661 0.96485085 0.9683011  0.97238619\n",
      " 0.97552887 0.97709331 0.97803375 0.97615386 0.73758404 0.70463418\n",
      " 0.68894344 0.66916662 0.66194574 0.65285188 0.65191637 0.64595532\n",
      " 0.97834428 0.99027227 0.99372351 0.99560537 0.99591984 0.99780269\n",
      " 0.99748921 0.99748921 0.97834428 0.99027227 0.99372351 0.99560537\n",
      " 0.99591984 0.99780269 0.99748921 0.99748921 0.80507581 0.79347607\n",
      " 0.78530195 0.77337296 0.76427022 0.75987461 0.75989038 0.75235504\n",
      " 0.99121173 0.99811616 0.99937107 1.         0.99968553 1.\n",
      " 1.         1.         0.99121173 0.99811616 0.99937107 1.\n",
      " 0.99968553 1.         1.         1.         0.86596873 0.87162812\n",
      " 0.86723152 0.85686599 0.86377142 0.86283393 0.86065239 0.85562785\n",
      " 0.99623627 1.         0.99937107 1.         1.         1.\n",
      " 1.         1.         0.99623627 1.         0.99937107 1.\n",
      " 1.         1.         1.         1.         0.903329   0.92436663\n",
      " 0.92718894 0.92969973 0.9322125  0.93848899 0.93849688 0.93598608\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.93910708 0.95448434\n",
      " 0.95888291 0.9645354  0.97332564 0.97364011 0.97772422 0.97960805\n",
      " 0.99937205 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99937205 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96390745 0.98274285\n",
      " 0.98179649 0.98587863 0.99058773 0.9912137  0.99215611 0.99215611\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97207468 0.98775951\n",
      " 0.99466395 0.99654877 0.99686126 0.99686225 0.99811715 0.99843063\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98274088 0.99560734\n",
      " 0.99780367 0.99811814 0.99905956 0.99937205 0.99937304 0.99905759\n",
      " 0.89329272 0.89769031 0.89800576 0.90145798 0.90428028 0.90490527\n",
      " 0.90679009 0.9052148  0.89329272 0.89769031 0.89800576 0.90145798\n",
      " 0.90428028 0.90490527 0.90679009 0.9052148  0.65126871 0.61737939\n",
      " 0.60294454 0.59541216 0.59102147 0.59008103 0.58945506 0.58914158\n",
      " 0.93598017 0.95292581 0.9573234  0.95669447 0.96203052 0.962968\n",
      " 0.9661097  0.96516827 0.93598017 0.95292581 0.9573234  0.95669447\n",
      " 0.96203052 0.962968   0.9661097  0.96516827 0.71309418 0.68297944\n",
      " 0.65629522 0.63777331 0.6321287  0.63087281 0.62836793 0.61926914\n",
      " 0.97018592 0.98587863 0.98933085 0.99121468 0.9912137  0.99027326\n",
      " 0.99278405 0.993412   0.97018592 0.98587863 0.98933085 0.99121468\n",
      " 0.9912137  0.99027326 0.99278405 0.993412   0.77524398 0.76647148\n",
      " 0.7441819  0.72628103 0.72189823 0.72221171 0.72221565 0.71688551\n",
      " 0.98807594 0.9971777  0.99811814 0.99905956 0.99905858 0.99968652\n",
      " 0.99937304 0.99968652 0.98807594 0.9971777  0.99811814 0.99905956\n",
      " 0.99905858 0.99968652 0.99937304 0.99968652 0.84055224 0.83773092\n",
      " 0.83301295 0.8204649  0.8182597  0.81700972 0.8185919  0.81388577\n",
      " 0.99498235 0.99968553 1.         1.         1.         1.\n",
      " 1.         1.         0.99498235 0.99968553 1.         1.\n",
      " 1.         1.         1.         1.         0.88167524 0.89957118\n",
      " 0.89988072 0.89611896 0.90208198 0.89768636 0.90240039 0.90302636\n",
      " 0.99780269 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99780269 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.92623864 0.94350663\n",
      " 0.94193726 0.94507798 0.94853315 0.9482177  0.95293074 0.95763786\n",
      " 0.9987451  1.         1.         1.         1.         1.\n",
      " 1.         1.         0.9987451  1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94822559 0.96547978\n",
      " 0.96955797 0.9758394  0.9799166  0.98179945 0.9852566  0.98494213\n",
      " 0.99905858 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99905858 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96705309 0.97929359\n",
      " 0.98462175 0.98995682 0.99215512 0.99372055 0.99592082 0.99529485\n",
      " 0.99968652 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968652 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97803277 0.99215315\n",
      " 0.99560241 0.99717277 0.99811518 0.99780071 0.99905858 0.99905858\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656349206349206\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.613015873015873\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6242063492063493\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.8646825396825397\n",
      "testing classifiers: ['XGBClassifier']\n",
      "running: XGBClassifier\n",
      "0.8535714285714284\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_zwickau_greed_rearch_resp = []\n",
    "for cls in [\n",
    "    'SVC', \n",
    "    'DecisionTreeClassifier', \n",
    "    'GaussianProcessClassifier', \n",
    "    'RandomForestClassifier', \n",
    "    'GaussianNB', \n",
    "    'KNeighborsClassifier', \n",
    "    'AdaBoostClassifier', \n",
    "    'XGBClassifier'\n",
    "]:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_lz_zwickau_features_df, [cls])\n",
    "    burchard_lz_zwickau_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "374774fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.7262698412698413],\n",
       " ['DecisionTreeClassifier', 0.7492857142857142],\n",
       " ['GaussianProcessClassifier', 0.7064285714285714],\n",
       " ['RandomForestClassifier', 0.7656349206349206],\n",
       " ['GaussianNB', 0.613015873015873],\n",
       " ['KNeighborsClassifier', 0.6242063492063493],\n",
       " ['AdaBoostClassifier', 0.8646825396825397],\n",
       " ['XGBClassifier', 0.8535714285714284]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_lz_zwickau_greed_rearch_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fefadb5",
   "metadata": {},
   "source": [
    "##### create and save with argumests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f56af33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.8646825396825397\n"
     ]
    }
   ],
   "source": [
    "grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_lz_zwickau_features_df, ['AdaBoostClassifier'])\n",
    "burchard_lz_zwickau_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23e9c0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=1, n_estimators=2000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv_result[1][0].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1eef2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = thesisModelFeatures.create_X_y(burchard_lz_zwickau_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f429d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoostClassifier = AdaBoostClassifier(learning_rate=1, n_estimators=2000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d11378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thesisModelFeatures.save_zwickau_vs_burchard_best_model(\n",
    "    adaBoostClassifier, \n",
    "    'burchard_lz_AdaBoostClassifier(learning_rate=1, n_estimators=2000)_0.86468'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf441bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f38167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0088d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15001566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_zwickau_features_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    burchard_zl_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a4d8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_zwickau_result = thesisModelFeatures.run_models(\n",
    "    burchard_zl_zwickau_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c234e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       " SVM_linear                        0.293214      0.500000  0.369617  0.586429   \n",
       " SVM_RBF                           0.748904      0.621071  0.602430  0.673810   \n",
       " DecisionTreeClassifier            0.667688      0.666190  0.663477  0.671508   \n",
       " GaussianProcessClassifier         0.711243      0.683095  0.684108  0.702143   \n",
       " RandomForestClassifier            0.736234      0.693095  0.695071  0.718889   \n",
       " MLPClassifier                     0.708911      0.680952  0.680834  0.696349   \n",
       " GaussianNB                        0.646911      0.527262  0.467682  0.595000   \n",
       " KNeighborsClassifier              0.693926      0.555238  0.495901  0.625873   \n",
       " AdaBoostClassifier                0.786987      0.765952  0.767423  0.781508   \n",
       " XGBClassifier                     0.813956      0.788333  0.792804  0.807143   \n",
       " \n",
       "                            f1_weighted  accuracy  \n",
       " SVM_linear                    0.433623  0.586429  \n",
       " SVM_RBF                       0.630755  0.673810  \n",
       " DecisionTreeClassifier        0.671460  0.671508  \n",
       " GaussianProcessClassifier     0.695814  0.702143  \n",
       " RandomForestClassifier        0.708448  0.718889  \n",
       " MLPClassifier                 0.690898  0.696349  \n",
       " GaussianNB                    0.512376  0.595000  \n",
       " KNeighborsClassifier          0.540473  0.625873  \n",
       " AdaBoostClassifier            0.776693  0.781508  \n",
       " XGBClassifier                 0.801836  0.807143  ,\n",
       " [{'fit_time': array([39.36209798, 14.56277204, 16.70043015,  8.70665026, 10.14383411,\n",
       "           9.61304498,  9.08619189,  7.66484499,  9.99872088,  8.20317197]),\n",
       "   'score_time': array([1.88651085, 2.65840197, 1.00752997, 1.0130229 , 0.98300385,\n",
       "          1.21239686, 1.01058602, 1.0665071 , 0.98413587, 1.03321218]),\n",
       "   'test_precision_macro': array([0.29166667, 0.29166667, 0.29166667, 0.28571429, 0.28571429,\n",
       "          0.28571429, 0.3       , 0.3       , 0.3       , 0.3       ]),\n",
       "   'test_recall_macro': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "   'test_f1_macro': array([0.36842105, 0.36842105, 0.36842105, 0.36363636, 0.36363636,\n",
       "          0.36363636, 0.375     , 0.375     , 0.375     , 0.375     ]),\n",
       "   'test_f1_micro': array([0.58333333, 0.58333333, 0.58333333, 0.57142857, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ]),\n",
       "   'test_f1_weighted': array([0.42982456, 0.42982456, 0.42982456, 0.41558442, 0.41558442,\n",
       "          0.41558442, 0.45      , 0.45      , 0.45      , 0.45      ]),\n",
       "   'test_accuracy': array([0.58333333, 0.58333333, 0.58333333, 0.57142857, 0.57142857,\n",
       "          0.57142857, 0.6       , 0.6       , 0.6       , 0.6       ])},\n",
       "  {'fit_time': array([9.33100224, 8.93511724, 8.88671899, 8.68133879, 8.51143003,\n",
       "          8.42179108, 8.64743495, 8.51760721, 8.73519778, 8.73417187]),\n",
       "   'score_time': array([1.491117  , 1.47996187, 1.61796188, 1.72457314, 1.4326551 ,\n",
       "          1.49462891, 1.42070603, 1.53935695, 1.46029186, 1.46512318]),\n",
       "   'test_precision_macro': array([0.85      , 0.75      , 0.77339901, 0.8030303 , 0.67857143,\n",
       "          0.62731481, 0.48776224, 0.83870968, 0.81818182, 0.86206897]),\n",
       "   'test_recall_macro': array([0.7       , 0.64285714, 0.67619048, 0.56666667, 0.61666667,\n",
       "          0.59166667, 0.48809524, 0.64285714, 0.57142857, 0.71428571]),\n",
       "   'test_f1_macro': array([0.69747899, 0.6302521 , 0.67272727, 0.49500555, 0.60227273,\n",
       "          0.57909343, 0.48751077, 0.62606838, 0.51388889, 0.72      ]),\n",
       "   'test_f1_micro': array([0.75      , 0.69444444, 0.72222222, 0.62857143, 0.65714286,\n",
       "          0.62857143, 0.51428571, 0.71428571, 0.65714286, 0.77142857]),\n",
       "   'test_f1_weighted': array([0.71848739, 0.65592904, 0.69393939, 0.53210718, 0.62337662,\n",
       "          0.59970926, 0.51093885, 0.66239316, 0.56666667, 0.744     ]),\n",
       "   'test_accuracy': array([0.75      , 0.69444444, 0.72222222, 0.62857143, 0.65714286,\n",
       "          0.62857143, 0.51428571, 0.71428571, 0.65714286, 0.77142857])},\n",
       "  {'fit_time': array([0.47235703, 0.68888187, 0.49796581, 0.48570871, 0.68580794,\n",
       "          0.63120103, 0.58473086, 0.49249816, 0.71164393, 0.522856  ]),\n",
       "   'score_time': array([0.15628099, 0.15609407, 0.15682292, 0.16629028, 0.15631604,\n",
       "          0.1541791 , 0.15406489, 0.15388298, 0.15513301, 0.15660977]),\n",
       "   'test_precision_macro': array([0.68506494, 0.71571906, 0.57142857, 0.57352941, 0.67857143,\n",
       "          0.7124183 , 0.59210526, 0.68300654, 0.61013986, 0.8548951 ]),\n",
       "   'test_recall_macro': array([0.68095238, 0.7047619 , 0.57142857, 0.575     , 0.675     ,\n",
       "          0.71666667, 0.5952381 , 0.69047619, 0.60714286, 0.8452381 ]),\n",
       "   'test_f1_macro': array([0.68243785, 0.70779221, 0.55555556, 0.57002457, 0.67619849,\n",
       "          0.71217105, 0.59166667, 0.681555  , 0.60809647, 0.84926787]),\n",
       "   'test_f1_micro': array([0.69444444, 0.72222222, 0.55555556, 0.57142857, 0.68571429,\n",
       "          0.71428571, 0.6       , 0.68571429, 0.62857143, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.69272922, 0.71861472, 0.55555556, 0.57353457, 0.68412832,\n",
       "          0.71569549, 0.60333333, 0.68883375, 0.62601206, 0.85615848]),\n",
       "   'test_accuracy': array([0.69444444, 0.72222222, 0.55555556, 0.57142857, 0.68571429,\n",
       "          0.71428571, 0.6       , 0.68571429, 0.62857143, 0.85714286])},\n",
       "  {'fit_time': array([29.46960592, 29.44921803, 29.44967198, 29.69372988, 27.25885797,\n",
       "          29.61399913, 29.58847713, 29.48483801, 27.27795506, 27.26637411]),\n",
       "   'score_time': array([0.69599414, 0.698246  , 0.6962831 , 0.68023682, 0.68189812,\n",
       "          0.67828298, 0.67880607, 0.67980218, 0.68137097, 0.68614697]),\n",
       "   'test_precision_macro': array([0.75      , 0.80194805, 0.6875    , 0.52622378, 0.65151515,\n",
       "          0.62335526, 0.54575163, 0.80492424, 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.72857143, 0.7952381 , 0.69047619, 0.525     , 0.63333333,\n",
       "          0.625     , 0.54761905, 0.77380952, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.73333333, 0.797915  , 0.6884343 , 0.52380952, 0.63286713,\n",
       "          0.62365591, 0.53947368, 0.78222222, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.75      , 0.80555556, 0.69444444, 0.54285714, 0.65714286,\n",
       "          0.62857143, 0.54285714, 0.8       , 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.74444444, 0.80446405, 0.69564647, 0.53741497, 0.64635365,\n",
       "          0.62980031, 0.54736842, 0.79466667, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.75      , 0.80555556, 0.69444444, 0.54285714, 0.65714286,\n",
       "          0.62857143, 0.54285714, 0.8       , 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.56326079, 0.51897073, 0.51735091, 0.51660228, 0.52219391,\n",
       "          0.51572204, 0.50943589, 0.53382492, 0.51951504, 0.53092694]),\n",
       "   'score_time': array([0.1611042 , 0.15894723, 0.16056299, 0.16155577, 0.16079688,\n",
       "          0.1609931 , 0.161695  , 0.16092396, 0.15990591, 0.16077018]),\n",
       "   'test_precision_macro': array([0.85454545, 0.80194805, 0.76538462, 0.58522727, 0.70833333,\n",
       "          0.52622378, 0.54575163, 0.80492424, 0.85      , 0.92      ]),\n",
       "   'test_recall_macro': array([0.80952381, 0.7952381 , 0.71904762, 0.575     , 0.65      ,\n",
       "          0.525     , 0.54761905, 0.77380952, 0.67857143, 0.85714286]),\n",
       "   'test_f1_macro': array([0.81939799, 0.797915  , 0.72425532, 0.57167832, 0.64384829,\n",
       "          0.52380952, 0.53947368, 0.78222222, 0.6749226 , 0.87318841]),\n",
       "   'test_f1_micro': array([0.83333333, 0.80555556, 0.75      , 0.6       , 0.68571429,\n",
       "          0.54285714, 0.54285714, 0.8       , 0.74285714, 0.88571429]),\n",
       "   'test_f1_weighted': array([0.8277592 , 0.80446405, 0.73829787, 0.58741259, 0.66129245,\n",
       "          0.53741497, 0.54736842, 0.79466667, 0.70464396, 0.88115942]),\n",
       "   'test_accuracy': array([0.83333333, 0.80555556, 0.75      , 0.6       , 0.68571429,\n",
       "          0.54285714, 0.54285714, 0.8       , 0.74285714, 0.88571429])},\n",
       "  {'fit_time': array([ 98.83903384,  92.54836202,  91.32959294,  97.80268908,\n",
       "           85.09377885,  97.61890507,  84.74994516, 106.88669586,\n",
       "           96.7263248 ,  97.16596913]),\n",
       "   'score_time': array([0.2131052 , 0.20783806, 0.211061  , 0.21136403, 0.2253859 ,\n",
       "          0.21284294, 0.21570992, 0.21714115, 0.24042988, 0.21304679]),\n",
       "   'test_precision_macro': array([0.8125    , 0.77142857, 0.6875    , 0.48366013, 0.65151515,\n",
       "          0.59803922, 0.55833333, 0.80492424, 0.85      , 0.87121212]),\n",
       "   'test_recall_macro': array([0.78571429, 0.77142857, 0.69047619, 0.48333333, 0.63333333,\n",
       "          0.6       , 0.55952381, 0.77380952, 0.67857143, 0.83333333]),\n",
       "   'test_f1_macro': array([0.79259259, 0.77142857, 0.6884343 , 0.48190789, 0.63286713,\n",
       "          0.59703947, 0.54248366, 0.78222222, 0.6749226 , 0.84444444]),\n",
       "   'test_f1_micro': array([0.80555556, 0.77777778, 0.69444444, 0.48571429, 0.65714286,\n",
       "          0.6       , 0.54285714, 0.8       , 0.74285714, 0.85714286]),\n",
       "   'test_f1_weighted': array([0.80123457, 0.77777778, 0.69564647, 0.48825188, 0.64635365,\n",
       "          0.60197368, 0.54509804, 0.79466667, 0.70464396, 0.85333333]),\n",
       "   'test_accuracy': array([0.80555556, 0.77777778, 0.69444444, 0.48571429, 0.65714286,\n",
       "          0.6       , 0.54285714, 0.8       , 0.74285714, 0.85714286])},\n",
       "  {'fit_time': array([0.3473599 , 0.25012589, 0.24284315, 0.28262401, 0.24066401,\n",
       "          0.2409029 , 0.24118829, 0.24126577, 0.24070287, 0.24055982]),\n",
       "   'score_time': array([0.17808723, 0.16666102, 0.16683292, 0.16654301, 0.16636896,\n",
       "          0.16488695, 0.16543102, 0.16429424, 0.16535711, 0.16636205]),\n",
       "   'test_precision_macro': array([0.8       , 0.8       , 0.48846154, 0.39919355, 0.68145161,\n",
       "          0.68145161, 0.42857143, 0.80882353, 0.828125  , 0.5530303 ]),\n",
       "   'test_recall_macro': array([0.53333333, 0.53333333, 0.49047619, 0.45833333, 0.575     ,\n",
       "          0.575     , 0.45238095, 0.53571429, 0.60714286, 0.51190476]),\n",
       "   'test_f1_macro': array([0.4375    , 0.4375    , 0.47914894, 0.38596491, 0.53044376,\n",
       "          0.53044376, 0.42176871, 0.44848485, 0.572697  , 0.43287037]),\n",
       "   'test_f1_micro': array([0.61111111, 0.61111111, 0.52777778, 0.51428571, 0.62857143,\n",
       "          0.62857143, 0.51428571, 0.62857143, 0.68571429, 0.6       ]),\n",
       "   'test_f1_weighted': array([0.48958333, 0.48958333, 0.50567376, 0.42606516, 0.56110865,\n",
       "          0.56110865, 0.46802721, 0.51151515, 0.61664817, 0.49444444]),\n",
       "   'test_accuracy': array([0.61111111, 0.61111111, 0.52777778, 0.51428571, 0.62857143,\n",
       "          0.62857143, 0.51428571, 0.62857143, 0.68571429, 0.6       ])},\n",
       "  {'fit_time': array([0.17158794, 0.17083001, 0.17484999, 0.17497015, 0.17472219,\n",
       "          0.17124367, 0.17267895, 0.17511296, 0.17603707, 0.17445779]),\n",
       "   'score_time': array([0.2498858 , 0.26957917, 0.26786304, 0.2753768 , 0.28368473,\n",
       "          0.27032614, 0.24612498, 0.2725451 , 0.26645994, 0.26352525]),\n",
       "   'test_precision_macro': array([0.80882353, 0.63636364, 0.828125  , 0.79411765, 0.67857143,\n",
       "          0.54032258, 0.46354167, 0.5530303 , 0.81818182, 0.81818182]),\n",
       "   'test_recall_macro': array([0.56666667, 0.54285714, 0.63333333, 0.53333333, 0.61666667,\n",
       "          0.51666667, 0.48809524, 0.51190476, 0.57142857, 0.57142857]),\n",
       "   'test_f1_macro': array([0.49946524, 0.48148148, 0.60675273, 0.43287037, 0.60227273,\n",
       "          0.45820433, 0.4173141 , 0.43287037, 0.51388889, 0.51388889]),\n",
       "   'test_f1_micro': array([0.63888889, 0.61111111, 0.69444444, 0.6       , 0.65714286,\n",
       "          0.57142857, 0.57142857, 0.6       , 0.65714286, 0.65714286]),\n",
       "   'test_f1_weighted': array([0.54349376, 0.52469136, 0.63770275, 0.47685185, 0.62337662,\n",
       "          0.49358691, 0.4772475 , 0.49444444, 0.56666667, 0.56666667]),\n",
       "   'test_accuracy': array([0.63888889, 0.61111111, 0.69444444, 0.6       , 0.65714286,\n",
       "          0.57142857, 0.57142857, 0.6       , 0.65714286, 0.65714286])},\n",
       "  {'fit_time': array([3.82125783, 3.83622789, 3.84122491, 3.85032892, 3.82694769,\n",
       "          3.83253884, 3.8538959 , 3.85261798, 3.74059987, 3.77596498]),\n",
       "   'score_time': array([0.27504921, 0.21349216, 0.21454215, 0.21091509, 0.20964408,\n",
       "          0.21151805, 0.21008992, 0.21181321, 0.20985413, 0.20991993]),\n",
       "   'test_precision_macro': array([0.74375   , 0.89632107, 0.8361204 , 0.59166667, 0.82679739,\n",
       "          0.70833333, 0.8548951 , 0.82142857, 0.76149425, 0.82905983]),\n",
       "   'test_recall_macro': array([0.74761905, 0.87619048, 0.81904762, 0.59166667, 0.83333333,\n",
       "          0.70833333, 0.8452381 , 0.82142857, 0.6547619 , 0.76190476]),\n",
       "   'test_f1_macro': array([0.74508261, 0.88311688, 0.82467532, 0.59166667, 0.82730263,\n",
       "          0.70833333, 0.84926787, 0.82142857, 0.65      , 0.773358  ]),\n",
       "   'test_f1_micro': array([0.75      , 0.88888889, 0.83333333, 0.6       , 0.82857143,\n",
       "          0.71428571, 0.85714286, 0.82857143, 0.71428571, 0.8       ]),\n",
       "   'test_f1_weighted': array([0.75098348, 0.88744589, 0.83116883, 0.6       , 0.82941729,\n",
       "          0.71428571, 0.85615848, 0.82857143, 0.68      , 0.78889917]),\n",
       "   'test_accuracy': array([0.75      , 0.88888889, 0.83333333, 0.6       , 0.82857143,\n",
       "          0.71428571, 0.85714286, 0.82857143, 0.71428571, 0.8       ])},\n",
       "  {'fit_time': array([10.95590711, 11.15239596, 11.08756518, 11.09563971, 11.07726622,\n",
       "          10.93594599, 11.06437016, 11.06816792, 11.66593289, 11.34095693]),\n",
       "   'score_time': array([0.46792507, 0.46325397, 0.46376395, 0.44265437, 0.44440198,\n",
       "          0.44448185, 0.44195104, 0.44573498, 0.44300318, 0.44759703]),\n",
       "   'test_precision_macro': array([0.8125    , 0.89632107, 0.8125    , 0.73504274, 0.77097902,\n",
       "          0.70833333, 0.76630435, 0.82971014, 0.80787037, 1.        ]),\n",
       "   'test_recall_macro': array([0.78571429, 0.87619048, 0.78571429, 0.68333333, 0.75833333,\n",
       "          0.70833333, 0.75      , 0.80952381, 0.72619048, 1.        ]),\n",
       "   'test_f1_macro': array([0.79259259, 0.88311688, 0.79259259, 0.68297101, 0.76190476,\n",
       "          0.70833333, 0.75524476, 0.81643357, 0.73484848, 1.        ]),\n",
       "   'test_f1_micro': array([0.80555556, 0.88888889, 0.80555556, 0.71428571, 0.77142857,\n",
       "          0.71428571, 0.77142857, 0.82857143, 0.77142857, 1.        ]),\n",
       "   'test_f1_weighted': array([0.80123457, 0.88744589, 0.80123457, 0.69720497, 0.76870748,\n",
       "          0.71428571, 0.76783217, 0.82587413, 0.75454545, 1.        ]),\n",
       "   'test_accuracy': array([0.80555556, 0.88888889, 0.80555556, 0.71428571, 0.77142857,\n",
       "          0.71428571, 0.77142857, 0.82857143, 0.77142857, 1.        ])}])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zl_zwickau_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27db3e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.293214</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369617</td>\n",
       "      <td>0.586429</td>\n",
       "      <td>0.433623</td>\n",
       "      <td>0.586429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.748904</td>\n",
       "      <td>0.621071</td>\n",
       "      <td>0.602430</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.630755</td>\n",
       "      <td>0.673810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.667688</td>\n",
       "      <td>0.666190</td>\n",
       "      <td>0.663477</td>\n",
       "      <td>0.671508</td>\n",
       "      <td>0.671460</td>\n",
       "      <td>0.671508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.711243</td>\n",
       "      <td>0.683095</td>\n",
       "      <td>0.684108</td>\n",
       "      <td>0.702143</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.702143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.736234</td>\n",
       "      <td>0.693095</td>\n",
       "      <td>0.695071</td>\n",
       "      <td>0.718889</td>\n",
       "      <td>0.708448</td>\n",
       "      <td>0.718889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.708911</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.680834</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>0.690898</td>\n",
       "      <td>0.696349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.646911</td>\n",
       "      <td>0.527262</td>\n",
       "      <td>0.467682</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.512376</td>\n",
       "      <td>0.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.693926</td>\n",
       "      <td>0.555238</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.625873</td>\n",
       "      <td>0.540473</td>\n",
       "      <td>0.625873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.786987</td>\n",
       "      <td>0.765952</td>\n",
       "      <td>0.767423</td>\n",
       "      <td>0.781508</td>\n",
       "      <td>0.776693</td>\n",
       "      <td>0.781508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.813956</td>\n",
       "      <td>0.788333</td>\n",
       "      <td>0.792804</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.801836</td>\n",
       "      <td>0.807143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "SVM_linear                        0.293214      0.500000  0.369617  0.586429   \n",
       "SVM_RBF                           0.748904      0.621071  0.602430  0.673810   \n",
       "DecisionTreeClassifier            0.667688      0.666190  0.663477  0.671508   \n",
       "GaussianProcessClassifier         0.711243      0.683095  0.684108  0.702143   \n",
       "RandomForestClassifier            0.736234      0.693095  0.695071  0.718889   \n",
       "MLPClassifier                     0.708911      0.680952  0.680834  0.696349   \n",
       "GaussianNB                        0.646911      0.527262  0.467682  0.595000   \n",
       "KNeighborsClassifier              0.693926      0.555238  0.495901  0.625873   \n",
       "AdaBoostClassifier                0.786987      0.765952  0.767423  0.781508   \n",
       "XGBClassifier                     0.813956      0.788333  0.792804  0.807143   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "SVM_linear                    0.433623  0.586429  \n",
       "SVM_RBF                       0.630755  0.673810  \n",
       "DecisionTreeClassifier        0.671460  0.671508  \n",
       "GaussianProcessClassifier     0.695814  0.702143  \n",
       "RandomForestClassifier        0.708448  0.718889  \n",
       "MLPClassifier                 0.690898  0.696349  \n",
       "GaussianNB                    0.512376  0.595000  \n",
       "KNeighborsClassifier          0.540473  0.625873  \n",
       "AdaBoostClassifier            0.776693  0.781508  \n",
       "XGBClassifier                 0.801836  0.807143  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zl_zwickau_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d276e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.7216666666666667\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7738095238095237\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.705\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.68753968 0.7047619  0.7018254  0.71047619 0.70753968 0.71325397\n",
      " 0.71904762 0.71896825 0.68753968 0.7047619  0.7018254  0.71047619\n",
      " 0.70753968 0.71325397 0.71904762 0.71896825 0.58365079 0.58642857\n",
      " 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857\n",
      " 0.71888889 0.7131746  0.72468254 0.71611111 0.72174603 0.71603175\n",
      " 0.71611111 0.72174603 0.71888889 0.7131746  0.72468254 0.71611111\n",
      " 0.72174603 0.71603175 0.71611111 0.72174603 0.59214286 0.58642857\n",
      " 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857\n",
      " 0.6902381  0.70738095 0.71325397 0.71611111 0.72468254 0.72174603\n",
      " 0.71611111 0.71904762 0.6902381  0.70738095 0.71325397 0.71611111\n",
      " 0.72468254 0.72174603 0.71611111 0.71904762 0.59492063 0.58365079\n",
      " 0.58642857 0.58928571 0.58928571 0.58928571 0.58928571 0.58928571\n",
      " 0.71031746 0.71031746 0.72452381 0.71611111 0.71888889 0.7302381\n",
      " 0.72166667 0.71611111 0.71031746 0.71031746 0.72452381 0.71611111\n",
      " 0.71888889 0.7302381  0.72166667 0.71611111 0.6115873  0.60333333\n",
      " 0.58912698 0.58920635 0.59769841 0.60055556 0.59777778 0.60063492\n",
      " 0.71325397 0.71611111 0.72452381 0.72452381 0.72460317 0.73325397\n",
      " 0.73031746 0.7302381  0.71325397 0.71611111 0.72452381 0.72452381\n",
      " 0.72460317 0.73325397 0.73031746 0.7302381  0.60015873 0.59769841\n",
      " 0.60333333 0.60055556 0.62031746 0.61468254 0.6118254  0.60055556\n",
      " 0.71031746 0.72468254 0.71603175 0.7218254  0.7218254  0.72468254\n",
      " 0.72468254 0.72746032 0.71031746 0.72468254 0.71603175 0.7218254\n",
      " 0.7218254  0.72468254 0.72468254 0.72746032 0.60579365 0.61174603\n",
      " 0.58912698 0.59198413 0.60880952 0.60888889 0.61174603 0.60896825\n",
      " 0.71603175 0.72190476 0.7131746  0.70746032 0.71325397 0.71325397\n",
      " 0.7018254  0.70753968 0.71603175 0.72190476 0.7131746  0.70746032\n",
      " 0.71325397 0.71325397 0.7018254  0.70753968 0.61174603 0.63444444\n",
      " 0.60619048 0.60904762 0.62309524 0.62587302 0.62309524 0.62031746\n",
      " 0.70174603 0.7218254  0.70468254 0.70753968 0.71325397 0.7218254\n",
      " 0.70761905 0.7218254  0.70174603 0.7218254  0.70468254 0.70753968\n",
      " 0.71325397 0.7218254  0.70761905 0.7218254  0.64539683 0.64007937\n",
      " 0.62873016 0.63436508 0.64015873 0.64579365 0.63730159 0.63444444\n",
      " 0.71587302 0.72452381 0.71325397 0.71880952 0.72452381 0.72174603\n",
      " 0.72468254 0.71888889 0.71587302 0.72452381 0.71325397 0.71880952\n",
      " 0.72452381 0.72174603 0.72468254 0.71888889 0.67365079 0.66531746\n",
      " 0.64       0.63412698 0.62587302 0.64825397 0.64563492 0.62857143\n",
      " 0.70769841 0.6934127  0.71055556 0.71047619 0.71325397 0.71047619\n",
      " 0.71626984 0.71904762 0.70769841 0.6934127  0.71055556 0.71047619\n",
      " 0.71325397 0.71047619 0.71626984 0.71904762 0.58928571 0.58642857\n",
      " 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857\n",
      " 0.71325397 0.7131746  0.71896825 0.71611111 0.71904762 0.71626984\n",
      " 0.71634921 0.71619048 0.71325397 0.7131746  0.71896825 0.71611111\n",
      " 0.71904762 0.71626984 0.71634921 0.71619048 0.58642857 0.58642857\n",
      " 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857 0.58642857\n",
      " 0.71039683 0.71595238 0.7302381  0.73880952 0.73309524 0.73595238\n",
      " 0.73309524 0.73031746 0.71039683 0.71595238 0.7302381  0.73880952\n",
      " 0.73309524 0.73595238 0.73309524 0.73031746 0.59492063 0.58357143\n",
      " 0.58642857 0.58928571 0.58928571 0.58928571 0.58928571 0.58928571\n",
      " 0.71301587 0.73007937 0.72746032 0.71611111 0.7302381  0.73031746\n",
      " 0.74460317 0.73888889 0.71301587 0.73007937 0.72746032 0.71611111\n",
      " 0.7302381  0.73031746 0.74460317 0.73888889 0.5918254  0.59198413\n",
      " 0.58634921 0.59206349 0.59206349 0.59492063 0.60063492 0.59785714\n",
      " 0.7131746  0.71603175 0.71888889 0.71611111 0.73325397 0.73896825\n",
      " 0.73325397 0.73309524 0.7131746  0.71603175 0.71888889 0.71611111\n",
      " 0.73325397 0.73896825 0.73325397 0.73309524 0.60603175 0.5947619\n",
      " 0.6031746  0.59468254 0.61174603 0.60904762 0.60047619 0.60626984\n",
      " 0.72452381 0.72166667 0.72166667 0.70746032 0.70746032 0.71896825\n",
      " 0.72460317 0.72452381 0.72452381 0.72166667 0.72166667 0.70746032\n",
      " 0.70746032 0.71896825 0.72460317 0.72452381 0.61730159 0.60579365\n",
      " 0.59166667 0.59452381 0.62563492 0.62865079 0.6202381  0.6202381\n",
      " 0.71611111 0.71301587 0.7218254  0.71619048 0.72190476 0.7247619\n",
      " 0.7331746  0.73309524 0.71611111 0.71301587 0.7218254  0.71619048\n",
      " 0.72190476 0.7247619  0.7331746  0.73309524 0.6115873  0.61722222\n",
      " 0.60309524 0.60880952 0.62857143 0.64285714 0.6315873  0.62873016\n",
      " 0.72753968 0.7331746  0.74174603 0.73039683 0.73603175 0.73039683\n",
      " 0.73603175 0.73031746 0.72753968 0.7331746  0.74174603 0.73039683\n",
      " 0.73603175 0.73039683 0.73603175 0.73031746 0.6202381  0.63714286\n",
      " 0.62015873 0.62857143 0.63420635 0.65420635 0.63714286 0.63722222\n",
      " 0.71015873 0.71873016 0.71888889 0.72460317 0.7218254  0.7218254\n",
      " 0.7302381  0.72452381 0.71015873 0.71873016 0.71888889 0.72460317\n",
      " 0.7218254  0.7218254  0.7302381  0.72452381 0.63142857 0.63968254\n",
      " 0.64555556 0.64301587 0.64857143 0.65428571 0.65126984 0.64563492\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.91566474 0.91503184 0.91691268 0.91785509 0.92131818 0.92698351\n",
      " 0.92414737 0.92194611 0.91566474 0.91503184 0.91691268 0.91785509\n",
      " 0.92131818 0.92698351 0.92414737 0.92194611 0.63015991 0.61819832\n",
      " 0.60622483 0.60559788 0.6046525  0.60276472 0.59584251 0.59206496\n",
      " 0.95342043 0.96443962 0.96852767 0.97072892 0.97356705 0.97482194\n",
      " 0.97450747 0.97577029 0.95342043 0.96443962 0.96852767 0.97072892\n",
      " 0.97356705 0.97482194 0.97450747 0.97577029 0.70002976 0.68680138\n",
      " 0.6603595  0.66508144 0.66665972 0.66508541 0.65469913 0.64872031\n",
      " 0.98112017 0.98993115 0.99370474 0.99401821 0.99527806 0.99590798\n",
      " 0.99590897 0.99559352 0.98112017 0.98993115 0.99370474 0.99401821\n",
      " 0.99527806 0.99590798 0.99590897 0.99559352 0.77652421 0.77242426\n",
      " 0.76644049 0.77021903 0.77305518 0.77966391 0.77273873 0.76802274\n",
      " 0.99181696 0.99748229 0.99905462 0.99936909 0.99968454 1.\n",
      " 1.         0.99968454 0.99181696 0.99748229 0.99905462 0.99936909\n",
      " 0.99968454 1.         1.         0.99968454 0.84072972 0.84701407\n",
      " 0.84953277 0.85331726 0.85929707 0.86086741 0.86748309 0.86496935\n",
      " 0.99622443 0.99905462 0.99905462 0.99968454 1.         1.\n",
      " 1.         1.         0.99622443 0.99905462 0.99905462 0.99968454\n",
      " 1.         1.         1.         1.         0.89865385 0.90682896\n",
      " 0.91910303 0.92288951 0.93422415 0.94020197 0.94649922 0.94146281\n",
      " 0.99937008 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99937008 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.93012717 0.95404936\n",
      " 0.96601095 0.97199571 0.97608376 0.97922941 0.98080571 0.97765808\n",
      " 0.99874015 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99874015 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96035057 0.97828304\n",
      " 0.98615658 0.98930619 0.99213539 0.99402119 0.99496558 0.99433665\n",
      " 0.99937008 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99937008 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.974193   0.99118505\n",
      " 0.99590699 0.99779775 0.99748031 0.99842569 0.99811122 0.99811122\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98489276 0.99622245\n",
      " 0.99811122 0.99937008 0.99936909 0.99968454 0.99937107 0.99905462\n",
      " 0.89613912 0.90086404 0.90085908 0.90463663 0.90432415 0.90998651\n",
      " 0.90526457 0.90463167 0.89613912 0.90086404 0.90085908 0.90463663\n",
      " 0.90432415 0.90998651 0.90526457 0.90463167 0.6219729  0.60812154\n",
      " 0.59615697 0.59804674 0.59646846 0.59395472 0.59017717 0.58891832\n",
      " 0.94114735 0.95216654 0.95027875 0.95814832 0.96254985 0.96317779\n",
      " 0.96035057 0.95877527 0.94114735 0.95216654 0.95027875 0.95814832\n",
      " 0.96254985 0.96317779 0.96035057 0.95877527 0.68429955 0.66792552\n",
      " 0.64651211 0.64461838 0.64462135 0.64399341 0.6354959  0.62794377\n",
      " 0.97545483 0.98300399 0.98678253 0.98992818 0.99181894 0.9930768\n",
      " 0.99150547 0.99181993 0.97545483 0.98300399 0.98678253 0.98992818\n",
      " 0.99181894 0.9930768  0.99150547 0.99181993 0.74945142 0.73937861\n",
      " 0.73119457 0.73244747 0.7412654  0.74724421 0.73874571 0.73213202\n",
      " 0.98898081 0.99433169 0.99716485 0.99936909 0.99905462 0.99937008\n",
      " 0.99937107 0.99937107 0.98898081 0.99433169 0.99716485 0.99936909\n",
      " 0.99905462 0.99937008 0.99937107 0.99937107 0.81492867 0.8215255\n",
      " 0.81585521 0.82372478 0.82687836 0.83002897 0.83065889 0.82719779\n",
      " 0.99307779 0.99874115 0.99968553 0.99968553 0.99968553 1.\n",
      " 1.         1.         0.99307779 0.99874115 0.99968553 0.99968553\n",
      " 0.99968553 1.         1.         1.         0.87347479 0.88101799\n",
      " 0.8873083  0.89519076 0.8999127  0.90589647 0.91312918 0.90589747\n",
      " 0.99779676 0.99968454 1.         1.         1.         1.\n",
      " 1.         1.         0.99779676 0.99968454 1.         1.\n",
      " 1.         1.         1.         1.         0.90716326 0.92257108\n",
      " 0.93610995 0.94241216 0.9515386  0.952481   0.95625558 0.95909073\n",
      " 0.99874214 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99874214 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.93863659 0.96255084\n",
      " 0.96916354 0.97357399 0.98175208 0.98237903 0.98112216 0.98206456\n",
      " 0.99968553 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968553 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95908874 0.97796857\n",
      " 0.98489673 0.99181696 0.99433367 0.99307581 0.99338928 0.99433466\n",
      " 0.99937008 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99937008 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96947503 0.98867032\n",
      " 0.99402218 0.99748328 0.99716783 0.99748229 0.99811122 0.99811122\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7446031746031746\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.6032539682539683\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6258730158730159\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.8326984126984126\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_zwickau_greed_rearch_resp = []\n",
    "for cls in [\n",
    "    'SVC', \n",
    "    'DecisionTreeClassifier', \n",
    "    'GaussianProcessClassifier', \n",
    "    'RandomForestClassifier', \n",
    "    'GaussianNB', \n",
    "    'KNeighborsClassifier', \n",
    "    'AdaBoostClassifier'\n",
    "]:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zl_zwickau_features_df, [cls])\n",
    "    burchard_zl_zwickau_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49535cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['XGBClassifier']\n",
      "running: XGBClassifier\n",
      "0.826984126984127\n"
     ]
    }
   ],
   "source": [
    "for cls in ['XGBClassifier']:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zl_zwickau_features_df, [cls])\n",
    "    burchard_zl_zwickau_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6cc601a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.7216666666666667],\n",
       " ['DecisionTreeClassifier', 0.7738095238095237],\n",
       " ['GaussianProcessClassifier', 0.705],\n",
       " ['RandomForestClassifier', 0.7446031746031746],\n",
       " ['GaussianNB', 0.6032539682539683],\n",
       " ['KNeighborsClassifier', 0.6258730158730159],\n",
       " ['AdaBoostClassifier', 0.8326984126984126]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zl_zwickau_greed_rearch_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62adf142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "AdaBoostClassifier(learning_rate=1, n_estimators=2000)\n"
     ]
    }
   ],
   "source": [
    "grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zl_zwickau_features_df, ['AdaBoostClassifier'])\n",
    "print(grid_search_cv_result[1][0].best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c277792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8326984126984126\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d108036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = thesisModelFeatures.create_X_y(burchard_zl_zwickau_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dcc7fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoostClassifier_burchard_zl = AdaBoostClassifier(learning_rate=1, n_estimators=2000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5eb226de",
   "metadata": {},
   "outputs": [],
   "source": [
    "thesisModelFeatures.save_zwickau_vs_burchard_best_model(\n",
    "    adaBoostClassifier_burchard_zl, \n",
    "    'burchard_zl_AdaBoostClassifier(learning_rate=1, n_estimators=2000)_0.83269'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b2ddc",
   "metadata": {},
   "source": [
    "# london burchard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "028a6de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_london_features_df = thesisModelFeatures.create_features_df(\n",
    "    london_leftofvers_long,\n",
    "    None,\n",
    "    burchard_lz_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adf722f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_london_result = thesisModelFeatures.run_models(\n",
    "    burchard_lz_london_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc5e56b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       " SVM_linear                        0.284947      0.500000  0.362989  0.569895   \n",
       " SVM_RBF                           0.805178      0.658185  0.635549  0.703754   \n",
       " DecisionTreeClassifier            0.636666      0.632887  0.629784  0.640841   \n",
       " GaussianProcessClassifier         0.737535      0.719196  0.717911  0.733859   \n",
       " RandomForestClassifier            0.801534      0.739554  0.736178  0.766892   \n",
       " MLPClassifier                     0.747724      0.729881  0.727008  0.742192   \n",
       " GaussianNB                        0.604570      0.564821  0.541575  0.602628   \n",
       " KNeighborsClassifier              0.638506      0.592857  0.572866  0.624700   \n",
       " AdaBoostClassifier                0.718949      0.713929  0.711432  0.720345   \n",
       " XGBClassifier                     0.766798      0.748899  0.748292  0.761111   \n",
       " \n",
       "                            f1_weighted  accuracy  \n",
       " SVM_linear                    0.413811  0.569895  \n",
       " SVM_RBF                       0.657934  0.703754  \n",
       " DecisionTreeClassifier        0.637810  0.640841  \n",
       " GaussianProcessClassifier     0.726839  0.733859  \n",
       " RandomForestClassifier        0.748578  0.766892  \n",
       " MLPClassifier                 0.735265  0.742192  \n",
       " GaussianNB                    0.564061  0.602628  \n",
       " KNeighborsClassifier          0.592579  0.624700  \n",
       " AdaBoostClassifier            0.717980  0.720345  \n",
       " XGBClassifier                 0.755762  0.761111  ,\n",
       " [{'fit_time': array([6.96423078, 7.16646409, 7.69423079, 7.45739293, 6.5737319 ,\n",
       "          6.89816308, 6.81424832, 6.35098386, 7.53263688, 7.27267504]),\n",
       "   'score_time': array([0.83050108, 0.78587222, 0.92508721, 1.0628612 , 0.82419586,\n",
       "          0.87909079, 0.84793186, 0.77601385, 0.87592697, 0.99115181]),\n",
       "   'test_precision_macro': array([0.28378378, 0.28378378, 0.28378378, 0.28378378, 0.28378378,\n",
       "          0.27777778, 0.27777778, 0.29166667, 0.29166667, 0.29166667]),\n",
       "   'test_recall_macro': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "   'test_f1_macro': array([0.36206897, 0.36206897, 0.36206897, 0.36206897, 0.36206897,\n",
       "          0.35714286, 0.35714286, 0.36842105, 0.36842105, 0.36842105]),\n",
       "   'test_f1_micro': array([0.56756757, 0.56756757, 0.56756757, 0.56756757, 0.56756757,\n",
       "          0.55555556, 0.55555556, 0.58333333, 0.58333333, 0.58333333]),\n",
       "   'test_f1_weighted': array([0.4109972 , 0.4109972 , 0.4109972 , 0.4109972 , 0.4109972 ,\n",
       "          0.3968254 , 0.3968254 , 0.42982456, 0.42982456, 0.42982456]),\n",
       "   'test_accuracy': array([0.56756757, 0.56756757, 0.56756757, 0.56756757, 0.56756757,\n",
       "          0.55555556, 0.55555556, 0.58333333, 0.58333333, 0.58333333])},\n",
       "  {'fit_time': array([7.26153398, 6.87653899, 7.02397585, 6.76516795, 6.98306632,\n",
       "          6.81182313, 9.25776005, 6.86676407, 8.66659975, 7.49670315]),\n",
       "   'score_time': array([1.13593388, 1.23829889, 1.1963172 , 1.17857504, 1.44723773,\n",
       "          1.37580299, 1.4868238 , 1.22674298, 1.34506917, 1.23122096]),\n",
       "   'test_precision_macro': array([0.83870968, 0.83870968, 0.73924731, 0.86206897, 0.83870968,\n",
       "          0.8030303 , 0.87037037, 0.63392857, 0.80882353, 0.81818182]),\n",
       "   'test_recall_macro': array([0.6875    , 0.6875    , 0.63244048, 0.75      , 0.6875    ,\n",
       "          0.59375   , 0.78125   , 0.5952381 , 0.56666667, 0.6       ]),\n",
       "   'test_f1_macro': array([0.67657343, 0.67657343, 0.61188811, 0.75333333, 0.67657343,\n",
       "          0.53525323, 0.78553191, 0.58473824, 0.49946524, 0.55555556]),\n",
       "   'test_f1_micro': array([0.72972973, 0.72972973, 0.67567568, 0.78378378, 0.72972973,\n",
       "          0.63888889, 0.80555556, 0.63888889, 0.63888889, 0.66666667]),\n",
       "   'test_f1_weighted': array([0.69429219, 0.69429219, 0.63315063, 0.76504505, 0.69429219,\n",
       "          0.55963809, 0.79281324, 0.60973085, 0.54349376, 0.59259259]),\n",
       "   'test_accuracy': array([0.72972973, 0.72972973, 0.67567568, 0.78378378, 0.72972973,\n",
       "          0.63888889, 0.80555556, 0.63888889, 0.63888889, 0.66666667])},\n",
       "  {'fit_time': array([0.99628305, 0.68849397, 0.76774502, 0.73172283, 0.66113734,\n",
       "          0.71589184, 0.74867201, 0.68708897, 0.59880614, 0.55755329]),\n",
       "   'score_time': array([0.17552495, 0.16609406, 0.16581917, 0.17724609, 0.16559792,\n",
       "          0.16146302, 0.16348505, 0.181813  , 0.16287684, 0.16167784]),\n",
       "   'test_precision_macro': array([0.73291925, 0.72470238, 0.53529412, 0.72670807, 0.59649123,\n",
       "          0.55      , 0.775     , 0.54285714, 0.55769231, 0.625     ]),\n",
       "   'test_recall_macro': array([0.72321429, 0.72470238, 0.53571429, 0.7172619 , 0.59821429,\n",
       "          0.55      , 0.775     , 0.54285714, 0.54761905, 0.61428571]),\n",
       "   'test_f1_macro': array([0.7018315 , 0.72470238, 0.53510717, 0.71969697, 0.59340659,\n",
       "          0.55      , 0.775     , 0.54285714, 0.54042553, 0.61481481]),\n",
       "   'test_f1_micro': array([0.7027027 , 0.72972973, 0.54054054, 0.72972973, 0.59459459,\n",
       "          0.55555556, 0.77777778, 0.55555556, 0.58333333, 0.63888889]),\n",
       "   'test_f1_weighted': array([0.6996535 , 0.72972973, 0.54189888, 0.72686323, 0.5963766 ,\n",
       "          0.55555556, 0.77777778, 0.55555556, 0.56382979, 0.6308642 ]),\n",
       "   'test_accuracy': array([0.7027027 , 0.72972973, 0.54054054, 0.72972973, 0.59459459,\n",
       "          0.55555556, 0.77777778, 0.55555556, 0.58333333, 0.63888889])},\n",
       "  {'fit_time': array([35.39009309, 32.89118505, 35.07959795, 30.07327199, 32.60753512,\n",
       "          32.97770095, 30.39399791, 33.02066827, 25.46486688, 35.8835578 ]),\n",
       "   'score_time': array([0.78105998, 0.75708985, 0.76020217, 0.75521994, 0.76395798,\n",
       "          0.74269605, 0.75073719, 0.75369406, 0.75101805, 0.76957583]),\n",
       "   'test_precision_macro': array([0.83482143, 0.78216374, 0.67333333, 0.75877193, 0.7530303 ,\n",
       "          0.54166667, 0.86190476, 0.65551839, 0.74074074, 0.77339901]),\n",
       "   'test_recall_macro': array([0.83482143, 0.78720238, 0.6547619 , 0.76339286, 0.7485119 ,\n",
       "          0.5375    , 0.85625   , 0.64761905, 0.68571429, 0.67619048]),\n",
       "   'test_f1_macro': array([0.83482143, 0.78235294, 0.6552795 , 0.75604396, 0.75018755,\n",
       "          0.53246753, 0.85837923, 0.64935065, 0.6875    , 0.67272727]),\n",
       "   'test_f1_micro': array([0.83783784, 0.78378378, 0.67567568, 0.75675676, 0.75675676,\n",
       "          0.55555556, 0.86111111, 0.66666667, 0.72222222, 0.72222222]),\n",
       "   'test_f1_weighted': array([0.83783784, 0.78473768, 0.66661071, 0.75782596, 0.75566189,\n",
       "          0.54401154, 0.86056473, 0.66233766, 0.70486111, 0.69393939]),\n",
       "   'test_accuracy': array([0.83783784, 0.78378378, 0.67567568, 0.75675676, 0.75675676,\n",
       "          0.55555556, 0.86111111, 0.66666667, 0.72222222, 0.72222222])},\n",
       "  {'fit_time': array([0.61132598, 0.56484199, 0.54778767, 0.56053877, 0.55826998,\n",
       "          0.59776998, 0.57609391, 0.52870226, 0.53298998, 0.53462672]),\n",
       "   'score_time': array([0.1727128 , 0.17022419, 0.17629719, 0.17438889, 0.16934395,\n",
       "          0.1748631 , 0.1670053 , 0.16851091, 0.16718793, 0.16527104]),\n",
       "   'test_precision_macro': array([0.84161491, 0.7797619 , 0.7281746 , 0.75185185, 0.87820513,\n",
       "          0.63333333, 0.91904762, 0.79464286, 0.85      , 0.83870968]),\n",
       "   'test_recall_macro': array([0.82738095, 0.7797619 , 0.67113095, 0.70238095, 0.85119048,\n",
       "          0.575     , 0.9125    , 0.70952381, 0.7       , 0.66666667]),\n",
       "   'test_f1_macro': array([0.83181818, 0.7797619 , 0.6677551 , 0.70352564, 0.85823755,\n",
       "          0.54181818, 0.91502754, 0.71251109, 0.69747899, 0.65384615]),\n",
       "   'test_f1_micro': array([0.83783784, 0.78378378, 0.7027027 , 0.72972973, 0.86486486,\n",
       "          0.61111111, 0.91666667, 0.75      , 0.75      , 0.72222222]),\n",
       "   'test_f1_weighted': array([0.83611794, 0.78378378, 0.6823166 , 0.71543659, 0.86237962,\n",
       "          0.56161616, 0.91633884, 0.72981366, 0.71848739, 0.67948718]),\n",
       "   'test_accuracy': array([0.83783784, 0.78378378, 0.7027027 , 0.72972973, 0.86486486,\n",
       "          0.61111111, 0.91666667, 0.75      , 0.75      , 0.72222222])},\n",
       "  {'fit_time': array([136.33170891, 115.679317  , 131.13600707, 124.73968792,\n",
       "          163.64897108, 135.57495904, 104.53207803, 116.36341   ,\n",
       "          132.8523891 , 112.89384103]),\n",
       "   'score_time': array([0.242136  , 0.23562503, 0.22091103, 0.2250092 , 0.21759295,\n",
       "          0.21331406, 0.24272513, 0.23351693, 0.22166514, 0.23506403]),\n",
       "   'test_precision_macro': array([0.82589286, 0.83482143, 0.67333333, 0.8128655 , 0.67397661,\n",
       "          0.60769231, 0.8961039 , 0.65551839, 0.72363636, 0.77339901]),\n",
       "   'test_recall_macro': array([0.82589286, 0.83482143, 0.6547619 , 0.81845238, 0.67708333,\n",
       "          0.5875    , 0.88125   , 0.64761905, 0.6952381 , 0.67619048]),\n",
       "   'test_f1_macro': array([0.81081081, 0.83482143, 0.6552795 , 0.81025641, 0.67352941,\n",
       "          0.57859532, 0.88571429, 0.64935065, 0.69899666, 0.67272727]),\n",
       "   'test_f1_micro': array([0.81081081, 0.83783784, 0.67567568, 0.81081081, 0.67567568,\n",
       "          0.61111111, 0.88888889, 0.66666667, 0.72222222, 0.72222222]),\n",
       "   'test_f1_weighted': array([0.81081081, 0.83783784, 0.66661071, 0.81164241, 0.67710652,\n",
       "          0.59160164, 0.88783069, 0.66233766, 0.712932  , 0.69393939]),\n",
       "   'test_accuracy': array([0.81081081, 0.83783784, 0.67567568, 0.81081081, 0.67567568,\n",
       "          0.61111111, 0.88888889, 0.66666667, 0.72222222, 0.72222222])},\n",
       "  {'fit_time': array([0.42439485, 0.26297188, 0.25429296, 0.2549262 , 0.25179505,\n",
       "          0.30491304, 0.26004696, 0.28322697, 0.27186489, 0.25744915]),\n",
       "   'score_time': array([0.18905401, 0.17469025, 0.17589688, 0.17324495, 0.17169595,\n",
       "          0.17440701, 0.17499495, 0.172611  , 0.17115521, 0.17202806]),\n",
       "   'test_precision_macro': array([0.61481481, 0.828125  , 0.34455128, 0.70258621, 0.67333333,\n",
       "          0.66748768, 0.43939394, 0.5625    , 0.60645161, 0.60645161]),\n",
       "   'test_recall_macro': array([0.5922619 , 0.65625   , 0.35565476, 0.63988095, 0.6547619 ,\n",
       "          0.60625   , 0.48125   , 0.55714286, 0.55238095, 0.55238095]),\n",
       "   'test_f1_macro': array([0.5849359 , 0.63432165, 0.34789272, 0.63      , 0.6552795 ,\n",
       "          0.58473824, 0.39225422, 0.55555556, 0.51538462, 0.51538462]),\n",
       "   'test_f1_micro': array([0.62162162, 0.7027027 , 0.37837838, 0.67567568, 0.67567568,\n",
       "          0.63888889, 0.52777778, 0.58333333, 0.61111111, 0.61111111]),\n",
       "   'test_f1_weighted': array([0.60161123, 0.65569073, 0.36694626, 0.64756757, 0.66661071,\n",
       "          0.60139998, 0.42414212, 0.57407407, 0.55128205, 0.55128205]),\n",
       "   'test_accuracy': array([0.62162162, 0.7027027 , 0.37837838, 0.67567568, 0.67567568,\n",
       "          0.63888889, 0.52777778, 0.58333333, 0.61111111, 0.61111111])},\n",
       "  {'fit_time': array([0.17756319, 0.17717099, 0.17696834, 0.18355799, 0.17954302,\n",
       "          0.17754984, 0.17721701, 0.18035579, 0.18054509, 0.17760682]),\n",
       "   'score_time': array([0.29496408, 0.30485702, 0.32999873, 0.25885987, 0.27084708,\n",
       "          0.25319719, 0.253196  , 0.28675389, 0.28576183, 0.26531315]),\n",
       "   'test_precision_macro': array([0.49761905, 0.44086022, 0.6547619 , 0.78232759, 0.66925466,\n",
       "          0.51337793, 0.54545455, 0.80882353, 0.75      , 0.72258065]),\n",
       "   'test_recall_macro': array([0.4985119 , 0.4672619 , 0.61607143, 0.69494048, 0.66220238,\n",
       "          0.5125    , 0.54375   , 0.56666667, 0.75714286, 0.60952381]),\n",
       "   'test_f1_macro': array([0.46376812, 0.41783217, 0.60734694, 0.69166667, 0.66363636,\n",
       "          0.50922213, 0.54285714, 0.49946524, 0.74825175, 0.58461538]),\n",
       "   'test_f1_micro': array([0.54054054, 0.51351351, 0.64864865, 0.72972973, 0.67567568,\n",
       "          0.52777778, 0.55555556, 0.63888889, 0.75      , 0.66666667]),\n",
       "   'test_f1_weighted': array([0.49118684, 0.44972595, 0.62455598, 0.70630631, 0.67223587,\n",
       "          0.51982536, 0.55132275, 0.54349376, 0.75174825, 0.61538462]),\n",
       "   'test_accuracy': array([0.54054054, 0.51351351, 0.64864865, 0.72972973, 0.67567568,\n",
       "          0.52777778, 0.55555556, 0.63888889, 0.75      , 0.66666667])},\n",
       "  {'fit_time': array([4.1719389 , 4.10771799, 4.08781004, 4.07774091, 4.10379791,\n",
       "          4.08661795, 4.11985087, 4.07437968, 3.97170568, 3.96405625]),\n",
       "   'score_time': array([0.2620492 , 0.22201109, 0.2213819 , 0.22326303, 0.23323774,\n",
       "          0.219733  , 0.222785  , 0.21866226, 0.21992397, 0.21811604]),\n",
       "   'test_precision_macro': array([0.79117647, 0.75294118, 0.61458333, 0.72470238, 0.78416149,\n",
       "          0.63377926, 0.82380952, 0.56818182, 0.8       , 0.69615385]),\n",
       "   'test_recall_macro': array([0.79464286, 0.75595238, 0.61458333, 0.72470238, 0.77232143,\n",
       "          0.625     , 0.81875   , 0.56666667, 0.8047619 , 0.66190476]),\n",
       "   'test_f1_macro': array([0.78362573, 0.75388027, 0.61458333, 0.72470238, 0.77575758,\n",
       "          0.62469928, 0.80540541, 0.56696071, 0.80173092, 0.66297872]),\n",
       "   'test_f1_micro': array([0.78378378, 0.75675676, 0.62162162, 0.72972973, 0.78378378,\n",
       "          0.63888889, 0.80555556, 0.58333333, 0.80555556, 0.69444444]),\n",
       "   'test_f1_weighted': array([0.78441599, 0.75747588, 0.62162162, 0.72972973, 0.78149058,\n",
       "          0.63280763, 0.8048048 , 0.58099439, 0.80632048, 0.68014184]),\n",
       "   'test_accuracy': array([0.78378378, 0.75675676, 0.62162162, 0.72972973, 0.78378378,\n",
       "          0.63888889, 0.80555556, 0.58333333, 0.80555556, 0.69444444])},\n",
       "  {'fit_time': array([12.45611525, 11.90790772, 12.02213192, 12.23633003, 12.43812084,\n",
       "          12.52630019, 12.52424121, 12.76108408, 12.59282589, 12.29801416]),\n",
       "   'score_time': array([0.49285197, 0.47693729, 0.48063684, 0.50261712, 0.51537514,\n",
       "          0.48267078, 0.47455382, 0.48237181, 0.49167204, 0.4724617 ]),\n",
       "   'test_precision_macro': array([0.89035088, 0.75294118, 0.66925466, 0.80735294, 0.86515152,\n",
       "          0.54545455, 0.80959752, 0.76538462, 0.78909091, 0.77339901]),\n",
       "   'test_recall_macro': array([0.89732143, 0.75595238, 0.66220238, 0.8110119 , 0.85863095,\n",
       "          0.54375   , 0.8125    , 0.71904762, 0.75238095, 0.67619048]),\n",
       "   'test_f1_macro': array([0.89117647, 0.75388027, 0.66363636, 0.80857354, 0.8612153 ,\n",
       "          0.54285714, 0.80540541, 0.72425532, 0.75919732, 0.67272727]),\n",
       "   'test_f1_micro': array([0.89189189, 0.75675676, 0.67567568, 0.81081081, 0.86486486,\n",
       "          0.55555556, 0.80555556, 0.75      , 0.77777778, 0.72222222]),\n",
       "   'test_f1_weighted': array([0.89236884, 0.75747588, 0.67223587, 0.81137013, 0.8642566 ,\n",
       "          0.55132275, 0.80600601, 0.73829787, 0.7703456 , 0.69393939]),\n",
       "   'test_accuracy': array([0.89189189, 0.75675676, 0.67567568, 0.81081081, 0.86486486,\n",
       "          0.55555556, 0.80555556, 0.75      , 0.77777778, 0.72222222])}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_lz_london_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7ad6e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.284947</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.362989</td>\n",
       "      <td>0.569895</td>\n",
       "      <td>0.413811</td>\n",
       "      <td>0.569895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.805178</td>\n",
       "      <td>0.658185</td>\n",
       "      <td>0.635549</td>\n",
       "      <td>0.703754</td>\n",
       "      <td>0.657934</td>\n",
       "      <td>0.703754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.636666</td>\n",
       "      <td>0.632887</td>\n",
       "      <td>0.629784</td>\n",
       "      <td>0.640841</td>\n",
       "      <td>0.637810</td>\n",
       "      <td>0.640841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.737535</td>\n",
       "      <td>0.719196</td>\n",
       "      <td>0.717911</td>\n",
       "      <td>0.733859</td>\n",
       "      <td>0.726839</td>\n",
       "      <td>0.733859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.801534</td>\n",
       "      <td>0.739554</td>\n",
       "      <td>0.736178</td>\n",
       "      <td>0.766892</td>\n",
       "      <td>0.748578</td>\n",
       "      <td>0.766892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.747724</td>\n",
       "      <td>0.729881</td>\n",
       "      <td>0.727008</td>\n",
       "      <td>0.742192</td>\n",
       "      <td>0.735265</td>\n",
       "      <td>0.742192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.604570</td>\n",
       "      <td>0.564821</td>\n",
       "      <td>0.541575</td>\n",
       "      <td>0.602628</td>\n",
       "      <td>0.564061</td>\n",
       "      <td>0.602628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.638506</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.572866</td>\n",
       "      <td>0.624700</td>\n",
       "      <td>0.592579</td>\n",
       "      <td>0.624700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.718949</td>\n",
       "      <td>0.713929</td>\n",
       "      <td>0.711432</td>\n",
       "      <td>0.720345</td>\n",
       "      <td>0.717980</td>\n",
       "      <td>0.720345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.766798</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.748292</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.755762</td>\n",
       "      <td>0.761111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "SVM_linear                        0.284947      0.500000  0.362989  0.569895   \n",
       "SVM_RBF                           0.805178      0.658185  0.635549  0.703754   \n",
       "DecisionTreeClassifier            0.636666      0.632887  0.629784  0.640841   \n",
       "GaussianProcessClassifier         0.737535      0.719196  0.717911  0.733859   \n",
       "RandomForestClassifier            0.801534      0.739554  0.736178  0.766892   \n",
       "MLPClassifier                     0.747724      0.729881  0.727008  0.742192   \n",
       "GaussianNB                        0.604570      0.564821  0.541575  0.602628   \n",
       "KNeighborsClassifier              0.638506      0.592857  0.572866  0.624700   \n",
       "AdaBoostClassifier                0.718949      0.713929  0.711432  0.720345   \n",
       "XGBClassifier                     0.766798      0.748899  0.748292  0.761111   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "SVM_linear                    0.413811  0.569895  \n",
       "SVM_RBF                       0.657934  0.703754  \n",
       "DecisionTreeClassifier        0.637810  0.640841  \n",
       "GaussianProcessClassifier     0.726839  0.733859  \n",
       "RandomForestClassifier        0.748578  0.766892  \n",
       "MLPClassifier                 0.735265  0.742192  \n",
       "GaussianNB                    0.564061  0.602628  \n",
       "KNeighborsClassifier          0.592579  0.624700  \n",
       "AdaBoostClassifier            0.717980  0.720345  \n",
       "XGBClassifier                 0.755762  0.761111  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_lz_london_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0e606c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.753003003003003\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.6713963963963964\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7557057057057057\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.74504505 0.74782282 0.7475976  0.73400901 0.74219219 0.73408408\n",
      " 0.73956456 0.73956456 0.74504505 0.74782282 0.7475976  0.73400901\n",
      " 0.74219219 0.73408408 0.73956456 0.73956456 0.57815315 0.56989489\n",
      " 0.56989489 0.56989489 0.56989489 0.56989489 0.56989489 0.56989489\n",
      " 0.76396396 0.76674174 0.76674174 0.76411411 0.75870871 0.75307808\n",
      " 0.75315315 0.7475976  0.76396396 0.76674174 0.76674174 0.76411411\n",
      " 0.75870871 0.75307808 0.75315315 0.7475976  0.58355856 0.57267267\n",
      " 0.57545045 0.56989489 0.56989489 0.56989489 0.56989489 0.56989489\n",
      " 0.75315315 0.75315315 0.75600601 0.74774775 0.75045045 0.75307808\n",
      " 0.75848348 0.76118619 0.75315315 0.75315315 0.75600601 0.74774775\n",
      " 0.75045045 0.75307808 0.75848348 0.76118619 0.59737237 0.57267267\n",
      " 0.58085586 0.5725976  0.5725976  0.5725976  0.5753003  0.5753003\n",
      " 0.74504505 0.75578078 0.76666667 0.75840841 0.74767267 0.75585586\n",
      " 0.75848348 0.75855856 0.74504505 0.75578078 0.76666667 0.75840841\n",
      " 0.74767267 0.75585586 0.75848348 0.75855856 0.58385886 0.58348348\n",
      " 0.58348348 0.5725976  0.5725976  0.5753003  0.578003   0.578003\n",
      " 0.75555556 0.75315315 0.75593093 0.76689189 0.75307808 0.75052553\n",
      " 0.753003   0.76674174 0.75555556 0.75315315 0.75593093 0.76689189\n",
      " 0.75307808 0.75052553 0.753003   0.76674174 0.60818318 0.59451952\n",
      " 0.59722222 0.58903904 0.57807808 0.57807808 0.58618619 0.58070571\n",
      " 0.75052553 0.75292793 0.74767267 0.76974474 0.76148649 0.75863363\n",
      " 0.75855856 0.76411411 0.75052553 0.75292793 0.74767267 0.76974474\n",
      " 0.76148649 0.75863363 0.75855856 0.76411411 0.63033033 0.61358859\n",
      " 0.61073574 0.59444444 0.58626126 0.58618619 0.58618619 0.59159159\n",
      " 0.76141141 0.75052553 0.76126126 0.76951952 0.76118619 0.76396396\n",
      " 0.76126126 0.7722973  0.76141141 0.75052553 0.76126126 0.76951952\n",
      " 0.76118619 0.76396396 0.76126126 0.7722973  0.64091592 0.61629129\n",
      " 0.60818318 0.59984985 0.58626126 0.58903904 0.59174174 0.59166667\n",
      " 0.75585586 0.75315315 0.76411411 0.76681682 0.7506006  0.76959459\n",
      " 0.76959459 0.76696697 0.75585586 0.75315315 0.76411411 0.76681682\n",
      " 0.7506006  0.76959459 0.76959459 0.76696697 0.64924925 0.63025526\n",
      " 0.62732733 0.60540541 0.59174174 0.59984985 0.61088589 0.60548048\n",
      " 0.74489489 0.76126126 0.76944444 0.775      0.76396396 0.76126126\n",
      " 0.75848348 0.76681682 0.74489489 0.76126126 0.76944444 0.775\n",
      " 0.76396396 0.76126126 0.75848348 0.76681682 0.67124625 0.6710961\n",
      " 0.64924925 0.63543544 0.62177177 0.62462462 0.63280781 0.61351351\n",
      " 0.73971471 0.73963964 0.75322823 0.74496997 0.73956456 0.74234234\n",
      " 0.74226727 0.73686186 0.73971471 0.73963964 0.75322823 0.74496997\n",
      " 0.73956456 0.74234234 0.74226727 0.73686186 0.57274775 0.56989489\n",
      " 0.56989489 0.56989489 0.56989489 0.56989489 0.56989489 0.56989489\n",
      " 0.73408408 0.75045045 0.76133634 0.75037538 0.76951952 0.75870871\n",
      " 0.75593093 0.75863363 0.73408408 0.75045045 0.76133634 0.75037538\n",
      " 0.76951952 0.75870871 0.75593093 0.75863363 0.58626126 0.578003\n",
      " 0.57267267 0.56989489 0.56989489 0.56989489 0.5725976  0.56989489\n",
      " 0.73123123 0.73941441 0.75585586 0.753003   0.75037538 0.75037538\n",
      " 0.74767267 0.75045045 0.73123123 0.73941441 0.75585586 0.753003\n",
      " 0.75037538 0.75037538 0.74767267 0.75045045 0.6027027  0.578003\n",
      " 0.5753003  0.5725976  0.5725976  0.5753003  0.578003   0.578003\n",
      " 0.74226727 0.75067568 0.75600601 0.75052553 0.75600601 0.75322823\n",
      " 0.75585586 0.76141141 0.74226727 0.75067568 0.75600601 0.75052553\n",
      " 0.75600601 0.75322823 0.75585586 0.76141141 0.58911411 0.58626126\n",
      " 0.58618619 0.58070571 0.5725976  0.5753003  0.578003   0.578003\n",
      " 0.73671171 0.74512012 0.74512012 0.75067568 0.75337838 0.7533033\n",
      " 0.75870871 0.75878378 0.73671171 0.74512012 0.74512012 0.75067568\n",
      " 0.75337838 0.7533033  0.75870871 0.75878378 0.61088589 0.60525526\n",
      " 0.59166667 0.58633634 0.57807808 0.58348348 0.578003   0.58070571\n",
      " 0.76156156 0.75322823 0.76681682 0.76148649 0.75870871 0.75870871\n",
      " 0.76133634 0.75863363 0.76156156 0.75322823 0.76681682 0.76148649\n",
      " 0.75870871 0.75870871 0.76133634 0.75863363 0.63018018 0.61081081\n",
      " 0.60247748 0.60255255 0.58896396 0.58896396 0.59166667 0.58881381\n",
      " 0.73671171 0.75870871 0.75315315 0.76126126 0.76944444 0.76396396\n",
      " 0.77214715 0.76951952 0.73671171 0.75870871 0.75315315 0.76126126\n",
      " 0.76944444 0.76396396 0.77214715 0.76951952 0.62184685 0.6271021\n",
      " 0.61899399 0.60540541 0.6        0.5972973  0.60262763 0.59984985\n",
      " 0.75015015 0.76388889 0.7722973  0.76681682 0.76951952 0.76411411\n",
      " 0.75870871 0.76418919 0.75015015 0.76388889 0.7722973  0.76681682\n",
      " 0.76951952 0.76411411 0.75870871 0.76418919 0.6274024  0.61366366\n",
      " 0.62177177 0.61081081 0.59984985 0.60803303 0.60533033 0.60795796\n",
      " 0.76951952 0.77507508 0.76396396 0.76951952 0.76959459 0.76411411\n",
      " 0.76951952 0.76959459 0.76951952 0.77507508 0.76396396 0.76951952\n",
      " 0.76959459 0.76411411 0.76951952 0.76959459 0.6493994  0.63273273\n",
      " 0.64887387 0.63521021 0.62147147 0.61606607 0.63258258 0.62154655\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.92664393 0.94094633 0.94612091 0.94854974 0.95068574 0.9509934\n",
      " 0.95251501 0.95037901 0.92664393 0.94094633 0.94612091 0.94854974\n",
      " 0.95068574 0.9509934  0.95251501 0.95037901 0.66331455 0.63257469\n",
      " 0.62770313 0.61187542 0.60426551 0.60243902 0.59634332 0.59147546\n",
      " 0.96651716 0.97960375 0.98112351 0.98416673 0.98599507 0.98660483\n",
      " 0.98721551 0.98599785 0.96651716 0.97960375 0.98112351 0.98416673\n",
      " 0.98599507 0.98660483 0.98721551 0.98599785 0.73211969 0.70927144\n",
      " 0.71597042 0.702275   0.69862759 0.69100749 0.68949329 0.6852389\n",
      " 0.9838637  0.99360868 0.99543517 0.9954361  0.99634888 0.99817629\n",
      " 0.9993921  0.99969605 0.9838637  0.99360868 0.99543517 0.9954361\n",
      " 0.99634888 0.99817629 0.9993921  0.99969605 0.81582308 0.81003596\n",
      " 0.8228223  0.80882571 0.81278078 0.81065405 0.81126381 0.80091556\n",
      " 0.99604215 0.99878141 0.99908537 0.99908537 1.         1.\n",
      " 1.         1.         0.99604215 0.99878141 0.99908537 0.99908537\n",
      " 1.         1.         1.         1.         0.86877456 0.88735451\n",
      " 0.90227778 0.89223719 0.89680295 0.89650085 0.90258359 0.89862573\n",
      " 0.99878141 0.99969605 1.         1.         1.         1.\n",
      " 1.         1.         0.99878141 0.99969605 1.         1.\n",
      " 1.         1.         1.         1.         0.91292257 0.93728316\n",
      " 0.94854882 0.94245867 0.94794369 0.95220643 0.95707521 0.95494477\n",
      " 0.99969512 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969512 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94062384 0.96620024\n",
      " 0.97473312 0.97382219 0.97351638 0.97747516 0.97990678 0.9792998\n",
      " 0.99939117 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99939117 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96437375 0.97716936\n",
      " 0.98569205 0.98721273 0.98873619 0.9893478  0.99086663 0.9899557\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97076785 0.98599785\n",
      " 0.99086663 0.99391078 0.99482634 0.99421751 0.99482356 0.99543239\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98447161 0.99178219\n",
      " 0.99634702 0.9963461  0.99695678 0.99695585 0.99786771 0.99786585\n",
      " 0.92359886 0.93302876 0.93394803 0.93181945 0.93821354 0.93760101\n",
      " 0.93425198 0.93212154 0.92359886 0.93302876 0.93394803 0.93181945\n",
      " 0.93821354 0.93760101 0.93425198 0.93212154 0.66057899 0.62008674\n",
      " 0.61217288 0.59482263 0.59208151 0.5899557  0.58538253 0.58447253\n",
      " 0.95373545 0.9713878  0.97321151 0.97625473 0.97869282 0.9802098\n",
      " 0.97990678 0.98203722 0.95373545 0.9713878  0.97321151 0.97625473\n",
      " 0.97869282 0.9802098  0.97990678 0.98203722 0.72115057 0.69436578\n",
      " 0.69467529 0.67579695 0.66787197 0.66695641 0.66422641 0.65570743\n",
      " 0.98052487 0.98934688 0.99177941 0.99360405 0.99451868 0.99482356\n",
      " 0.99695493 0.99756468 0.98052487 0.98934688 0.99177941 0.99360405\n",
      " 0.99451868 0.99482356 0.99695493 0.99756468 0.79817166 0.78113092\n",
      " 0.79269127 0.77808121 0.77350341 0.77564219 0.77473404 0.76621506\n",
      " 0.99269405 0.99695585 0.99817259 0.99756283 0.99878141 0.99939117\n",
      " 0.99908629 0.99969512 0.99269405 0.99695585 0.99817259 0.99756283\n",
      " 0.99878141 0.99939117 0.99908629 0.99969512 0.85236582 0.86026855\n",
      " 0.87396953 0.86301709 0.86057621 0.86666636 0.87001353 0.86574802\n",
      " 0.99695863 0.99969605 0.99969512 1.         1.         1.\n",
      " 1.         1.         0.99695863 0.99969605 0.99969512 1.\n",
      " 1.         1.         1.         1.         0.89315924 0.91202647\n",
      " 0.9287651  0.92785232 0.92846486 0.93181389 0.93729242 0.93759174\n",
      " 0.99878327 0.99969605 1.         1.         1.         1.\n",
      " 1.         1.         0.99878327 0.99969605 1.         1.\n",
      " 1.         1.         1.         1.         0.92938691 0.94734506\n",
      " 0.96073282 0.96225443 0.96560623 0.96682297 0.97138594 0.96986526\n",
      " 0.99969512 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969512 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95342223 0.9686476\n",
      " 0.97930258 0.98173326 0.98478112 0.98356346 0.98599692 0.98721551\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96864297 0.98204\n",
      " 0.98843317 0.99147639 0.99056453 0.99238824 0.99208614 0.99360683\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98173419 0.98873434\n",
      " 0.99177941 0.99421473 0.99543332 0.99482449 0.99604215 0.9966519\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7750750750750751\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.6271771771771772\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6246996996996997\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.7584084084084084\n",
      "testing classifiers: ['XGBClassifier']\n",
      "running: XGBClassifier\n",
      "0.794069069069069\n"
     ]
    }
   ],
   "source": [
    "burchard_lz_london_greed_rearch_resp = []\n",
    "for cls in [\n",
    "    'SVC', \n",
    "    'DecisionTreeClassifier', \n",
    "    'GaussianProcessClassifier', \n",
    "    'RandomForestClassifier', \n",
    "    'GaussianNB', \n",
    "    'KNeighborsClassifier', \n",
    "    'AdaBoostClassifier', \n",
    "    'XGBClassifier'\n",
    "]:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_lz_london_features_df, [cls])\n",
    "    burchard_lz_london_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58e2af4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.753003003003003],\n",
       " ['DecisionTreeClassifier', 0.6713963963963964],\n",
       " ['GaussianProcessClassifier', 0.7557057057057057],\n",
       " ['RandomForestClassifier', 0.7750750750750751],\n",
       " ['GaussianNB', 0.6271771771771772],\n",
       " ['KNeighborsClassifier', 0.6246996996996997],\n",
       " ['AdaBoostClassifier', 0.7584084084084084],\n",
       " ['XGBClassifier', 0.794069069069069]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_lz_london_greed_rearch_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "674137e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['XGBClassifier']\n",
      "running: XGBClassifier\n",
      "0.794069069069069\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.4, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=3,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_lz_london_features_df, ['XGBClassifier'])\n",
    "print(grid_search_cv_result[1][0].best_score_)\n",
    "print(grid_search_cv_result[1][0].best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e364afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.4, 'max_depth': 9, 'min_child_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_cv_result[1][0].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60d9740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = thesisModelFeatures.create_X_y(burchard_lz_london_features_df)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "XGBClassifier_burchard_lz = xgb.XGBClassifier(gamma = 0.4, max_depth = 9, min_child_weight = 3).fit(X, y_encoded)\n",
    "thesisModelFeatures.save_london_vs_burchard_best_model(\n",
    "    XGBClassifier_burchard_lz,\n",
    "    'burchard_lz_XGBClassifier(gamma = 0.4, max_depth = 9, min_child_weight = 3)_0.79406'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d7ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34337632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99faf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a0a5e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_london_features_df = thesisModelFeatures.create_features_df(\n",
    "    london_leftofvers_long,\n",
    "    None,\n",
    "    burchard_zl_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c15d103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n",
      "running: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_london_result = thesisModelFeatures.run_models(\n",
    "    burchard_zl_london_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77211a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       " SVM_linear                        0.284347      0.500000  0.362497  0.568694   \n",
       " SVM_RBF                           0.756748      0.610565  0.574762  0.658934   \n",
       " DecisionTreeClassifier            0.693412      0.686696  0.684231  0.694820   \n",
       " GaussianProcessClassifier         0.751322      0.721696  0.721269  0.738363   \n",
       " RandomForestClassifier            0.761028      0.704464  0.701412  0.730631   \n",
       " MLPClassifier                     0.744924      0.728125  0.726809  0.741066   \n",
       " GaussianNB                        0.572023      0.546905  0.523554  0.585135   \n",
       " KNeighborsClassifier              0.598200      0.566577  0.547757  0.593844   \n",
       " AdaBoostClassifier                0.705674      0.691101  0.686170  0.700075   \n",
       " XGBClassifier                     0.747152      0.728958  0.727342  0.746697   \n",
       " \n",
       "                            f1_weighted  accuracy  \n",
       " SVM_linear                    0.412394  0.568694  \n",
       " SVM_RBF                       0.601055  0.658934  \n",
       " DecisionTreeClassifier        0.691294  0.694820  \n",
       " GaussianProcessClassifier     0.730126  0.738363  \n",
       " RandomForestClassifier        0.713913  0.730631  \n",
       " MLPClassifier                 0.734884  0.741066  \n",
       " GaussianNB                    0.546757  0.585135  \n",
       " KNeighborsClassifier          0.566142  0.593844  \n",
       " AdaBoostClassifier            0.693903  0.700075  \n",
       " XGBClassifier                 0.737281  0.746697  ,\n",
       " [{'fit_time': array([22.89978814, 13.14906907,  5.7983551 ,  6.12110305,  5.91459584,\n",
       "           6.66867685,  6.18312716,  5.98741794,  5.84809184,  5.86036801]),\n",
       "   'score_time': array([1.41951895, 0.82463288, 0.77944994, 0.82756996, 1.5519228 ,\n",
       "          0.76598907, 0.79578376, 0.74052811, 0.80412602, 0.7653439 ]),\n",
       "   'test_precision_macro': array([0.28378378, 0.28378378, 0.28378378, 0.28378378, 0.27777778,\n",
       "          0.27777778, 0.27777778, 0.29166667, 0.29166667, 0.29166667]),\n",
       "   'test_recall_macro': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "   'test_f1_macro': array([0.36206897, 0.36206897, 0.36206897, 0.36206897, 0.35714286,\n",
       "          0.35714286, 0.35714286, 0.36842105, 0.36842105, 0.36842105]),\n",
       "   'test_f1_micro': array([0.56756757, 0.56756757, 0.56756757, 0.56756757, 0.55555556,\n",
       "          0.55555556, 0.55555556, 0.58333333, 0.58333333, 0.58333333]),\n",
       "   'test_f1_weighted': array([0.4109972 , 0.4109972 , 0.4109972 , 0.4109972 , 0.3968254 ,\n",
       "          0.3968254 , 0.3968254 , 0.42982456, 0.42982456, 0.42982456]),\n",
       "   'test_accuracy': array([0.56756757, 0.56756757, 0.56756757, 0.56756757, 0.55555556,\n",
       "          0.55555556, 0.55555556, 0.58333333, 0.58333333, 0.58333333])},\n",
       "  {'fit_time': array([ 6.19749212,  6.18405914,  6.32809591,  6.14566803, 11.55399513,\n",
       "          12.17757893, 10.55559611, 11.32001185, 10.52664018, 11.11179376]),\n",
       "   'score_time': array([1.20592093, 1.16994596, 1.21740294, 1.15514898, 1.73048663,\n",
       "          2.03256989, 1.81746387, 1.75763416, 1.73312879, 1.73418498]),\n",
       "   'test_precision_macro': array([0.828125  , 0.828125  , 0.7125    , 0.75185185, 0.8125    ,\n",
       "          0.59032258, 0.60769231, 0.81818182, 0.8       , 0.81818182]),\n",
       "   'test_recall_macro': array([0.65625   , 0.65625   , 0.60119048, 0.70238095, 0.625     ,\n",
       "          0.54375   , 0.5875    , 0.6       , 0.53333333, 0.6       ]),\n",
       "   'test_f1_macro': array([0.63432165, 0.63432165, 0.56783468, 0.70352564, 0.58461538,\n",
       "          0.49579832, 0.57859532, 0.55555556, 0.4375    , 0.55555556]),\n",
       "   'test_f1_micro': array([0.7027027 , 0.7027027 , 0.64864865, 0.72972973, 0.66666667,\n",
       "          0.58333333, 0.61111111, 0.66666667, 0.61111111, 0.66666667]),\n",
       "   'test_f1_weighted': array([0.65569073, 0.65569073, 0.59308905, 0.71543659, 0.60512821,\n",
       "          0.51914099, 0.59160164, 0.59259259, 0.48958333, 0.59259259]),\n",
       "   'test_accuracy': array([0.7027027 , 0.7027027 , 0.64864865, 0.72972973, 0.66666667,\n",
       "          0.58333333, 0.61111111, 0.66666667, 0.61111111, 0.66666667])},\n",
       "  {'fit_time': array([0.73930407, 0.66710806, 0.57083797, 0.69835401, 0.67543602,\n",
       "          0.62286592, 0.7307539 , 0.76364207, 0.61355495, 0.55996585]),\n",
       "   'score_time': array([0.17010689, 0.16434789, 0.20627618, 0.16715193, 0.16415429,\n",
       "          0.16194892, 0.16386414, 0.17098904, 0.16081882, 0.16553116]),\n",
       "   'test_precision_macro': array([0.7797619 , 0.75877193, 0.64102564, 0.69545455, 0.61111111,\n",
       "          0.72916667, 0.72222222, 0.77591973, 0.5625    , 0.65818182]),\n",
       "   'test_recall_macro': array([0.7797619 , 0.76339286, 0.63095238, 0.69196429, 0.6125    ,\n",
       "          0.70625   , 0.725     , 0.76190476, 0.55714286, 0.63809524]),\n",
       "   'test_f1_macro': array([0.7797619 , 0.75604396, 0.63141762, 0.6754386 , 0.60990712,\n",
       "          0.70779221, 0.72136223, 0.76623377, 0.55555556, 0.63879599]),\n",
       "   'test_f1_micro': array([0.78378378, 0.75675676, 0.64864865, 0.67567568, 0.61111111,\n",
       "          0.72222222, 0.72222222, 0.77777778, 0.58333333, 0.66666667]),\n",
       "   'test_f1_weighted': array([0.78378378, 0.75782596, 0.64218701, 0.6742532 , 0.6123151 ,\n",
       "          0.71500722, 0.72308222, 0.77489177, 0.57407407, 0.65551839]),\n",
       "   'test_accuracy': array([0.78378378, 0.75675676, 0.64864865, 0.67567568, 0.61111111,\n",
       "          0.72222222, 0.72222222, 0.77777778, 0.58333333, 0.66666667])},\n",
       "  {'fit_time': array([32.93389583, 27.94167495, 35.28829002, 30.27203918, 35.60880184,\n",
       "          33.13615513, 30.36602402, 32.96109796, 25.34460473, 35.49258494]),\n",
       "   'score_time': array([0.77255917, 0.77368307, 0.76407003, 0.7656498 , 0.75477815,\n",
       "          0.77380991, 0.74609685, 0.7466979 , 0.74452114, 0.7443819 ]),\n",
       "   'test_precision_macro': array([0.85833333, 0.83482143, 0.735     , 0.78216374, 0.66666667,\n",
       "          0.5735786 , 0.75386997, 0.79464286, 0.74074074, 0.77339901]),\n",
       "   'test_recall_macro': array([0.81994048, 0.83482143, 0.70982143, 0.78720238, 0.66875   ,\n",
       "          0.56875   , 0.75625   , 0.70952381, 0.68571429, 0.67619048]),\n",
       "   'test_f1_macro': array([0.82763975, 0.83482143, 0.71273292, 0.78235294, 0.66563467,\n",
       "          0.56696071, 0.74980695, 0.71251109, 0.6875    , 0.67272727]),\n",
       "   'test_f1_micro': array([0.83783784, 0.83783784, 0.72972973, 0.78378378, 0.66666667,\n",
       "          0.58333333, 0.75      , 0.75      , 0.72222222, 0.72222222]),\n",
       "   'test_f1_weighted': array([0.83330536, 0.83783784, 0.72217559, 0.78473768, 0.66769866,\n",
       "          0.57631649, 0.75057915, 0.72981366, 0.70486111, 0.69393939]),\n",
       "   'test_accuracy': array([0.83783784, 0.83783784, 0.72972973, 0.78378378, 0.66666667,\n",
       "          0.58333333, 0.75      , 0.75      , 0.72222222, 0.72222222])},\n",
       "  {'fit_time': array([0.71747994, 0.56563401, 0.57272601, 0.55292392, 0.56673789,\n",
       "          0.54974484, 0.55343485, 0.55578279, 0.55789709, 0.54808092]),\n",
       "   'score_time': array([0.18235111, 0.16846704, 0.16795397, 0.1668098 , 0.1690619 ,\n",
       "          0.17046809, 0.16617012, 0.16684008, 0.16907167, 0.16600013]),\n",
       "   'test_precision_macro': array([0.81891026, 0.75294118, 0.7281746 , 0.70979021, 0.85416667,\n",
       "          0.57407407, 0.72222222, 0.85      , 0.85      , 0.75      ]),\n",
       "   'test_recall_macro': array([0.79613095, 0.75595238, 0.67113095, 0.67857143, 0.81875   ,\n",
       "          0.55625   , 0.725     , 0.7       , 0.7       , 0.64285714]),\n",
       "   'test_f1_macro': array([0.80153257, 0.75388027, 0.6677551 , 0.67927502, 0.82467532,\n",
       "          0.54042553, 0.72136223, 0.69747899, 0.69747899, 0.6302521 ]),\n",
       "   'test_f1_micro': array([0.81081081, 0.75675676, 0.7027027 , 0.7027027 , 0.83333333,\n",
       "          0.58333333, 0.72222222, 0.75      , 0.75      , 0.69444444]),\n",
       "   'test_f1_weighted': array([0.80733147, 0.75747588, 0.6823166 , 0.69098886, 0.82900433,\n",
       "          0.55602837, 0.72308222, 0.71848739, 0.71848739, 0.65592904]),\n",
       "   'test_accuracy': array([0.81081081, 0.75675676, 0.7027027 , 0.7027027 , 0.83333333,\n",
       "          0.58333333, 0.72222222, 0.75      , 0.75      , 0.69444444])},\n",
       "  {'fit_time': array([157.79890418, 112.71357608, 121.75196028, 115.83118415,\n",
       "          137.88742614, 144.02765608, 119.12930417, 120.60455394,\n",
       "          120.68428683, 133.86304903]),\n",
       "   'score_time': array([0.22455883, 0.24000406, 0.22150278, 0.2490499 , 0.25428295,\n",
       "          0.23108292, 0.23470402, 0.22665071, 0.2272191 , 0.28651476]),\n",
       "   'test_precision_macro': array([0.86515152, 0.83625731, 0.735     , 0.78216374, 0.69195046,\n",
       "          0.5735786 , 0.7875    , 0.81481481, 0.69615385, 0.66666667]),\n",
       "   'test_recall_macro': array([0.85863095, 0.8422619 , 0.70982143, 0.78720238, 0.69375   ,\n",
       "          0.56875   , 0.7875    , 0.74285714, 0.66190476, 0.62857143]),\n",
       "   'test_f1_macro': array([0.8612153 , 0.83676471, 0.71273292, 0.78235294, 0.69230769,\n",
       "          0.56696071, 0.77777778, 0.75      , 0.66297872, 0.625     ]),\n",
       "   'test_f1_micro': array([0.86486486, 0.83783784, 0.72972973, 0.78378378, 0.69444444,\n",
       "          0.58333333, 0.77777778, 0.77777778, 0.69444444, 0.66666667]),\n",
       "   'test_f1_weighted': array([0.8642566 , 0.83855326, 0.72217559, 0.78473768, 0.6951567 ,\n",
       "          0.57631649, 0.77777778, 0.76388889, 0.68014184, 0.64583333]),\n",
       "   'test_accuracy': array([0.86486486, 0.83783784, 0.72972973, 0.78378378, 0.69444444,\n",
       "          0.58333333, 0.77777778, 0.77777778, 0.69444444, 0.66666667])},\n",
       "  {'fit_time': array([0.43823576, 0.26766586, 0.26006103, 0.25952673, 0.28401089,\n",
       "          0.25482512, 0.2560451 , 0.27367806, 0.25498199, 0.2558651 ]),\n",
       "   'score_time': array([0.19192195, 0.17569613, 0.17255592, 0.17344737, 0.17771387,\n",
       "          0.17679191, 0.17447495, 0.17553711, 0.17534685, 0.17365193]),\n",
       "   'test_precision_macro': array([0.61481481, 0.7125    , 0.40384615, 0.67380952, 0.66666667,\n",
       "          0.57407407, 0.23333333, 0.68472906, 0.55      , 0.60645161]),\n",
       "   'test_recall_macro': array([0.5922619 , 0.60119048, 0.41071429, 0.60863095, 0.65      ,\n",
       "          0.55625   , 0.35      , 0.61904762, 0.52857143, 0.55238095]),\n",
       "   'test_f1_macro': array([0.5849359 , 0.56783468, 0.4045977 , 0.58994032, 0.64935065,\n",
       "          0.54042553, 0.28      , 0.60727273, 0.49579832, 0.51538462]),\n",
       "   'test_f1_micro': array([0.62162162, 0.64864865, 0.43243243, 0.64864865, 0.66666667,\n",
       "          0.58333333, 0.38888889, 0.66666667, 0.58333333, 0.61111111]),\n",
       "   'test_f1_weighted': array([0.60161123, 0.59308905, 0.42199441, 0.61090758, 0.65800866,\n",
       "          0.55602837, 0.31111111, 0.63272727, 0.53081232, 0.55128205]),\n",
       "   'test_accuracy': array([0.62162162, 0.64864865, 0.43243243, 0.64864865, 0.66666667,\n",
       "          0.58333333, 0.38888889, 0.66666667, 0.58333333, 0.61111111])},\n",
       "  {'fit_time': array([0.1785059 , 0.17871404, 0.17842793, 0.17976499, 0.18318295,\n",
       "          0.18043208, 0.18347621, 0.18472028, 0.18397999, 0.18468118]),\n",
       "   'score_time': array([0.3214252 , 0.31280017, 0.31281304, 0.28304219, 0.32486987,\n",
       "          0.28577709, 0.28828597, 0.28197765, 0.26834583, 0.30033898]),\n",
       "   'test_precision_macro': array([0.58134921, 0.44086022, 0.5462963 , 0.51573427, 0.72077922,\n",
       "          0.46190476, 0.55      , 0.80882353, 0.70625   , 0.65      ]),\n",
       "   'test_recall_macro': array([0.5610119 , 0.4672619 , 0.53720238, 0.51339286, 0.7125    ,\n",
       "          0.4625    , 0.55      , 0.56666667, 0.70952381, 0.58571429]),\n",
       "   'test_f1_macro': array([0.54693878, 0.41783217, 0.52564103, 0.50433412, 0.71428571,\n",
       "          0.46184107, 0.55      , 0.49946524, 0.69420849, 0.56302521]),\n",
       "   'test_f1_micro': array([0.59459459, 0.51351351, 0.56756757, 0.54054054, 0.72222222,\n",
       "          0.47222222, 0.55555556, 0.63888889, 0.69444444, 0.63888889]),\n",
       "   'test_f1_weighted': array([0.56679537, 0.44972595, 0.54469854, 0.52243733, 0.71957672,\n",
       "          0.47014599, 0.55555556, 0.54349376, 0.6956242 , 0.59337068]),\n",
       "   'test_accuracy': array([0.59459459, 0.51351351, 0.56756757, 0.54054054, 0.72222222,\n",
       "          0.47222222, 0.55555556, 0.63888889, 0.69444444, 0.63888889])},\n",
       "  {'fit_time': array([4.18535399, 4.21085405, 4.17357612, 4.27943301, 4.323627  ,\n",
       "          4.21678996, 4.15743303, 4.11756396, 4.04343104, 4.00935388]),\n",
       "   'score_time': array([0.26472211, 0.22767901, 0.2304008 , 0.22523522, 0.23956013,\n",
       "          0.22533894, 0.22250915, 0.24657702, 0.22248983, 0.22227311]),\n",
       "   'test_precision_macro': array([0.78416149, 0.75877193, 0.67397661, 0.75877193, 0.69814241,\n",
       "          0.54166667, 0.78762542, 0.6875    , 0.77339901, 0.59272727]),\n",
       "   'test_recall_macro': array([0.77232143, 0.76339286, 0.67708333, 0.76339286, 0.7       ,\n",
       "          0.5375    , 0.76875   , 0.67142857, 0.67619048, 0.58095238]),\n",
       "   'test_f1_macro': array([0.77575758, 0.75604396, 0.67352941, 0.75604396, 0.69420849,\n",
       "          0.53246753, 0.74825175, 0.67407407, 0.67272727, 0.57859532]),\n",
       "   'test_f1_micro': array([0.78378378, 0.75675676, 0.67567568, 0.75675676, 0.69444444,\n",
       "          0.55555556, 0.75      , 0.69444444, 0.72222222, 0.61111111]),\n",
       "   'test_f1_weighted': array([0.78149058, 0.75782596, 0.67710652, 0.75782596, 0.6951523 ,\n",
       "          0.54401154, 0.74592075, 0.68765432, 0.69393939, 0.59810479]),\n",
       "   'test_accuracy': array([0.78378378, 0.75675676, 0.67567568, 0.75675676, 0.69444444,\n",
       "          0.55555556, 0.75      , 0.69444444, 0.72222222, 0.61111111])},\n",
       "  {'fit_time': array([13.39078903, 12.29541206, 12.39379215, 12.38013816, 12.77010512,\n",
       "          12.22756672, 12.70250201, 12.32564497, 12.52671003, 12.59634924]),\n",
       "   'score_time': array([0.50861502, 0.49327397, 0.49750805, 0.49395013, 0.48486876,\n",
       "          0.49283314, 0.48583007, 0.48778987, 0.49033689, 0.48542976]),\n",
       "   'test_precision_macro': array([0.86176471, 0.72470238, 0.75961538, 0.84161491, 0.81438127,\n",
       "          0.53846154, 0.85913313, 0.72363636, 0.79464286, 0.55357143]),\n",
       "   'test_recall_macro': array([0.86607143, 0.72470238, 0.74107143, 0.82738095, 0.79375   ,\n",
       "          0.53125   , 0.8625    , 0.6952381 , 0.70952381, 0.53809524]),\n",
       "   'test_f1_macro': array([0.86326681, 0.72470238, 0.74482759, 0.83181818, 0.797915  ,\n",
       "          0.51839465, 0.86013986, 0.69899666, 0.71251109, 0.52085182]),\n",
       "   'test_f1_micro': array([0.86486486, 0.72972973, 0.75675676, 0.83783784, 0.80555556,\n",
       "          0.55555556, 0.86111111, 0.72222222, 0.75      , 0.58333333]),\n",
       "   'test_f1_weighted': array([0.86526438, 0.72972973, 0.75228332, 0.83611794, 0.80228103,\n",
       "          0.53325901, 0.86143486, 0.712932  , 0.72981366, 0.54968944]),\n",
       "   'test_accuracy': array([0.86486486, 0.72972973, 0.75675676, 0.83783784, 0.80555556,\n",
       "          0.55555556, 0.86111111, 0.72222222, 0.75      , 0.58333333])}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zl_london_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30c5f06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.284347</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.362497</td>\n",
       "      <td>0.568694</td>\n",
       "      <td>0.412394</td>\n",
       "      <td>0.568694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.756748</td>\n",
       "      <td>0.610565</td>\n",
       "      <td>0.574762</td>\n",
       "      <td>0.658934</td>\n",
       "      <td>0.601055</td>\n",
       "      <td>0.658934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.693412</td>\n",
       "      <td>0.686696</td>\n",
       "      <td>0.684231</td>\n",
       "      <td>0.694820</td>\n",
       "      <td>0.691294</td>\n",
       "      <td>0.694820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.751322</td>\n",
       "      <td>0.721696</td>\n",
       "      <td>0.721269</td>\n",
       "      <td>0.738363</td>\n",
       "      <td>0.730126</td>\n",
       "      <td>0.738363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.761028</td>\n",
       "      <td>0.704464</td>\n",
       "      <td>0.701412</td>\n",
       "      <td>0.730631</td>\n",
       "      <td>0.713913</td>\n",
       "      <td>0.730631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.744924</td>\n",
       "      <td>0.728125</td>\n",
       "      <td>0.726809</td>\n",
       "      <td>0.741066</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.741066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.572023</td>\n",
       "      <td>0.546905</td>\n",
       "      <td>0.523554</td>\n",
       "      <td>0.585135</td>\n",
       "      <td>0.546757</td>\n",
       "      <td>0.585135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.598200</td>\n",
       "      <td>0.566577</td>\n",
       "      <td>0.547757</td>\n",
       "      <td>0.593844</td>\n",
       "      <td>0.566142</td>\n",
       "      <td>0.593844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.705674</td>\n",
       "      <td>0.691101</td>\n",
       "      <td>0.686170</td>\n",
       "      <td>0.700075</td>\n",
       "      <td>0.693903</td>\n",
       "      <td>0.700075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.747152</td>\n",
       "      <td>0.728958</td>\n",
       "      <td>0.727342</td>\n",
       "      <td>0.746697</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>0.746697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "SVM_linear                        0.284347      0.500000  0.362497  0.568694   \n",
       "SVM_RBF                           0.756748      0.610565  0.574762  0.658934   \n",
       "DecisionTreeClassifier            0.693412      0.686696  0.684231  0.694820   \n",
       "GaussianProcessClassifier         0.751322      0.721696  0.721269  0.738363   \n",
       "RandomForestClassifier            0.761028      0.704464  0.701412  0.730631   \n",
       "MLPClassifier                     0.744924      0.728125  0.726809  0.741066   \n",
       "GaussianNB                        0.572023      0.546905  0.523554  0.585135   \n",
       "KNeighborsClassifier              0.598200      0.566577  0.547757  0.593844   \n",
       "AdaBoostClassifier                0.705674      0.691101  0.686170  0.700075   \n",
       "XGBClassifier                     0.747152      0.728958  0.727342  0.746697   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "SVM_linear                    0.412394  0.568694  \n",
       "SVM_RBF                       0.601055  0.658934  \n",
       "DecisionTreeClassifier        0.691294  0.694820  \n",
       "GaussianProcessClassifier     0.730126  0.738363  \n",
       "RandomForestClassifier        0.713913  0.730631  \n",
       "MLPClassifier                 0.734884  0.741066  \n",
       "GaussianNB                    0.546757  0.585135  \n",
       "KNeighborsClassifier          0.566142  0.593844  \n",
       "AdaBoostClassifier            0.693903  0.700075  \n",
       "XGBClassifier                 0.737281  0.746697  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zl_london_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f8137cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.7575075075075076\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7225225225225226\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7383633633633634\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.70570571 0.74414414 0.73858859 0.74136637 0.73581081 0.73843844\n",
      " 0.74121622 0.73581081 0.70570571 0.74414414 0.73858859 0.74136637\n",
      " 0.73581081 0.73843844 0.74121622 0.73581081 0.57132132 0.5740991\n",
      " 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.72214715 0.74136637 0.74954955 0.74136637 0.74677177 0.74129129\n",
      " 0.74662162 0.73843844 0.72214715 0.74136637 0.74954955 0.74136637\n",
      " 0.74677177 0.74129129 0.74662162 0.73843844 0.58506006 0.5795045\n",
      " 0.5713964  0.5740991  0.56869369 0.57417417 0.56869369 0.56869369\n",
      " 0.73558559 0.74114114 0.73573574 0.75225225 0.75773273 0.74932432\n",
      " 0.7548048  0.74662162 0.73558559 0.74114114 0.73573574 0.75225225\n",
      " 0.75773273 0.74932432 0.7548048  0.74662162 0.58513514 0.58791291\n",
      " 0.57687688 0.5795045  0.5713964  0.5713964  0.5740991  0.5713964\n",
      " 0.71073574 0.72462462 0.74662162 0.75495495 0.75487988 0.74662162\n",
      " 0.7466967  0.75503003 0.71073574 0.72462462 0.74662162 0.75495495\n",
      " 0.75487988 0.74662162 0.7466967  0.75503003 0.61253754 0.59039039\n",
      " 0.59309309 0.58753754 0.58498498 0.57957958 0.57957958 0.5713964\n",
      " 0.74084084 0.74677177 0.7493994  0.75503003 0.75765766 0.74932432\n",
      " 0.7493994  0.74684685 0.74084084 0.74677177 0.7493994  0.75503003\n",
      " 0.75765766 0.74932432 0.7493994  0.74684685 0.63468468 0.62597598\n",
      " 0.61516517 0.60127628 0.59594595 0.59039039 0.58768769 0.58768769\n",
      " 0.73033033 0.75217718 0.74947447 0.76313814 0.76321321 0.75202703\n",
      " 0.75217718 0.75773273 0.73033033 0.75217718 0.74947447 0.76313814\n",
      " 0.76321321 0.75202703 0.75217718 0.75773273 0.61501502 0.61801802\n",
      " 0.6015015  0.60135135 0.59864865 0.60135135 0.59857357 0.59324324\n",
      " 0.71081081 0.73558559 0.73588589 0.75225225 0.74684685 0.74662162\n",
      " 0.7466967  0.75225225 0.71081081 0.73558559 0.73588589 0.75225225\n",
      " 0.74684685 0.74662162 0.7466967  0.75225225 0.6207958  0.6231982\n",
      " 0.60968468 0.62057057 0.62057057 0.62057057 0.61779279 0.61493994\n",
      " 0.7298048  0.76869369 0.7548048  0.76861862 0.76336336 0.76043544\n",
      " 0.76051051 0.76306306 0.7298048  0.76869369 0.7548048  0.76861862\n",
      " 0.76336336 0.76043544 0.76051051 0.76306306 0.59894895 0.6204955\n",
      " 0.61764264 0.61771772 0.61501502 0.61223724 0.61786787 0.60675676\n",
      " 0.73836336 0.76576577 0.76043544 0.76043544 0.77154655 0.76058559\n",
      " 0.75773273 0.76043544 0.73836336 0.76576577 0.76043544 0.76043544\n",
      " 0.77154655 0.76058559 0.75773273 0.76043544 0.61801802 0.63138138\n",
      " 0.61779279 0.63701201 0.6286036  0.62597598 0.62304805 0.63138138\n",
      " 0.71096096 0.73866366 0.74429429 0.73340841 0.7222973  0.725\n",
      " 0.73851351 0.74129129 0.71096096 0.73866366 0.74429429 0.73340841\n",
      " 0.7222973  0.725      0.73851351 0.74129129 0.57957958 0.5740991\n",
      " 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.73325826 0.75765766 0.75503003 0.75510511 0.73596096 0.74144144\n",
      " 0.75495495 0.75495495 0.73325826 0.75765766 0.75503003 0.75510511\n",
      " 0.73596096 0.74144144 0.75495495 0.75495495 0.59316817 0.58228228\n",
      " 0.5740991  0.5768018  0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.74384384 0.75773273 0.76328829 0.76328829 0.76058559 0.75503003\n",
      " 0.75225225 0.74684685 0.74384384 0.75773273 0.76328829 0.76328829\n",
      " 0.76058559 0.75503003 0.75225225 0.74684685 0.60713213 0.58498498\n",
      " 0.58776276 0.58220721 0.5740991  0.5713964  0.5740991  0.56869369\n",
      " 0.71689189 0.74414414 0.75518018 0.75247748 0.74414414 0.73866366\n",
      " 0.74136637 0.74684685 0.71689189 0.74414414 0.75518018 0.75247748\n",
      " 0.74414414 0.73866366 0.74136637 0.74684685 0.61253754 0.60142643\n",
      " 0.59324324 0.58228228 0.57957958 0.58228228 0.5795045  0.5795045\n",
      " 0.74947447 0.74947447 0.75217718 0.74947447 0.74121622 0.74662162\n",
      " 0.74391892 0.74129129 0.74947447 0.74947447 0.75217718 0.74947447\n",
      " 0.74121622 0.74662162 0.74391892 0.74129129 0.62627628 0.61246246\n",
      " 0.60412913 0.59587087 0.58761261 0.59039039 0.58761261 0.58490991\n",
      " 0.71651652 0.75518018 0.746997   0.76343844 0.74977477 0.74129129\n",
      " 0.74692192 0.74677177 0.71651652 0.75518018 0.746997   0.76343844\n",
      " 0.74977477 0.74129129 0.74692192 0.74677177 0.62094595 0.60960961\n",
      " 0.60705706 0.6042042  0.60690691 0.59864865 0.59864865 0.59039039\n",
      " 0.72755255 0.74954955 0.75487988 0.75247748 0.7496997  0.74421922\n",
      " 0.75225225 0.75503003 0.72755255 0.74954955 0.75487988 0.75247748\n",
      " 0.7496997  0.74421922 0.75225225 0.75503003 0.63168168 0.61794294\n",
      " 0.6262012  0.61261261 0.61794294 0.61786787 0.62327327 0.60142643\n",
      " 0.7466967  0.76876877 0.75780781 0.746997   0.73873874 0.75232733\n",
      " 0.75217718 0.74954955 0.7466967  0.76876877 0.75780781 0.746997\n",
      " 0.73873874 0.75232733 0.75217718 0.74954955 0.6289039  0.61531532\n",
      " 0.6207958  0.62364865 0.61801802 0.62072072 0.6262012  0.62334835\n",
      " 0.73288288 0.76599099 0.76614114 0.77184685 0.76343844 0.76328829\n",
      " 0.75780781 0.76051051 0.73288288 0.76599099 0.76614114 0.77184685\n",
      " 0.76343844 0.76328829 0.75780781 0.76051051 0.64271772 0.63430931\n",
      " 0.63986486 0.63978979 0.62605105 0.62064565 0.63693694 0.63145646\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.93162527 0.94566365 0.94657642 0.94626874 0.94657921 0.94840568\n",
      " 0.9471899  0.94688223 0.93162527 0.94566365 0.94657642 0.94626874\n",
      " 0.94657921 0.94840568 0.9471899  0.94688223 0.66210002 0.63309279\n",
      " 0.62728892 0.61873648 0.61232192 0.6080499  0.60408089 0.59736705\n",
      " 0.97375065 0.98442884 0.98534534 0.98473652 0.98382375 0.98596162\n",
      " 0.98657045 0.98473838 0.97375065 0.98442884 0.98534534 0.98473652\n",
      " 0.98382375 0.98596162 0.98657045 0.98473838 0.73626743 0.71794865\n",
      " 0.71337081 0.71397125 0.71305941 0.71091687 0.69779966 0.68955676\n",
      " 0.98901134 0.99603099 0.99572518 0.99602913 0.99694563 0.9972505\n",
      " 0.99847375 0.99877956 0.98901134 0.99603099 0.99572518 0.99602913\n",
      " 0.99694563 0.9972505  0.99847375 0.99877956 0.81562057 0.80739632\n",
      " 0.81197509 0.82509137 0.82386813 0.81776404 0.82172466 0.81257272\n",
      " 0.99481148 0.99816887 0.99908443 0.99969512 1.         1.\n",
      " 1.         1.         0.99481148 0.99816887 0.99908443 0.99969512\n",
      " 1.         1.         1.         1.         0.87423081 0.87820914\n",
      " 0.89407959 0.90599127 0.91178955 0.91178209 0.91544156 0.91330835\n",
      " 0.9972505  1.         1.         1.         1.         1.\n",
      " 1.         1.         0.9972505  1.         1.         1.\n",
      " 1.         1.         1.         1.         0.90964142 0.92947994\n",
      " 0.94413739 0.95177053 0.95634743 0.95756881 0.95970109 0.96305568\n",
      " 0.99938838 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99938838 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94871802 0.96001063\n",
      " 0.97161464 0.97558458 0.97680596 0.97832942 0.9822947  0.98443164\n",
      " 0.99908257 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99908257 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96488402 0.98107705\n",
      " 0.98535094 0.98962482 0.99206571 0.99236593 0.99419986 0.99359103\n",
      " 0.99969419 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969419 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97618315 0.98961923\n",
      " 0.99481148 0.99725144 0.99603379 0.99511636 0.99664261 0.99603192\n",
      " 0.99969419 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969419 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98870087 0.99480775\n",
      " 0.99755911 0.99847375 0.99816887 0.99786399 0.99847281 0.99786212\n",
      " 0.92613187 0.93253431 0.92887111 0.93070784 0.93222943 0.93223223\n",
      " 0.93131946 0.92948646 0.92613187 0.93253431 0.92887111 0.93070784\n",
      " 0.93222943 0.93223223 0.93131946 0.92948646 0.65079623 0.62331711\n",
      " 0.61568863 0.60377788 0.59828075 0.59767286 0.59156597 0.58821045\n",
      " 0.96001343 0.97130603 0.97222626 0.97405367 0.97649735 0.97863523\n",
      " 0.9786343  0.97649642 0.96001343 0.97130603 0.97222626 0.97405367\n",
      " 0.97649735 0.97863523 0.9786343  0.97649642 0.72191765 0.70360166\n",
      " 0.69199858 0.69168904 0.68406057 0.67154472 0.66971545 0.66238812\n",
      " 0.98015682 0.99023085 0.98961643 0.9890132  0.99114828 0.99145223\n",
      " 0.99420079 0.99420079 0.98015682 0.99023085 0.98961643 0.9890132\n",
      " 0.99114828 0.99145223 0.99420079 0.99420079 0.7905898  0.78938241\n",
      " 0.78175021 0.79366003 0.79518255 0.78663944 0.77869397 0.76831506\n",
      " 0.99084247 0.9963396  0.99755911 0.99694935 0.99847561 0.99939024\n",
      " 1.         1.         0.99084247 0.9963396  0.99755911 0.99694935\n",
      " 0.99847561 0.99939024 1.         1.         0.85379    0.85958921\n",
      " 0.86722048 0.87577944 0.88310677 0.88035355 0.8815684  0.88186768\n",
      " 0.99481055 0.99939024 1.         1.         1.         1.\n",
      " 1.         1.         0.99481055 0.99939024 1.         1.\n",
      " 1.         1.         1.         1.         0.89407399 0.91514694\n",
      " 0.92979973 0.93682498 0.93987283 0.93926027 0.94780245 0.94658201\n",
      " 0.99694469 0.99969512 1.         1.         1.         1.\n",
      " 1.         1.         0.99694469 0.99969512 1.         1.\n",
      " 1.         1.         1.         1.         0.92826788 0.94780525\n",
      " 0.96276385 0.96642612 0.97069814 0.97130883 0.97802081 0.97650015\n",
      " 0.99908443 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99908443 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.9517724  0.97131256\n",
      " 0.98169333 0.98382468 0.987183   0.98687533 0.99114828 0.98900854\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96520195 0.9826033\n",
      " 0.99023738 0.99420266 0.99511915 0.9945038  0.99542124 0.99572705\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97741012 0.99237059\n",
      " 0.99572891 0.99756098 0.99786492 0.99694749 0.99755818 0.99755725\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718468468468469\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.6096096096096096\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6374624624624624\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.7580330330330332\n",
      "testing classifiers: ['XGBClassifier']\n",
      "running: XGBClassifier\n",
      "0.7660660660660661\n"
     ]
    }
   ],
   "source": [
    "burchard_zl_london_greed_rearch_resp = []\n",
    "for cls in [\n",
    "    'SVC', \n",
    "    'DecisionTreeClassifier', \n",
    "    'GaussianProcessClassifier', \n",
    "    'RandomForestClassifier', \n",
    "    'GaussianNB', \n",
    "    'KNeighborsClassifier', \n",
    "    'AdaBoostClassifier', \n",
    "    'XGBClassifier'\n",
    "]:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zl_london_features_df, [cls])\n",
    "    burchard_zl_london_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35a3090c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.7575075075075076],\n",
       " ['DecisionTreeClassifier', 0.7225225225225226],\n",
       " ['GaussianProcessClassifier', 0.7383633633633634],\n",
       " ['RandomForestClassifier', 0.7718468468468469],\n",
       " ['GaussianNB', 0.6096096096096096],\n",
       " ['KNeighborsClassifier', 0.6374624624624624],\n",
       " ['AdaBoostClassifier', 0.7580330330330332],\n",
       " ['XGBClassifier', 0.7660660660660661]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zl_london_greed_rearch_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6e2c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.70570571 0.74414414 0.73858859 0.74136637 0.73581081 0.73843844\n",
      " 0.74121622 0.73581081 0.70570571 0.74414414 0.73858859 0.74136637\n",
      " 0.73581081 0.73843844 0.74121622 0.73581081 0.57132132 0.5740991\n",
      " 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.72214715 0.74136637 0.74954955 0.74136637 0.74677177 0.74129129\n",
      " 0.74662162 0.73843844 0.72214715 0.74136637 0.74954955 0.74136637\n",
      " 0.74677177 0.74129129 0.74662162 0.73843844 0.58506006 0.5795045\n",
      " 0.5713964  0.5740991  0.56869369 0.57417417 0.56869369 0.56869369\n",
      " 0.73558559 0.74114114 0.73573574 0.75225225 0.75773273 0.74932432\n",
      " 0.7548048  0.74662162 0.73558559 0.74114114 0.73573574 0.75225225\n",
      " 0.75773273 0.74932432 0.7548048  0.74662162 0.58513514 0.58791291\n",
      " 0.57687688 0.5795045  0.5713964  0.5713964  0.5740991  0.5713964\n",
      " 0.71073574 0.72462462 0.74662162 0.75495495 0.75487988 0.74662162\n",
      " 0.7466967  0.75503003 0.71073574 0.72462462 0.74662162 0.75495495\n",
      " 0.75487988 0.74662162 0.7466967  0.75503003 0.61253754 0.59039039\n",
      " 0.59309309 0.58753754 0.58498498 0.57957958 0.57957958 0.5713964\n",
      " 0.74084084 0.74677177 0.7493994  0.75503003 0.75765766 0.74932432\n",
      " 0.7493994  0.74684685 0.74084084 0.74677177 0.7493994  0.75503003\n",
      " 0.75765766 0.74932432 0.7493994  0.74684685 0.63468468 0.62597598\n",
      " 0.61516517 0.60127628 0.59594595 0.59039039 0.58768769 0.58768769\n",
      " 0.73033033 0.75217718 0.74947447 0.76313814 0.76321321 0.75202703\n",
      " 0.75217718 0.75773273 0.73033033 0.75217718 0.74947447 0.76313814\n",
      " 0.76321321 0.75202703 0.75217718 0.75773273 0.61501502 0.61801802\n",
      " 0.6015015  0.60135135 0.59864865 0.60135135 0.59857357 0.59324324\n",
      " 0.71081081 0.73558559 0.73588589 0.75225225 0.74684685 0.74662162\n",
      " 0.7466967  0.75225225 0.71081081 0.73558559 0.73588589 0.75225225\n",
      " 0.74684685 0.74662162 0.7466967  0.75225225 0.6207958  0.6231982\n",
      " 0.60968468 0.62057057 0.62057057 0.62057057 0.61779279 0.61493994\n",
      " 0.7298048  0.76869369 0.7548048  0.76861862 0.76336336 0.76043544\n",
      " 0.76051051 0.76306306 0.7298048  0.76869369 0.7548048  0.76861862\n",
      " 0.76336336 0.76043544 0.76051051 0.76306306 0.59894895 0.6204955\n",
      " 0.61764264 0.61771772 0.61501502 0.61223724 0.61786787 0.60675676\n",
      " 0.73836336 0.76576577 0.76043544 0.76043544 0.77154655 0.76058559\n",
      " 0.75773273 0.76043544 0.73836336 0.76576577 0.76043544 0.76043544\n",
      " 0.77154655 0.76058559 0.75773273 0.76043544 0.61801802 0.63138138\n",
      " 0.61779279 0.63701201 0.6286036  0.62597598 0.62304805 0.63138138\n",
      " 0.71096096 0.73866366 0.74429429 0.73340841 0.7222973  0.725\n",
      " 0.73851351 0.74129129 0.71096096 0.73866366 0.74429429 0.73340841\n",
      " 0.7222973  0.725      0.73851351 0.74129129 0.57957958 0.5740991\n",
      " 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.73325826 0.75765766 0.75503003 0.75510511 0.73596096 0.74144144\n",
      " 0.75495495 0.75495495 0.73325826 0.75765766 0.75503003 0.75510511\n",
      " 0.73596096 0.74144144 0.75495495 0.75495495 0.59316817 0.58228228\n",
      " 0.5740991  0.5768018  0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.74384384 0.75773273 0.76328829 0.76328829 0.76058559 0.75503003\n",
      " 0.75225225 0.74684685 0.74384384 0.75773273 0.76328829 0.76328829\n",
      " 0.76058559 0.75503003 0.75225225 0.74684685 0.60713213 0.58498498\n",
      " 0.58776276 0.58220721 0.5740991  0.5713964  0.5740991  0.56869369\n",
      " 0.71689189 0.74414414 0.75518018 0.75247748 0.74414414 0.73866366\n",
      " 0.74136637 0.74684685 0.71689189 0.74414414 0.75518018 0.75247748\n",
      " 0.74414414 0.73866366 0.74136637 0.74684685 0.61253754 0.60142643\n",
      " 0.59324324 0.58228228 0.57957958 0.58228228 0.5795045  0.5795045\n",
      " 0.74947447 0.74947447 0.75217718 0.74947447 0.74121622 0.74662162\n",
      " 0.74391892 0.74129129 0.74947447 0.74947447 0.75217718 0.74947447\n",
      " 0.74121622 0.74662162 0.74391892 0.74129129 0.62627628 0.61246246\n",
      " 0.60412913 0.59587087 0.58761261 0.59039039 0.58761261 0.58490991\n",
      " 0.71651652 0.75518018 0.746997   0.76343844 0.74977477 0.74129129\n",
      " 0.74692192 0.74677177 0.71651652 0.75518018 0.746997   0.76343844\n",
      " 0.74977477 0.74129129 0.74692192 0.74677177 0.62094595 0.60960961\n",
      " 0.60705706 0.6042042  0.60690691 0.59864865 0.59864865 0.59039039\n",
      " 0.72755255 0.74954955 0.75487988 0.75247748 0.7496997  0.74421922\n",
      " 0.75225225 0.75503003 0.72755255 0.74954955 0.75487988 0.75247748\n",
      " 0.7496997  0.74421922 0.75225225 0.75503003 0.63168168 0.61794294\n",
      " 0.6262012  0.61261261 0.61794294 0.61786787 0.62327327 0.60142643\n",
      " 0.7466967  0.76876877 0.75780781 0.746997   0.73873874 0.75232733\n",
      " 0.75217718 0.74954955 0.7466967  0.76876877 0.75780781 0.746997\n",
      " 0.73873874 0.75232733 0.75217718 0.74954955 0.6289039  0.61531532\n",
      " 0.6207958  0.62364865 0.61801802 0.62072072 0.6262012  0.62334835\n",
      " 0.73288288 0.76599099 0.76614114 0.77184685 0.76343844 0.76328829\n",
      " 0.75780781 0.76051051 0.73288288 0.76599099 0.76614114 0.77184685\n",
      " 0.76343844 0.76328829 0.75780781 0.76051051 0.64271772 0.63430931\n",
      " 0.63986486 0.63978979 0.62605105 0.62064565 0.63693694 0.63145646\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.93162527 0.94566365 0.94657642 0.94626874 0.94657921 0.94840568\n",
      " 0.9471899  0.94688223 0.93162527 0.94566365 0.94657642 0.94626874\n",
      " 0.94657921 0.94840568 0.9471899  0.94688223 0.66210002 0.63309279\n",
      " 0.62728892 0.61873648 0.61232192 0.6080499  0.60408089 0.59736705\n",
      " 0.97375065 0.98442884 0.98534534 0.98473652 0.98382375 0.98596162\n",
      " 0.98657045 0.98473838 0.97375065 0.98442884 0.98534534 0.98473652\n",
      " 0.98382375 0.98596162 0.98657045 0.98473838 0.73626743 0.71794865\n",
      " 0.71337081 0.71397125 0.71305941 0.71091687 0.69779966 0.68955676\n",
      " 0.98901134 0.99603099 0.99572518 0.99602913 0.99694563 0.9972505\n",
      " 0.99847375 0.99877956 0.98901134 0.99603099 0.99572518 0.99602913\n",
      " 0.99694563 0.9972505  0.99847375 0.99877956 0.81562057 0.80739632\n",
      " 0.81197509 0.82509137 0.82386813 0.81776404 0.82172466 0.81257272\n",
      " 0.99481148 0.99816887 0.99908443 0.99969512 1.         1.\n",
      " 1.         1.         0.99481148 0.99816887 0.99908443 0.99969512\n",
      " 1.         1.         1.         1.         0.87423081 0.87820914\n",
      " 0.89407959 0.90599127 0.91178955 0.91178209 0.91544156 0.91330835\n",
      " 0.9972505  1.         1.         1.         1.         1.\n",
      " 1.         1.         0.9972505  1.         1.         1.\n",
      " 1.         1.         1.         1.         0.90964142 0.92947994\n",
      " 0.94413739 0.95177053 0.95634743 0.95756881 0.95970109 0.96305568\n",
      " 0.99938838 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99938838 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94871802 0.96001063\n",
      " 0.97161464 0.97558458 0.97680596 0.97832942 0.9822947  0.98443164\n",
      " 0.99908257 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99908257 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96488402 0.98107705\n",
      " 0.98535094 0.98962482 0.99206571 0.99236593 0.99419986 0.99359103\n",
      " 0.99969419 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969419 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97618315 0.98961923\n",
      " 0.99481148 0.99725144 0.99603379 0.99511636 0.99664261 0.99603192\n",
      " 0.99969419 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969419 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98870087 0.99480775\n",
      " 0.99755911 0.99847375 0.99816887 0.99786399 0.99847281 0.99786212\n",
      " 0.92613187 0.93253431 0.92887111 0.93070784 0.93222943 0.93223223\n",
      " 0.93131946 0.92948646 0.92613187 0.93253431 0.92887111 0.93070784\n",
      " 0.93222943 0.93223223 0.93131946 0.92948646 0.65079623 0.62331711\n",
      " 0.61568863 0.60377788 0.59828075 0.59767286 0.59156597 0.58821045\n",
      " 0.96001343 0.97130603 0.97222626 0.97405367 0.97649735 0.97863523\n",
      " 0.9786343  0.97649642 0.96001343 0.97130603 0.97222626 0.97405367\n",
      " 0.97649735 0.97863523 0.9786343  0.97649642 0.72191765 0.70360166\n",
      " 0.69199858 0.69168904 0.68406057 0.67154472 0.66971545 0.66238812\n",
      " 0.98015682 0.99023085 0.98961643 0.9890132  0.99114828 0.99145223\n",
      " 0.99420079 0.99420079 0.98015682 0.99023085 0.98961643 0.9890132\n",
      " 0.99114828 0.99145223 0.99420079 0.99420079 0.7905898  0.78938241\n",
      " 0.78175021 0.79366003 0.79518255 0.78663944 0.77869397 0.76831506\n",
      " 0.99084247 0.9963396  0.99755911 0.99694935 0.99847561 0.99939024\n",
      " 1.         1.         0.99084247 0.9963396  0.99755911 0.99694935\n",
      " 0.99847561 0.99939024 1.         1.         0.85379    0.85958921\n",
      " 0.86722048 0.87577944 0.88310677 0.88035355 0.8815684  0.88186768\n",
      " 0.99481055 0.99939024 1.         1.         1.         1.\n",
      " 1.         1.         0.99481055 0.99939024 1.         1.\n",
      " 1.         1.         1.         1.         0.89407399 0.91514694\n",
      " 0.92979973 0.93682498 0.93987283 0.93926027 0.94780245 0.94658201\n",
      " 0.99694469 0.99969512 1.         1.         1.         1.\n",
      " 1.         1.         0.99694469 0.99969512 1.         1.\n",
      " 1.         1.         1.         1.         0.92826788 0.94780525\n",
      " 0.96276385 0.96642612 0.97069814 0.97130883 0.97802081 0.97650015\n",
      " 0.99908443 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99908443 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.9517724  0.97131256\n",
      " 0.98169333 0.98382468 0.987183   0.98687533 0.99114828 0.98900854\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96520195 0.9826033\n",
      " 0.99023738 0.99420266 0.99511915 0.9945038  0.99542124 0.99572705\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97741012 0.99237059\n",
      " 0.99572891 0.99756098 0.99786492 0.99694749 0.99755818 0.99755725\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718468468468469\n",
      "RandomForestClassifier(criterion='entropy', max_depth=12, n_estimators=200,\n",
      "                       random_state=0)\n",
      "{'criterion': 'entropy', 'max_depth': 12, 'max_features': 'auto', 'n_estimators': 200, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zl_london_features_df, ['RandomForestClassifier'])\n",
    "print(grid_search_cv_result[1][0].best_score_)\n",
    "print(grid_search_cv_result[1][0].best_estimator_)\n",
    "print(grid_search_cv_result[1][0].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bafc6448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = thesisModelFeatures.create_X_y(burchard_zl_london_features_df)\n",
    "RandomForestClassifier_burchard_zl = RandomForestClassifier(criterion = \"entropy\" , max_depth=12, n_estimators=200, random_state=0).fit(X, y)\n",
    "thesisModelFeatures.save_london_vs_burchard_best_model(\n",
    "    XGBClassifier_burchard_lz,\n",
    "    \"burchard_zl_RandomForestClassifier(criterion='entropy', max_depth=12, n_estimators=200, random_state=0)_0.77184\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74f2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee8afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221595a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e7f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f98df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc1e5f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london_best_result_1\" 0.794069069069069\n",
      "london_best_result_2: 0.7718468468468469\n",
      "london_classifier_total_result: 0.782957957957958\n"
     ]
    }
   ],
   "source": [
    "london_best_result_1 = np.amax([i[1] for i in burchard_lz_london_greed_rearch_resp])\n",
    "print(f'london_best_result_1\" {london_best_result_1}')\n",
    "\n",
    "london_best_result_2 = np.amax([i[1] for i in burchard_zl_london_greed_rearch_resp])\n",
    "print(f'london_best_result_2: {london_best_result_2}')\n",
    "\n",
    "london_classifier_total_result = (london_best_result_1 + london_best_result_2) / 2\n",
    "print(f'london_classifier_total_result: {london_classifier_total_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7a2a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zwickau_best_result_1: 0.8646825396825397\n",
      "zwickau_best_result_2: 0.8326984126984126\n",
      "zwickau_classifier_total_result: 0.8486904761904761\n"
     ]
    }
   ],
   "source": [
    "zwickau_best_result_1 = np.amax([i[1] for i in burchard_lz_zwickau_greed_rearch_resp])\n",
    "print(f'zwickau_best_result_1: {zwickau_best_result_1}')\n",
    "\n",
    "zwickau_best_result_2 = np.amax([i[1] for i in burchard_zl_zwickau_greed_rearch_resp])\n",
    "print(f'zwickau_best_result_2: {zwickau_best_result_2}')\n",
    "\n",
    "zwickau_classifier_total_result = (zwickau_best_result_1 + zwickau_best_result_2) / 2\n",
    "print(f'zwickau_classifier_total_result: {zwickau_classifier_total_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7327227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to classifier ability to distinguish between 2 version, version candidate to be closer to burchard is: london\n"
     ]
    }
   ],
   "source": [
    "more_original_version = 'not found'\n",
    "if london_classifier_total_result < zwickau_classifier_total_result: more_original_version = 'london'\n",
    "elif zwickau_classifier_total_result < london_classifier_total_result: more_original_version = 'zwickau'\n",
    "\n",
    "print(f'Due to classifier ability to distinguish between 2 version, version candidate to be closer to burchard is: {more_original_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2ce8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089fc28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672ba2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c7eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab39ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144924bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6ed3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdaf898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e91d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4bca316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> 1: 0.8131045786315674\n",
      "1 -> 1: 0.8111619165215265\n"
     ]
    }
   ],
   "source": [
    "print(london_zwickau_similarities.get_bidirectional_matches_by_threshold(0.5, zwickau_london_similarities)[0])\n",
    "print(zwickau_london_similarities.get_bidirectional_matches_by_threshold(0.5, london_zwickau_similarities)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ffd5170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cum in ueteribus historiis legamus sicut dicit beatus ieronimus quosdam lustrasse prouintias maria transfretasse ut ea que ex libris nouerant coram positi uiderent ut plato menpiticos uates et egiptum apolonius qui persas intrauit transiuit caucasum albanos scitas massagetas indiam bragmanos quoque ut iartam uideret et tandem egiptum intrauit ut famosam mensam solis uideret in sabulo quid mirum si cristiani terram ilam quam cristi sonant ecclesie uniuerse uidere et uisitare desiderant uanerabantur antiqui sancta sanctorum quia ibi erat arca testamenti et cerubin cum propitiatorio et manna et uirga aaron que fronduerat que omnia erant umbra futuri nonne aput nos uenerabilis est sepulcrum dulcis iesu quod quociens quis ingreditur tociens inuolutum sindone mentis uidet oculis saluatorem et paululum procedens uidet lapidem reuolutum angelum in eo sedentem et sudarium cum linteaminibus mulieribus ostendentem\n",
      "\n",
      "cum sicut dicit ieronimus quosdam inueniamus lustrasse prouintias maria transfretasse ut ea que ex scripturis nouerant coram uiderent ut plato mempiticos uates et egiptum appolonius qui persas intrauit transiuit cancasum albanos sticas massagetas quoque ut iarcam uideret et tandem egiptum intrauit ut famosam mensam solis uideret in sabulo quid mirum si cristiani terram ilam quam cristi sonant ecclesie uniuerse uidere et uisitare desiderant uenerabantur antiqui sancta sanctorum quia ibi erat arca testamenti et cernibulum cum propitiatorio et manna et uirga aaron que fronduerat que omnia erant umbra nonne uenerabilius est apud nos sepulcrum dulcis iesu quod quotiens quis ingreditur totiens inuolutum sindone mentis oculis uidet saluatorem et paululum procedens uidet lapidem reuolutum angelum in eo sedentem et sudarium cum lintiaminibus mulieribus ostendentem\n"
     ]
    }
   ],
   "source": [
    "print(london_zwickau_similarities.get_bidirectional_matches_by_threshold(0.5, zwickau_london_similarities)[0].original_text)\n",
    "print()\n",
    "print(london_zwickau_similarities.get_bidirectional_matches_by_threshold(0.5, zwickau_london_similarities)[0].match_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60ee1875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cum in sicut dicit ieronimus quosdam lustrasse prouintias maria transfretasse ut ea que ex nouerant coram uiderent ut plato uates et egiptum qui persas intrauit transiuit albanos massagetas quoque ut uideret et tandem egiptum intrauit ut famosam mensam solis uideret in sabulo quid mirum si cristiani terram ilam quam cristi sonant ecclesie uniuerse uidere et uisitare desiderant antiqui sancta sanctorum quia ibi erat arca testamenti et cum propitiatorio et manna et uirga aaron que fronduerat que omnia erant umbra nonne nos est sepulcrum dulcis iesu quod quis ingreditur inuolutum sindone mentis uidet oculis saluatorem et paululum procedens uidet lapidem reuolutum angelum in eo sedentem et sudarium cum mulieribus ostendentem'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(\n",
    "    thesisUtils.get_shared_words(\n",
    "        london_zwickau_similarities.get_bidirectional_matches_by_threshold(0.5, zwickau_london_similarities)[0].original_text,\n",
    "        london_zwickau_similarities.get_bidirectional_matches_by_threshold(0.5, zwickau_london_similarities)[0].match_text\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19647f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cum sicut dicit ieronimus quosdam lustrasse prouintias maria transfretasse ut ea que ex nouerant coram uiderent ut plato uates et egiptum qui persas intrauit transiuit albanos massagetas quoque ut uideret et tandem egiptum intrauit ut famosam mensam solis uideret in sabulo quid mirum si cristiani terram ilam quam cristi sonant ecclesie uniuerse uidere et uisitare desiderant antiqui sancta sanctorum quia ibi erat arca testamenti et cum propitiatorio et manna et uirga aaron que fronduerat que omnia erant umbra nonne est nos sepulcrum dulcis iesu quod quis ingreditur inuolutum sindone mentis oculis uidet saluatorem et paululum procedens uidet lapidem reuolutum angelum in eo sedentem et sudarium cum mulieribus ostendentem'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(\n",
    "    thesisUtils.get_shared_words(\n",
    "        london_zwickau_similarities.get_bidirectional_matches_by_threshold(0.5, zwickau_london_similarities)[0].match_text,\n",
    "        london_zwickau_similarities.get_bidirectional_matches_by_threshold(0.5, zwickau_london_similarities)[0].original_text,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8b39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
