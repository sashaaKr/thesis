{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6936cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_zwickau.loc[(statistics_df_zwickau['p_#'] == 0) & (statistics_df_zwickau['cross/inner'] == 'inner')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f38b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_combined_copy[\n",
    "    (statistics_df_combined_copy['feature_name'] == '5_gram') |\n",
    "    (statistics_df_combined_copy['feature_name'] == 'count_vectorizer_5_gram')\n",
    "].sort_values('p_#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3347c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_combined_copy[\n",
    "    (statistics_df_combined_copy['feature_name'] == '5_gram') |\n",
    "    (statistics_df_combined_copy['feature_name'] == 'count_vectorizer_5_gram')\n",
    "].sort_values('p_#').to_csv('../computed_data/text_to_text/5_gram_cv_itidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df[statistics_df['feature_name'] == '5_gram'].sort_values('p_#').to_csv('../computed_data/text_to_text/5_gram_zwickau_stats_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df[statistics_df['feature_name'] == '5_gram'].set_index(['p_#', 'cross/inner', ]).sort_values('p_#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "breslau_to_london_copy_df = statistics_df_combined_copy[\n",
    "    (statistics_df_combined_copy['feature_name'] == '5_gram') &\n",
    "    (statistics_df_combined_copy['cross/inner'] == 'inner') &\n",
    "    (statistics_df_combined_copy['version'] == 'breslau_to_london')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5af29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "breslau_to_london_copy_df.sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d77907",
   "metadata": {},
   "outputs": [],
   "source": [
    "breslau_to_london_copy_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "breslau_to_london_copy_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_combined_copy[\n",
    "    (statistics_df_combined_copy['feature_name'] == '5_gram') &\n",
    "    (statistics_df_combined_copy['cross/inner'] == 'inner') &\n",
    "    (statistics_df_combined_copy['version'] == 'london_to_breslau')\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ab819",
   "metadata": {},
   "source": [
    "# Word counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcd90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# # # here is neat graph for count: https://www.absentdata.com/python-graphs/python-word-frequency/\n",
    "# def create_words_frequency(corpus):    \n",
    "#     word_counter =  Counter(' '.join(corpus).split())\n",
    "#     return sorted(word_counter.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zwickau_corpus = thesisDataReader.get_zwickau_corpus()\n",
    "# london_corpus = thesisDataReader.get_london_corpus()\n",
    "# breslau_corpus = thesisDataReader.get_breslau_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70518f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data(\n",
    "#     dictionary, \n",
    "#     corpus_1_name, \n",
    "#     corpus_2_name, \n",
    "#     corpus_3_name,\n",
    "#     feature_name\n",
    "# ):\n",
    "#     data = []\n",
    "#     for i in dictionary:\n",
    "#         corpus_1_counter = 0 if corpus_1_name not in dictionary[i] else dictionary[i][corpus_1_name]\n",
    "#         corpus_2_counter = 0 if corpus_2_name not in dictionary[i] else dictionary[i][corpus_2_name]\n",
    "#         corpus_3_counter = 0 if corpus_3_name not in dictionary[i] else dictionary[i][corpus_3_name]\n",
    "        \n",
    "#         all_counters = [corpus_1_counter, corpus_2_counter, corpus_3_counter]\n",
    "#         all_names = [corpus_1_name, corpus_2_name, corpus_3_name]\n",
    "#         max_version_name = all_names[np.argmax(all_counters)]\n",
    "        \n",
    "#         data.append([\n",
    "#             feature_name,\n",
    "#             i,\n",
    "#             corpus_1_counter,\n",
    "#             corpus_2_counter,\n",
    "#             corpus_3_counter,\n",
    "#             max_version_name\n",
    "# #             corpus_1_name if corpus_1_counter > corpus_2_counter else 'equal' if corpus_1_counter == corpus_2_counter else corpus_2_name\n",
    "#         ])\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234eadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_word_frequency_data(\n",
    "#     corpus_1, \n",
    "#     corpus_1_name, \n",
    "#     corpus_2, \n",
    "#     corpus_2_name,\n",
    "#     corpus_3,\n",
    "#     corpus_3_name\n",
    "# ):    \n",
    "#     dictionary = {}\n",
    "    \n",
    "#     counter_sorted_corpus_1 = create_words_frequency(corpus_1)\n",
    "#     counter_sorted_corpus_2 = create_words_frequency(corpus_2)\n",
    "#     counter_sorted_corpus_3 = create_words_frequency(corpus_3)\n",
    "    \n",
    "#     def add_to_dictionary(counters, corpus_name):\n",
    "#         for i in counters:\n",
    "#             word = i[0]\n",
    "#             count = i[1]\n",
    "#             if word not in dictionary:\n",
    "#                 dictionary[word] = {}\n",
    "#             dictionary[word][corpus_name] = count\n",
    "\n",
    "#     add_to_dictionary(counter_sorted_corpus_1, corpus_1_name)\n",
    "#     add_to_dictionary(counter_sorted_corpus_2, corpus_2_name)\n",
    "#     add_to_dictionary(counter_sorted_corpus_3, corpus_3_name)\n",
    "\n",
    "#     data = []\n",
    "#     return create_data(\n",
    "#         dictionary, \n",
    "#         corpus_1_name, \n",
    "#         corpus_2_name,\n",
    "#         corpus_3_name,\n",
    "#         'word_counter'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ce357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_n_gram_frequency_data(\n",
    "#     corpus_1, \n",
    "#     corpus_1_name, \n",
    "#     corpus_2, \n",
    "#     corpus_2_name, \n",
    "#     corpus_3,\n",
    "#     corpus_3_name,\n",
    "#     n_gram\n",
    "# ):    \n",
    "#     dictionary = {}\n",
    "    \n",
    "#     counter_sorted_corpus_1 = create_n_gram_frequency(n_gram, corpus_1)\n",
    "#     counter_sorted_corpus_2 = create_n_gram_frequency(n_gram, corpus_2)\n",
    "#     counter_sorted_corpus_3 = create_n_gram_frequency(n_gram, corpus_3)\n",
    "    \n",
    "#     def add_to_dictionary(counters, corpus_name):\n",
    "#         for i in counters:\n",
    "#             word = i[0].replace(' ', '_')\n",
    "#             count = i[1]\n",
    "#             if word not in dictionary:\n",
    "#                 dictionary[word] = {}\n",
    "#             dictionary[word][corpus_name] = count\n",
    "\n",
    "#     add_to_dictionary(counter_sorted_corpus_1, corpus_1_name)\n",
    "#     add_to_dictionary(counter_sorted_corpus_2, corpus_2_name)\n",
    "#     add_to_dictionary(counter_sorted_corpus_3, corpus_3_name)\n",
    "    \n",
    "#     return create_data(\n",
    "#         dictionary, \n",
    "#         corpus_1_name, \n",
    "#         corpus_2_name,  \n",
    "#         corpus_3_name,\n",
    "#         f'count_vectorizer_{n_gram}_gram'\n",
    "#     )\n",
    "#     data = []\n",
    "#     for i in dictionary:\n",
    "#         corpus_1_counter = 0 if corpus_1_name not in dictionary[i] else dictionary[i][corpus_1_name]\n",
    "#         corpus_2_counter = 0 if corpus_2_name not in dictionary[i] else dictionary[i][corpus_2_name]\n",
    "#         data.append([\n",
    "#             f'count_vectorizer_{n_gram}_gram',\n",
    "#             i,\n",
    "#             corpus_1_counter,\n",
    "#             corpus_2_counter\n",
    "#         ])\n",
    "        \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1594ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word_freq = creat_word_frequency_data(\n",
    "#     zwickau_corpus,\n",
    "#     'zwickau',\n",
    "#     london_corpus,\n",
    "#     'london',\n",
    "#     breslau_corpus,\n",
    "#     'breslau'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344befa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b89943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_n_gram_frequency(n_gram, corpus):\n",
    "#     vec = CountVectorizer(ngram_range=(n_gram, n_gram), analyzer='char').fit(corpus)\n",
    "#     bag_of_words = vec.transform(corpus)\n",
    "#     sum_words = bag_of_words.sum(axis = 0)\n",
    "#     words_freq = [(word, sum_words[0, i]) for word, i in vec.vocabulary_.items()]\n",
    "#     words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "#     return words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_n_gram_frequency(5, zwickau_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_5_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name):\n",
    "#     return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_6_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name):\n",
    "#     return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_7_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name):\n",
    "#     return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed78fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_8_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name):\n",
    "#     return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_9_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name):\n",
    "#     return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56611e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def creat_10_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name):\n",
    "#     return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, corpus_3, corpus_3_name, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4648a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gram_5_frequency = creat_5_gram_frequency_data(\n",
    "#     zwickau_corpus,\n",
    "#     'zwickau',\n",
    "#     london_corpus,\n",
    "#     'london',\n",
    "#     breslau_corpus,\n",
    "#     'breslau'\n",
    "# )\n",
    "# gram_6_frequency = creat_6_gram_frequency_data(\n",
    "#     zwickau_corpus,\n",
    "#     'zwickau',\n",
    "#     london_corpus,\n",
    "#     'london',\n",
    "#     breslau_corpus,\n",
    "#     'breslau'\n",
    "# )\n",
    "# gram_7_frequency = creat_7_gram_frequency_data(\n",
    "#     zwickau_corpus,\n",
    "#     'zwickau',\n",
    "#     london_corpus,\n",
    "#     'london',\n",
    "#     breslau_corpus,\n",
    "#     'breslau'\n",
    "# )\n",
    "# gram_8_frequency = creat_8_gram_frequency_data(\n",
    "#     zwickau_corpus,\n",
    "#     'zwickau',\n",
    "#     london_corpus,\n",
    "#     'london',\n",
    "#     breslau_corpus,\n",
    "#     'breslau'\n",
    "# )\n",
    "# gram_9_frequency = creat_9_gram_frequency_data(\n",
    "#     zwickau_corpus,\n",
    "#     'zwickau',\n",
    "#     london_corpus,\n",
    "#     'london',\n",
    "#     breslau_corpus,\n",
    "#     'breslau'\n",
    "# )\n",
    "# gram_10_frequency = creat_10_gram_frequency_data(\n",
    "#     zwickau_corpus,\n",
    "#     'zwickau',\n",
    "#     london_corpus,\n",
    "#     'london',\n",
    "#     breslau_corpus,\n",
    "#     'breslau'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e48c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gram_10_frequency[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns = [\n",
    "#     'feature_name', \n",
    "#     'word', \n",
    "#     'zwickau', \n",
    "#     'london',\n",
    "#     'breslau',\n",
    "#     'version with higher score'\n",
    "# ]\n",
    "\n",
    "# words_df = pd.DataFrame(\n",
    "#     word_freq + gram_5_frequency + gram_6_frequency + gram_7_frequency + gram_8_frequency + gram_9_frequency + gram_10_frequency,\n",
    "#     columns=df_columns\n",
    "# )\n",
    "# words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf53ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_df['feature_name'] == 'word_counter']].to_csv('../computed_data/text_to_text/5_gram_zwickau_stats_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc269b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_df[words_df['feature_name'] == 'word_counter'].to_csv('../computed_data/text_to_text/count_words/word_counter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c915ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in [\n",
    "    'word_counter',\n",
    "    'count_vectorizer_5_gram',\n",
    "    'count_vectorizer_6_gram',\n",
    "    'count_vectorizer_7_gram',\n",
    "    'count_vectorizer_8_gram',\n",
    "    'count_vectorizer_9_gram',\n",
    "    'count_vectorizer_10_gram'\n",
    "]:\n",
    "    words_df[\n",
    "        words_df['feature_name'] == feature_name\n",
    "    ].to_csv(f'../computed_data/text_to_text/count_words/{feature_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51f4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
