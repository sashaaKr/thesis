{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed526465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: decorator==5.0.9 in /Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages (5.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install decorator==5.0.9\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd0037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features.tf_idf.n_gram' from '../src/features/tf_idf/n_gram.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import text_cleanup.text_cleanup as thesisCleanUp\n",
    "import preprocessing.text_preprocessing as thesisTextPreprocessing\n",
    "import data.reader as thesisDataReader\n",
    "import utils.utils as thesisUtils\n",
    "import features.tf_idf.n_gram as thesisTfIdfNgramFeatures\n",
    "import similarities.cosine as thesisCosineSimilarity\n",
    "\n",
    "imp.reload(thesisCleanUp)\n",
    "imp.reload(thesisTextPreprocessing)\n",
    "imp.reload(thesisDataReader)\n",
    "imp.reload(thesisUtils)\n",
    "imp.reload(thesisCosineSimilarity)\n",
    "imp.reload(thesisTfIdfNgramFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916e17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwickau_corpus = thesisDataReader.get_zwickau_corpus()\n",
    "london_corpus = thesisDataReader.get_london_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e0c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_zwickau = thesisCosineSimilarity.create_statistics_df(zwickau_corpus, london_corpus, 'zwickau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d655a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_london = thesisCosineSimilarity.create_statistics_df(london_corpus, zwickau_corpus, 'london')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01274301",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_combined = pd.concat([statistics_df_zwickau, statistics_df_london])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25757b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>p_#</th>\n",
       "      <th>cross/inner</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th># of 0 similarities</th>\n",
       "      <th>p_length</th>\n",
       "      <th>most_similar_p_#</th>\n",
       "      <th>most_similar_score</th>\n",
       "      <th>most_similar_p_length</th>\n",
       "      <th>most_similar_dropped</th>\n",
       "      <th>most_similar_dropped_p_#</th>\n",
       "      <th>most_similar_dropperd_score</th>\n",
       "      <th>most_similar_dropped_p_length</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>0</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.231428</td>\n",
       "      <td>0.049144</td>\n",
       "      <td>0.103870</td>\n",
       "      <td>0.199567</td>\n",
       "      <td>0.234173</td>\n",
       "      <td>0.266041</td>\n",
       "      <td>0.382694</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>321</td>\n",
       "      <td>0.382694</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>1</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.688952</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>0.274285</td>\n",
       "      <td>0.624526</td>\n",
       "      <td>0.710362</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.866673</td>\n",
       "      <td>0</td>\n",
       "      <td>878</td>\n",
       "      <td>5</td>\n",
       "      <td>0.866673</td>\n",
       "      <td>1248</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>2</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.625779</td>\n",
       "      <td>0.096483</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.572698</td>\n",
       "      <td>0.644933</td>\n",
       "      <td>0.700207</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>5</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>1248</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>3</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.659646</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.289649</td>\n",
       "      <td>0.601198</td>\n",
       "      <td>0.677046</td>\n",
       "      <td>0.733958</td>\n",
       "      <td>0.826515</td>\n",
       "      <td>0</td>\n",
       "      <td>725</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826515</td>\n",
       "      <td>1248</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>4</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.314683</td>\n",
       "      <td>0.595564</td>\n",
       "      <td>0.673477</td>\n",
       "      <td>0.730636</td>\n",
       "      <td>0.816763</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>281</td>\n",
       "      <td>0.816763</td>\n",
       "      <td>1334</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>313</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>0.045656</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.079608</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>0.131828</td>\n",
       "      <td>0.316795</td>\n",
       "      <td>0</td>\n",
       "      <td>3226</td>\n",
       "      <td>297</td>\n",
       "      <td>0.316795</td>\n",
       "      <td>2488</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>314</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.095552</td>\n",
       "      <td>0.053794</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.057207</td>\n",
       "      <td>0.085922</td>\n",
       "      <td>0.120639</td>\n",
       "      <td>0.341544</td>\n",
       "      <td>0</td>\n",
       "      <td>1325</td>\n",
       "      <td>152</td>\n",
       "      <td>0.341544</td>\n",
       "      <td>1518</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>315</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.102737</td>\n",
       "      <td>0.058298</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.062212</td>\n",
       "      <td>0.093139</td>\n",
       "      <td>0.129564</td>\n",
       "      <td>0.343818</td>\n",
       "      <td>0</td>\n",
       "      <td>821</td>\n",
       "      <td>87</td>\n",
       "      <td>0.343818</td>\n",
       "      <td>1222</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>316</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.057517</td>\n",
       "      <td>0.033607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032537</td>\n",
       "      <td>0.051247</td>\n",
       "      <td>0.077881</td>\n",
       "      <td>0.169342</td>\n",
       "      <td>3</td>\n",
       "      <td>463</td>\n",
       "      <td>115</td>\n",
       "      <td>0.169342</td>\n",
       "      <td>272</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>317</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.108846</td>\n",
       "      <td>0.053716</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.071610</td>\n",
       "      <td>0.098822</td>\n",
       "      <td>0.136519</td>\n",
       "      <td>0.298101</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>300</td>\n",
       "      <td>0.298101</td>\n",
       "      <td>608</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature_name  p_# cross/inner      mean       std       min  \\\n",
       "0                      2_gram    0       inner  0.231428  0.049144  0.103870   \n",
       "1                      2_gram    1       inner  0.688952  0.104741  0.274285   \n",
       "2                      2_gram    2       inner  0.625779  0.096483  0.250700   \n",
       "3                      2_gram    3       inner  0.659646  0.096405  0.289649   \n",
       "4                      2_gram    4       inner  0.655271  0.098697  0.314683   \n",
       "...                       ...  ...         ...       ...       ...       ...   \n",
       "3175  count_vectorizer_5_gram  313       cross  0.109089  0.045656  0.007279   \n",
       "3176  count_vectorizer_5_gram  314       cross  0.095552  0.053794  0.013822   \n",
       "3177  count_vectorizer_5_gram  315       cross  0.102737  0.058298  0.004337   \n",
       "3178  count_vectorizer_5_gram  316       cross  0.057517  0.033607  0.000000   \n",
       "3179  count_vectorizer_5_gram  317       cross  0.108846  0.053716  0.007811   \n",
       "\n",
       "           25%       50%       75%       max  # of 0 similarities  p_length  \\\n",
       "0     0.199567  0.234173  0.266041  0.382694                    0        31   \n",
       "1     0.624526  0.710362  0.764685  0.866673                    0       878   \n",
       "2     0.572698  0.644933  0.700207  0.797541                    0       377   \n",
       "3     0.601198  0.677046  0.733958  0.826515                    0       725   \n",
       "4     0.595564  0.673477  0.730636  0.816763                    0       707   \n",
       "...        ...       ...       ...       ...                  ...       ...   \n",
       "3175  0.079608  0.107231  0.131828  0.316795                    0      3226   \n",
       "3176  0.057207  0.085922  0.120639  0.341544                    0      1325   \n",
       "3177  0.062212  0.093139  0.129564  0.343818                    0       821   \n",
       "3178  0.032537  0.051247  0.077881  0.169342                    3       463   \n",
       "3179  0.071610  0.098822  0.136519  0.298101                    0       586   \n",
       "\n",
       "      most_similar_p_#  most_similar_score  most_similar_p_length  \\\n",
       "0                  321            0.382694                     53   \n",
       "1                    5            0.866673                   1248   \n",
       "2                    5            0.797541                   1248   \n",
       "3                    5            0.826515                   1248   \n",
       "4                  281            0.816763                   1334   \n",
       "...                ...                 ...                    ...   \n",
       "3175               297            0.316795                   2488   \n",
       "3176               152            0.341544                   1518   \n",
       "3177                87            0.343818                   1222   \n",
       "3178               115            0.169342                    272   \n",
       "3179               300            0.298101                    608   \n",
       "\n",
       "     most_similar_dropped  most_similar_dropped_p_#  \\\n",
       "0                    None                       NaN   \n",
       "1                    None                       NaN   \n",
       "2                    None                       NaN   \n",
       "3                    None                       NaN   \n",
       "4                    None                       NaN   \n",
       "...                   ...                       ...   \n",
       "3175                False                       NaN   \n",
       "3176                False                       NaN   \n",
       "3177                False                       NaN   \n",
       "3178                False                       NaN   \n",
       "3179                False                       NaN   \n",
       "\n",
       "      most_similar_dropperd_score  most_similar_dropped_p_length  version  \n",
       "0                             NaN                            NaN  zwickau  \n",
       "1                             NaN                            NaN  zwickau  \n",
       "2                             NaN                            NaN  zwickau  \n",
       "3                             NaN                            NaN  zwickau  \n",
       "4                             NaN                            NaN  zwickau  \n",
       "...                           ...                            ...      ...  \n",
       "3175                          NaN                            NaN   london  \n",
       "3176                          NaN                            NaN   london  \n",
       "3177                          NaN                            NaN   london  \n",
       "3178                          NaN                            NaN   london  \n",
       "3179                          NaN                            NaN   london  \n",
       "\n",
       "[6400 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715954b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_combined_copy = statistics_df_combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcfcfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zwickau_inner_df = statistics_df_combined.loc[\n",
    "#     (statistics_df_combined['cross/inner'] == 'inner') &\n",
    "#     (statistics_df_combined['version'] == 'zwickau')\n",
    "# ]\n",
    "# zwickau_cross_df = statistics_df_combined.loc[\n",
    "#     (statistics_df_combined['cross/inner'] == 'cross') &\n",
    "#     (statistics_df_combined['version'] == 'zwickau')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8b4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inner_cross_mean(statistics_df, version_name):\n",
    "    features = statistics_df.feature_name.unique()\n",
    "    \n",
    "    for feature in features:\n",
    "        total = 0\n",
    "        \n",
    "        version_inner_df = statistics_df.loc[\n",
    "            (statistics_df['cross/inner'] == 'inner') &\n",
    "            (statistics_df['version'] == version_name) & \n",
    "            (statistics_df['feature_name'] == feature)\n",
    "        ]\n",
    "        version_cross_df = statistics_df.loc[\n",
    "            (statistics_df['cross/inner'] == 'cross') &\n",
    "            (statistics_df['version'] == version_name) & \n",
    "            (statistics_df['feature_name'] == feature)\n",
    "        ]\n",
    "        \n",
    "        for i, d in version_cross_df.iterrows():\n",
    "            cross_mean_val = d['mean']\n",
    "            p_index = d['p_#']\n",
    "            inner_mean_val = version_inner_df.loc[\n",
    "                (version_inner_df['p_#'] == p_index) &\n",
    "                (version_inner_df['feature_name'] == feature),\n",
    "                'mean'\n",
    "            ].values[0]\n",
    "            \n",
    "            cross_inner_mean_diff = cross_mean_val - inner_mean_val\n",
    "            if cross_inner_mean_diff > 0:\n",
    "                statistics_df.loc[\n",
    "                    (statistics_df['version'] == version_name) &\n",
    "                    (statistics_df['cross/inner'] == 'inner') &\n",
    "                    (statistics_df['p_#'] == p_index) & \n",
    "                    (statistics_df['feature_name'] == feature),\n",
    "                    'inner_mean_is_low'\n",
    "                ] = True\n",
    "            else:\n",
    "                statistics_df.loc[\n",
    "                    (statistics_df['version'] == version_name) &\n",
    "                    (statistics_df['cross/inner'] == 'inner') &\n",
    "                    (statistics_df['p_#'] == p_index) & \n",
    "                    (statistics_df['feature_name'] == feature),\n",
    "                    'inner_mean_is_low'\n",
    "                ] = False\n",
    "                total += 1\n",
    "            statistics_df.loc[\n",
    "                (statistics_df['version'] == version_name) &\n",
    "                (statistics_df['cross/inner'] == 'inner') &\n",
    "                (statistics_df['p_#'] == p_index) & \n",
    "                (statistics_df['feature_name'] == feature),\n",
    "                'cross_inner_mean_diff'\n",
    "                ] = cross_inner_mean_diff\n",
    "            \n",
    "        print(f'version: {version_name}, for feature: {feature}, number of inner lowe that cross is: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20240838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: zwickau, for feature: 2_gram, number of inner lowe that cross is: 4\n",
      "version: zwickau, for feature: 3_gram, number of inner lowe that cross is: 3\n",
      "version: zwickau, for feature: 4_gram, number of inner lowe that cross is: 12\n",
      "version: zwickau, for feature: 5_gram, number of inner lowe that cross is: 22\n",
      "version: zwickau, for feature: count_vectorizer_5_gram, number of inner lowe that cross is: 7\n"
     ]
    }
   ],
   "source": [
    "check_inner_cross_mean(statistics_df_combined_copy, 'zwickau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d2a4d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: london, for feature: 2_gram, number of inner lowe that cross is: 318\n",
      "version: london, for feature: 3_gram, number of inner lowe that cross is: 318\n",
      "version: london, for feature: 4_gram, number of inner lowe that cross is: 316\n",
      "version: london, for feature: 5_gram, number of inner lowe that cross is: 284\n",
      "version: london, for feature: count_vectorizer_5_gram, number of inner lowe that cross is: 315\n"
     ]
    }
   ],
   "source": [
    "check_inner_cross_mean(statistics_df_combined_copy, 'london')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6583da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# for i, d in zwickau_cross_df.iterrows():\n",
    "#     cross_mean_val = d['mean']\n",
    "#     p_index = d['p_#']\n",
    "#     inner_mean_val = zwickau_inner_df.loc[zwickau_inner_df['p_#'] == p_index, 'mean'].values[0]\n",
    "#     if cross_mean_val > inner_mean_val:\n",
    "#         statistics_df_combined_copy.loc[\n",
    "#             (statistics_df_combined_copy['version'] == 'zwickau') &\n",
    "#             (statistics_df_combined_copy['cross/inner'] == 'inner') &\n",
    "#             (statistics_df_combined_copy['p_#'] == p_index),\n",
    "#             'inner_mean_is_low'\n",
    "#         ] = True\n",
    "#     else:\n",
    "#         statistics_df_combined_copy.loc[\n",
    "#             (statistics_df_combined_copy['version'] == 'zwickau') &\n",
    "#             (statistics_df_combined_copy['cross/inner'] == 'inner') &\n",
    "#             (statistics_df_combined_copy['p_#'] == p_index),\n",
    "#             'inner_mean_is_low'\n",
    "#         ] = False\n",
    "#         total += 1\n",
    "# print(f'number of inner mean lowwer than cross is: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d049f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# london_inner_df = statistics_df_combined.loc[\n",
    "#     (statistics_df_combined['cross/inner'] == 'inner') &\n",
    "#     (statistics_df_combined['version'] == 'london')\n",
    "# ]\n",
    "# london_cross_df = statistics_df_combined.loc[\n",
    "#     (statistics_df_combined['cross/inner'] == 'cross') &\n",
    "#     (statistics_df_combined['version'] == 'london')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5c99adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# for i, d in london_cross_df.iterrows():\n",
    "#     cross_mean_val = d['mean']\n",
    "#     p_index = d['p_#']\n",
    "#     inner_mean_val = london_inner_df.loc[london_inner_df['p_#'] == p_index, 'mean'].values[0]\n",
    "#     if cross_mean_val > inner_mean_val:\n",
    "#         statistics_df_combined_copy.loc[\n",
    "#             (statistics_df_combined_copy['version'] == 'london') &\n",
    "#             (statistics_df_combined_copy['cross/inner'] == 'inner') &\n",
    "#             (statistics_df_combined_copy['p_#'] == p_index),\n",
    "#             'inner_mean_is_low'\n",
    "#         ] = True\n",
    "#     else:\n",
    "#         statistics_df_combined_copy.loc[\n",
    "#             (statistics_df_combined_copy['version'] == 'london') &\n",
    "#             (statistics_df_combined_copy['cross/inner'] == 'inner') &\n",
    "#             (statistics_df_combined_copy['p_#'] == p_index),\n",
    "#             'inner_mean_is_low'\n",
    "#         ] = False\n",
    "#         total += 1\n",
    "# print(f'number of inner mean lowwer than cross is: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5517fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043ecab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c76a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_combined_copy.to_csv('../computed_data/text_to_text/statistics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6867cc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>p_#</th>\n",
       "      <th>cross/inner</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th># of 0 similarities</th>\n",
       "      <th>p_length</th>\n",
       "      <th>most_similar_p_#</th>\n",
       "      <th>most_similar_score</th>\n",
       "      <th>most_similar_p_length</th>\n",
       "      <th>most_similar_dropped</th>\n",
       "      <th>most_similar_dropped_p_#</th>\n",
       "      <th>most_similar_dropperd_score</th>\n",
       "      <th>most_similar_dropped_p_length</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>0</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.231428</td>\n",
       "      <td>0.049144</td>\n",
       "      <td>0.103870</td>\n",
       "      <td>0.199567</td>\n",
       "      <td>0.234173</td>\n",
       "      <td>0.266041</td>\n",
       "      <td>0.382694</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>321</td>\n",
       "      <td>0.382694</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>1</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.688952</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>0.274285</td>\n",
       "      <td>0.624526</td>\n",
       "      <td>0.710362</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.866673</td>\n",
       "      <td>0</td>\n",
       "      <td>878</td>\n",
       "      <td>5</td>\n",
       "      <td>0.866673</td>\n",
       "      <td>1248</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>2</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.625779</td>\n",
       "      <td>0.096483</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.572698</td>\n",
       "      <td>0.644933</td>\n",
       "      <td>0.700207</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>5</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>1248</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>3</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.659646</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.289649</td>\n",
       "      <td>0.601198</td>\n",
       "      <td>0.677046</td>\n",
       "      <td>0.733958</td>\n",
       "      <td>0.826515</td>\n",
       "      <td>0</td>\n",
       "      <td>725</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826515</td>\n",
       "      <td>1248</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_gram</td>\n",
       "      <td>4</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.314683</td>\n",
       "      <td>0.595564</td>\n",
       "      <td>0.673477</td>\n",
       "      <td>0.730636</td>\n",
       "      <td>0.816763</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>281</td>\n",
       "      <td>0.816763</td>\n",
       "      <td>1334</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>317</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.063064</td>\n",
       "      <td>0.027083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046415</td>\n",
       "      <td>0.062365</td>\n",
       "      <td>0.077461</td>\n",
       "      <td>0.175285</td>\n",
       "      <td>2</td>\n",
       "      <td>556</td>\n",
       "      <td>299</td>\n",
       "      <td>0.175285</td>\n",
       "      <td>2764</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>318</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.109734</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.079846</td>\n",
       "      <td>0.106301</td>\n",
       "      <td>0.136133</td>\n",
       "      <td>0.260851</td>\n",
       "      <td>0</td>\n",
       "      <td>1535</td>\n",
       "      <td>313</td>\n",
       "      <td>0.260851</td>\n",
       "      <td>1912</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>319</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.057275</td>\n",
       "      <td>0.076135</td>\n",
       "      <td>0.096259</td>\n",
       "      <td>0.191496</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>123</td>\n",
       "      <td>0.191496</td>\n",
       "      <td>1337</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>320</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>0.051501</td>\n",
       "      <td>0.071044</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>297</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>2488</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>321</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>0.025098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.023194</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>102</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature_name  p_# cross/inner      mean       std       min  \\\n",
       "0                      2_gram    0       inner  0.231428  0.049144  0.103870   \n",
       "1                      2_gram    1       inner  0.688952  0.104741  0.274285   \n",
       "2                      2_gram    2       inner  0.625779  0.096483  0.250700   \n",
       "3                      2_gram    3       inner  0.659646  0.096405  0.289649   \n",
       "4                      2_gram    4       inner  0.655271  0.098697  0.314683   \n",
       "...                       ...  ...         ...       ...       ...       ...   \n",
       "1605  count_vectorizer_5_gram  317       inner  0.063064  0.027083  0.000000   \n",
       "1606  count_vectorizer_5_gram  318       inner  0.109734  0.043691  0.004167   \n",
       "1607  count_vectorizer_5_gram  319       inner  0.078253  0.029624  0.004151   \n",
       "1608  count_vectorizer_5_gram  320       inner  0.053711  0.025757  0.003082   \n",
       "1609  count_vectorizer_5_gram  321       inner  0.017532  0.025098  0.000000   \n",
       "\n",
       "           25%       50%       75%       max  # of 0 similarities  p_length  \\\n",
       "0     0.199567  0.234173  0.266041  0.382694                    0        31   \n",
       "1     0.624526  0.710362  0.764685  0.866673                    0       878   \n",
       "2     0.572698  0.644933  0.700207  0.797541                    0       377   \n",
       "3     0.601198  0.677046  0.733958  0.826515                    0       725   \n",
       "4     0.595564  0.673477  0.730636  0.816763                    0       707   \n",
       "...        ...       ...       ...       ...                  ...       ...   \n",
       "1605  0.046415  0.062365  0.077461  0.175285                    2       556   \n",
       "1606  0.079846  0.106301  0.136133  0.260851                    0      1535   \n",
       "1607  0.057275  0.076135  0.096259  0.191496                    0      1418   \n",
       "1608  0.034590  0.051501  0.071044  0.146063                    0       520   \n",
       "1609  0.000000  0.010641  0.023194  0.247436                  102        53   \n",
       "\n",
       "      most_similar_p_#  most_similar_score  most_similar_p_length  \\\n",
       "0                  321            0.382694                     53   \n",
       "1                    5            0.866673                   1248   \n",
       "2                    5            0.797541                   1248   \n",
       "3                    5            0.826515                   1248   \n",
       "4                  281            0.816763                   1334   \n",
       "...                ...                 ...                    ...   \n",
       "1605               299            0.175285                   2764   \n",
       "1606               313            0.260851                   1912   \n",
       "1607               123            0.191496                   1337   \n",
       "1608               297            0.146063                   2488   \n",
       "1609                 0            0.247436                     31   \n",
       "\n",
       "     most_similar_dropped  most_similar_dropped_p_#  \\\n",
       "0                    None                       NaN   \n",
       "1                    None                       NaN   \n",
       "2                    None                       NaN   \n",
       "3                    None                       NaN   \n",
       "4                    None                       NaN   \n",
       "...                   ...                       ...   \n",
       "1605                 None                       NaN   \n",
       "1606                 None                       NaN   \n",
       "1607                 None                       NaN   \n",
       "1608                 None                       NaN   \n",
       "1609                 None                       NaN   \n",
       "\n",
       "      most_similar_dropperd_score  most_similar_dropped_p_length  version  \n",
       "0                             NaN                            NaN  zwickau  \n",
       "1                             NaN                            NaN  zwickau  \n",
       "2                             NaN                            NaN  zwickau  \n",
       "3                             NaN                            NaN  zwickau  \n",
       "4                             NaN                            NaN  zwickau  \n",
       "...                           ...                            ...      ...  \n",
       "1605                          NaN                            NaN  zwickau  \n",
       "1606                          NaN                            NaN  zwickau  \n",
       "1607                          NaN                            NaN  zwickau  \n",
       "1608                          NaN                            NaN  zwickau  \n",
       "1609                          NaN                            NaN  zwickau  \n",
       "\n",
       "[1610 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_df_zwickau.query(\"`cross/inner` == 'inner'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4acf32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6936cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_zwickau.loc[(statistics_df_zwickau['p_#'] == 0) & (statistics_df_zwickau['cross/inner'] == 'inner')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7a039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f38b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>p_#</th>\n",
       "      <th>cross/inner</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>...</th>\n",
       "      <th>most_similar_p_#</th>\n",
       "      <th>most_similar_score</th>\n",
       "      <th>most_similar_p_length</th>\n",
       "      <th>most_similar_dropped</th>\n",
       "      <th>most_similar_dropped_p_#</th>\n",
       "      <th>most_similar_dropperd_score</th>\n",
       "      <th>most_similar_dropped_p_length</th>\n",
       "      <th>version</th>\n",
       "      <th>inner_mean_is_low</th>\n",
       "      <th>cross_inner_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>5_gram</td>\n",
       "      <td>0</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>...</td>\n",
       "      <td>321</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>0</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.023127</td>\n",
       "      <td>0.220219</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.220219</td>\n",
       "      <td>360</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>5_gram</td>\n",
       "      <td>0</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.017142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.160069</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.160069</td>\n",
       "      <td>550</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>0</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.020757</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030692</td>\n",
       "      <td>0.158941</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.158941</td>\n",
       "      <td>853</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>0</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.019303</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027472</td>\n",
       "      <td>0.205132</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.205132</td>\n",
       "      <td>360</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>320</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.03459</td>\n",
       "      <td>0.051501</td>\n",
       "      <td>0.071044</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>...</td>\n",
       "      <td>297</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>2488</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>5_gram</td>\n",
       "      <td>321</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>5_gram</td>\n",
       "      <td>321</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.082978</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.082978</td>\n",
       "      <td>360</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>321</td>\n",
       "      <td>cross</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.024641</td>\n",
       "      <td>0.156363</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.156363</td>\n",
       "      <td>360</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>count_vectorizer_5_gram</td>\n",
       "      <td>321</td>\n",
       "      <td>inner</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>0.025098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.023194</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwickau</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature_name  p_# cross/inner      mean       std       min  \\\n",
       "966                    5_gram    0       inner  0.008343  0.015417  0.000000   \n",
       "2898  count_vectorizer_5_gram    0       cross  0.016631  0.026600  0.000000   \n",
       "2576                   5_gram    0       cross  0.009559  0.017142  0.000000   \n",
       "2862  count_vectorizer_5_gram    0       cross  0.020757  0.032964  0.000000   \n",
       "1272  count_vectorizer_5_gram    0       inner  0.019303  0.031500  0.000000   \n",
       "...                       ...  ...         ...       ...       ...       ...   \n",
       "1608  count_vectorizer_5_gram  320       inner  0.053711  0.025757  0.003082   \n",
       "1287                   5_gram  321       inner  0.010207  0.016764  0.000000   \n",
       "2897                   5_gram  321       cross  0.010295  0.013363  0.000000   \n",
       "3219  count_vectorizer_5_gram  321       cross  0.018136  0.022027  0.000000   \n",
       "1609  count_vectorizer_5_gram  321       inner  0.017532  0.025098  0.000000   \n",
       "\n",
       "          25%       50%       75%       max  ...  most_similar_p_#  \\\n",
       "966   0.00000  0.002362  0.010302  0.148716  ...               321   \n",
       "2898  0.00000  0.007410  0.023127  0.220219  ...                19   \n",
       "2576  0.00000  0.003247  0.011943  0.160069  ...                 8   \n",
       "2862  0.00000  0.000000  0.030692  0.158941  ...               274   \n",
       "1272  0.00000  0.000000  0.027472  0.205132  ...                19   \n",
       "...       ...       ...       ...       ...  ...               ...   \n",
       "1608  0.03459  0.051501  0.071044  0.146063  ...               297   \n",
       "1287  0.00000  0.005519  0.013074  0.148716  ...                 0   \n",
       "2897  0.00000  0.006274  0.013622  0.082978  ...                19   \n",
       "3219  0.00000  0.011561  0.024641  0.156363  ...                19   \n",
       "1609  0.00000  0.010641  0.023194  0.247436  ...                 0   \n",
       "\n",
       "      most_similar_score  most_similar_p_length  most_similar_dropped  \\\n",
       "966             0.148716                     53                  None   \n",
       "2898            0.220219                    360                 False   \n",
       "2576            0.160069                    550                 False   \n",
       "2862            0.158941                    853                 False   \n",
       "1272            0.205132                    360                  None   \n",
       "...                  ...                    ...                   ...   \n",
       "1608            0.146063                   2488                  None   \n",
       "1287            0.148716                     31                  None   \n",
       "2897            0.082978                    360                 False   \n",
       "3219            0.156363                    360                 False   \n",
       "1609            0.247436                     31                  None   \n",
       "\n",
       "      most_similar_dropped_p_# most_similar_dropperd_score  \\\n",
       "966                        NaN                         NaN   \n",
       "2898                       NaN                         NaN   \n",
       "2576                       NaN                         NaN   \n",
       "2862                       NaN                         NaN   \n",
       "1272                       NaN                         NaN   \n",
       "...                        ...                         ...   \n",
       "1608                       NaN                         NaN   \n",
       "1287                       NaN                         NaN   \n",
       "2897                       NaN                         NaN   \n",
       "3219                       NaN                         NaN   \n",
       "1609                       NaN                         NaN   \n",
       "\n",
       "      most_similar_dropped_p_length  version  inner_mean_is_low  \\\n",
       "966                             NaN  zwickau               True   \n",
       "2898                            NaN  zwickau                NaN   \n",
       "2576                            NaN  zwickau                NaN   \n",
       "2862                            NaN   london                NaN   \n",
       "1272                            NaN   london               True   \n",
       "...                             ...      ...                ...   \n",
       "1608                            NaN  zwickau               True   \n",
       "1287                            NaN  zwickau               True   \n",
       "2897                            NaN  zwickau                NaN   \n",
       "3219                            NaN  zwickau                NaN   \n",
       "1609                            NaN  zwickau               True   \n",
       "\n",
       "     cross_inner_mean_diff  \n",
       "966               0.001215  \n",
       "2898                   NaN  \n",
       "2576                   NaN  \n",
       "2862                   NaN  \n",
       "1272              0.001454  \n",
       "...                    ...  \n",
       "1608              0.003665  \n",
       "1287              0.000088  \n",
       "2897                   NaN  \n",
       "3219                   NaN  \n",
       "1609              0.000603  \n",
       "\n",
       "[2560 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_df_combined_copy[\n",
    "    (statistics_df_combined_copy['feature_name'] == '5_gram') |\n",
    "    (statistics_df_combined_copy['feature_name'] == 'count_vectorizer_5_gram')\n",
    "].sort_values('p_#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a3347c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df_combined_copy[\n",
    "    (statistics_df_combined_copy['feature_name'] == '5_gram') |\n",
    "    (statistics_df_combined_copy['feature_name'] == 'count_vectorizer_5_gram')\n",
    "].sort_values('p_#').to_csv('../computed_data/text_to_text/5_gram_cv_itidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df[statistics_df['feature_name'] == '5_gram'].sort_values('p_#').to_csv('../computed_data/text_to_text/5_gram_zwickau_stats_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df[statistics_df['feature_name'] == '5_gram'].set_index(['p_#', 'cross/inner', ]).sort_values('p_#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ca22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a45686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e67ab819",
   "metadata": {},
   "source": [
    "# Word counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57fcd90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# # here is neat graph for count: https://www.absentdata.com/python-graphs/python-word-frequency/\n",
    "def create_words_frequency(corpus):    \n",
    "    word_counter =  Counter(' '.join(corpus).split())\n",
    "    return sorted(word_counter.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931cfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwickau_corpus = thesisDataReader.get_zwickau_corpus()\n",
    "london_corpus = thesisDataReader.get_london_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70518f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(dictionary, corpus_1_name, corpus_2_name, feature_name):\n",
    "    data = []\n",
    "    for i in dictionary:\n",
    "        corpus_1_counter = 0 if corpus_1_name not in dictionary[i] else dictionary[i][corpus_1_name]\n",
    "        corpus_2_counter = 0 if corpus_2_name not in dictionary[i] else dictionary[i][corpus_2_name]\n",
    "        data.append([\n",
    "            feature_name,\n",
    "            i,\n",
    "            corpus_1_counter,\n",
    "            corpus_2_counter,\n",
    "            corpus_1_name if corpus_1_counter > corpus_2_counter else 'equal' if corpus_1_counter == corpus_2_counter else corpus_2_name\n",
    "        ])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234eadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_word_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name):    \n",
    "    dictionary = {}\n",
    "    \n",
    "    counter_sorted_corpus_1 = create_words_frequency(corpus_1)\n",
    "    counter_sorted_corpus_2 = create_words_frequency(corpus_2)\n",
    "    \n",
    "    def add_to_dictionary(counters, corpus_name):\n",
    "        for i in counters:\n",
    "            word = i[0]\n",
    "            count = i[1]\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = {}\n",
    "            dictionary[word][corpus_name] = count\n",
    "\n",
    "    add_to_dictionary(counter_sorted_corpus_1, corpus_1_name)\n",
    "    add_to_dictionary(counter_sorted_corpus_2, corpus_2_name)\n",
    "\n",
    "    data = []\n",
    "    return create_data(dictionary, corpus_1_name, corpus_2_name, 'word_counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8ce357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, n_gram):    \n",
    "    dictionary = {}\n",
    "    \n",
    "    counter_sorted_corpus_1 = create_n_gram_frequency(n_gram, corpus_1)\n",
    "    counter_sorted_corpus_2 = create_n_gram_frequency(n_gram, corpus_2)\n",
    "    \n",
    "    def add_to_dictionary(counters, corpus_name):\n",
    "        for i in counters:\n",
    "            word = i[0].replace(' ', '_')\n",
    "            count = i[1]\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = {}\n",
    "            dictionary[word][corpus_name] = count\n",
    "\n",
    "    add_to_dictionary(counter_sorted_corpus_1, corpus_1_name)\n",
    "    add_to_dictionary(counter_sorted_corpus_2, corpus_2_name)\n",
    "    return create_data(dictionary, corpus_1_name, corpus_2_name,  f'count_vectorizer_{n_gram}_gram')\n",
    "#     data = []\n",
    "#     for i in dictionary:\n",
    "#         corpus_1_counter = 0 if corpus_1_name not in dictionary[i] else dictionary[i][corpus_1_name]\n",
    "#         corpus_2_counter = 0 if corpus_2_name not in dictionary[i] else dictionary[i][corpus_2_name]\n",
    "#         data.append([\n",
    "#             f'count_vectorizer_{n_gram}_gram',\n",
    "#             i,\n",
    "#             corpus_1_counter,\n",
    "#             corpus_2_counter\n",
    "#         ])\n",
    "        \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1594ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_freq = creat_word_frequency_data(\n",
    "    zwickau_corpus,\n",
    "    'zwickau',\n",
    "    london_corpus,\n",
    "    'london'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "344befa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b89943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram_frequency(n_gram, corpus):\n",
    "    vec = CountVectorizer(ngram_range=(n_gram, n_gram), analyzer='char').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis = 0)\n",
    "    words_freq = [(word, sum_words[0, i]) for word, i in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "    return words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8839886e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' est ', 593),\n",
       " ('s et ', 357),\n",
       " ('ibus ', 319),\n",
       " ('m et ', 283),\n",
       " ('itur ', 280),\n",
       " (' que ', 263),\n",
       " (' quod', 262),\n",
       " (' mont', 261),\n",
       " ('quod ', 250),\n",
       " ('t in ', 238),\n",
       " (' cont', 234),\n",
       " ('iuita', 234),\n",
       " (' ciui', 229),\n",
       " ('ciuit', 229),\n",
       " (' per ', 224),\n",
       " ('sunt ', 221),\n",
       " ('ntem ', 209),\n",
       " (' sunt', 209),\n",
       " (' leuc', 209),\n",
       " ('contr', 207),\n",
       " ('ontra', 207),\n",
       " ('ntra ', 205),\n",
       " (' terr', 201),\n",
       " ('e et ', 186),\n",
       " ('orum ', 183),\n",
       " ('m in ', 181),\n",
       " (' qui ', 180),\n",
       " ('sque ', 171),\n",
       " (' et i', 171),\n",
       " ('monte', 163),\n",
       " ('usque', 162),\n",
       " (' non ', 159),\n",
       " (' usqu', 159),\n",
       " ('uitat', 159),\n",
       " ('terra', 157),\n",
       " (' habe', 153),\n",
       " ('a et ', 152),\n",
       " (' et s', 150),\n",
       " ('entem', 149),\n",
       " ('m est', 149),\n",
       " ('e ad ', 145),\n",
       " (' cum ', 143),\n",
       " ('s in ', 143),\n",
       " (' dici', 142),\n",
       " ('itate', 141),\n",
       " ('dicit', 139),\n",
       " (' ubi ', 139),\n",
       " ('ntur ', 137),\n",
       " ('um et', 137),\n",
       " (' et a', 133),\n",
       " ('is et', 133),\n",
       " ('t et ', 130),\n",
       " (' sed ', 130),\n",
       " ('i et ', 129),\n",
       " ('erat ', 128),\n",
       " ('et in', 127),\n",
       " ('e in ', 126),\n",
       " ('citur', 124),\n",
       " (' et p', 123),\n",
       " ('atur ', 123),\n",
       " ('inde ', 121),\n",
       " (' et e', 120),\n",
       " ('s est', 120),\n",
       " ('trum ', 120),\n",
       " ('leuca', 120),\n",
       " ('icitu', 120),\n",
       " ('quam ', 118),\n",
       " (' et c', 116),\n",
       " ('ntes ', 114),\n",
       " (' eius', 112),\n",
       " ('que a', 112),\n",
       " ('us et', 111),\n",
       " (' et d', 110),\n",
       " (' in l', 109),\n",
       " ('erra ', 109),\n",
       " ('austr', 106),\n",
       " ('orien', 105),\n",
       " ('rient', 104),\n",
       " ('um es', 104),\n",
       " (' orie', 104),\n",
       " ('tiam ', 103),\n",
       " ('strum', 103),\n",
       " ('um qu', 102),\n",
       " (' omni', 102),\n",
       " ('s con', 102),\n",
       " (' erat', 101),\n",
       " ('tibus', 101),\n",
       " ('onte ', 101),\n",
       " ('idem ', 100),\n",
       " ('erunt', 100),\n",
       " ('in qu', 100),\n",
       " ('um in', 99),\n",
       " ('iente', 99),\n",
       " (' in m', 99),\n",
       " (' inte', 99),\n",
       " (' in q', 99),\n",
       " ('ue ad', 99),\n",
       " (' aust', 99),\n",
       " (' inde', 98),\n",
       " ('tamen', 97),\n",
       " ('amen ', 96),\n",
       " ('super', 95),\n",
       " ('runt ', 95),\n",
       " (' tame', 95),\n",
       " (' quia', 94),\n",
       " ('quia ', 94),\n",
       " ('etiam', 94),\n",
       " (' mult', 94),\n",
       " ('ntis ', 93),\n",
       " (' in e', 93),\n",
       " ('rum e', 93),\n",
       " (' etia', 93),\n",
       " ('inter', 93),\n",
       " ('eius ', 93),\n",
       " ('utem ', 93),\n",
       " ('fuit ', 93),\n",
       " (' ibi ', 92),\n",
       " ('a in ', 92),\n",
       " ('mare ', 92),\n",
       " (' fuit', 92),\n",
       " ('iter ', 91),\n",
       " ('ident', 91),\n",
       " ('autem', 91),\n",
       " (' domi', 90),\n",
       " (' mare', 90),\n",
       " (' aute', 90),\n",
       " (' mari', 89),\n",
       " ('domin', 89),\n",
       " (' occi', 88),\n",
       " (' magn', 88),\n",
       " ('onem ', 86),\n",
       " (' long', 86),\n",
       " ('uero ', 86),\n",
       " ('tur i', 86),\n",
       " (' sicu', 85),\n",
       " (' uald', 85),\n",
       " ('ualde', 85),\n",
       " ('ucis ', 84),\n",
       " (' uero', 84),\n",
       " ('occid', 84),\n",
       " ('itas ', 84),\n",
       " ('alde ', 84),\n",
       " ('em in', 83),\n",
       " ('a est', 83),\n",
       " ('us in', 83),\n",
       " (' part', 83),\n",
       " ('atis ', 83),\n",
       " ('tudin', 83),\n",
       " ('illa ', 82),\n",
       " ('itudi', 82),\n",
       " (' in t', 81),\n",
       " ('tra a', 81),\n",
       " ('is qu', 80),\n",
       " ('i in ', 80),\n",
       " ('monti', 80),\n",
       " ('uius ', 80),\n",
       " (' locu', 80),\n",
       " ('sanct', 79),\n",
       " (' et m', 79),\n",
       " ('ccide', 79),\n",
       " ('ciden', 79),\n",
       " ('est i', 79),\n",
       " (' sanc', 78),\n",
       " (' et u', 78),\n",
       " ('tate ', 78),\n",
       " (' temp', 78),\n",
       " (' port', 78),\n",
       " ('t de ', 78),\n",
       " ('leuci', 78),\n",
       " ('eucis', 78),\n",
       " (' illa', 77),\n",
       " ('tur e', 77),\n",
       " ('uitas', 77),\n",
       " (' uide', 76),\n",
       " (' in p', 76),\n",
       " (' dict', 76),\n",
       " ('r et ', 75),\n",
       " (' uall', 75),\n",
       " ('tum e', 75),\n",
       " ('am et', 74),\n",
       " (' quam', 73),\n",
       " ('ctum ', 73),\n",
       " ('m ad ', 73),\n",
       " ('itati', 73),\n",
       " (' supe', 73),\n",
       " ('auit ', 72),\n",
       " ('ditur', 72),\n",
       " ('dente', 72),\n",
       " (' in c', 72),\n",
       " ('is co', 72),\n",
       " ('s que', 72),\n",
       " (' aqui', 72),\n",
       " ('iuxta', 72),\n",
       " ('uxta ', 72),\n",
       " (' et t', 71),\n",
       " ('s de ', 71),\n",
       " ('m de ', 71),\n",
       " ('ordan', 71),\n",
       " (' cast', 71),\n",
       " (' dist', 71),\n",
       " ('est a', 70),\n",
       " ('is in', 70),\n",
       " (' beth', 70),\n",
       " ('arum ', 70),\n",
       " (' nunc', 70),\n",
       " ('nter ', 70),\n",
       " ('porta', 70),\n",
       " ('endit', 70),\n",
       " ('ontis', 70),\n",
       " (' iuxt', 70),\n",
       " ('unt i', 70),\n",
       " ('liter', 69),\n",
       " ('iorda', 69),\n",
       " (' quo ', 69),\n",
       " ('us qu', 68),\n",
       " ('clesi', 68),\n",
       " ('alem ', 68),\n",
       " ('itus ', 68),\n",
       " ('habet', 68),\n",
       " ('am in', 67),\n",
       " ('eccle', 67),\n",
       " ('ccles', 67),\n",
       " (' uel ', 67),\n",
       " ('pella', 67),\n",
       " (' fili', 67),\n",
       " ('udine', 67),\n",
       " ('a que', 66),\n",
       " ('es et', 66),\n",
       " (' chri', 66),\n",
       " ('chris', 66),\n",
       " ('m qui', 66),\n",
       " (' in i', 66),\n",
       " (' loco', 66),\n",
       " ('llis ', 66),\n",
       " ('habit', 66),\n",
       " (' iord', 66),\n",
       " ('castr', 66),\n",
       " ('ustru', 66),\n",
       " (' supr', 66),\n",
       " (' simi', 66),\n",
       " ('simil', 66),\n",
       " ('s qui', 65),\n",
       " ('hrist', 65),\n",
       " (' eccl', 65),\n",
       " (' sub ', 65),\n",
       " ('nunc ', 65),\n",
       " (' et h', 65),\n",
       " ('est c', 65),\n",
       " ('dista', 65),\n",
       " ('supra', 65),\n",
       " ('siue ', 65),\n",
       " ('em et', 64),\n",
       " (' ista', 64),\n",
       " (' esse', 64),\n",
       " ('unt e', 64),\n",
       " ('aquil', 64),\n",
       " ('quilo', 64),\n",
       " ('tra o', 64),\n",
       " ('antur', 63),\n",
       " ('abita', 63),\n",
       " (' regi', 63),\n",
       " ('uilon', 63),\n",
       " (' siue', 63),\n",
       " (' plur', 62),\n",
       " ('mons ', 62),\n",
       " ('sicud', 62),\n",
       " ('trans', 61),\n",
       " ('us es', 61),\n",
       " ('haben', 61),\n",
       " ('uper ', 61),\n",
       " (' circ', 61),\n",
       " ('ucas ', 61),\n",
       " ('icud ', 61),\n",
       " ('nibus', 60),\n",
       " ('ontem', 60),\n",
       " ('entes', 60),\n",
       " ('tus e', 60),\n",
       " (' qua ', 60),\n",
       " (' habi', 60),\n",
       " ('eucas', 60),\n",
       " ('e est', 60),\n",
       " ('abet ', 60),\n",
       " ('ilite', 59),\n",
       " ('s ill', 59),\n",
       " (' enim', 59),\n",
       " ('enim ', 59),\n",
       " ('sarra', 59),\n",
       " ('racen', 59),\n",
       " ('e mon', 59),\n",
       " (' uidi', 59),\n",
       " (' sita', 59),\n",
       " ('parte', 59),\n",
       " ('tatis', 59),\n",
       " ('untur', 59),\n",
       " ('imili', 59),\n",
       " ('loco ', 59),\n",
       " ('tur a', 58),\n",
       " ('ntibu', 58),\n",
       " ('onis ', 58),\n",
       " ('et de', 58),\n",
       " ('nt in', 58),\n",
       " (' sarr', 58),\n",
       " ('arrac', 58),\n",
       " ('rrace', 58),\n",
       " ('sita ', 58),\n",
       " ('que e', 57),\n",
       " (' post', 57),\n",
       " (' gali', 57),\n",
       " ('galil', 57),\n",
       " ('alile', 57),\n",
       " (' quan', 57),\n",
       " ('uibus', 57),\n",
       " ('m quo', 57),\n",
       " ('ur in', 57),\n",
       " (' mons', 57),\n",
       " ('rant ', 56),\n",
       " ('erusa', 56),\n",
       " ('salem', 56),\n",
       " ('m que', 56),\n",
       " ('t est', 56),\n",
       " ('upra ', 56),\n",
       " ('risti', 55),\n",
       " ('um de', 55),\n",
       " ('st in', 55),\n",
       " ('usale', 55),\n",
       " ('omini', 55),\n",
       " ('bus e', 55),\n",
       " ('atem ', 55),\n",
       " ('inis ', 55),\n",
       " ('r in ', 55),\n",
       " ('atus ', 55),\n",
       " ('nt et', 55),\n",
       " ('it in', 55),\n",
       " (' fere', 55),\n",
       " ('est s', 55),\n",
       " (' mili', 55),\n",
       " ('n et ', 55),\n",
       " ('itum ', 55),\n",
       " ('rusal', 54),\n",
       " ('ta qu', 54),\n",
       " ('que d', 54),\n",
       " ('tatem', 54),\n",
       " ('m per', 54),\n",
       " ('issim', 54),\n",
       " ('de qu', 54),\n",
       " (' ad m', 54),\n",
       " (' dice', 54),\n",
       " ('fere ', 54),\n",
       " ('a ciu', 54),\n",
       " (' tran', 53),\n",
       " (' pro ', 53),\n",
       " (' et f', 53),\n",
       " (' appe', 53),\n",
       " ('appel', 53),\n",
       " ('ppell', 53),\n",
       " ('milit', 53),\n",
       " (' nec ', 53),\n",
       " ('am qu', 52),\n",
       " ('sepul', 52),\n",
       " ('pulcr', 52),\n",
       " ('ribus', 52),\n",
       " ('tur p', 52),\n",
       " (' secu', 52),\n",
       " ('aris ', 52),\n",
       " ('ista ', 52),\n",
       " (' aliq', 52),\n",
       " ('aliqu', 52),\n",
       " ('nditu', 52),\n",
       " (' pede', 51),\n",
       " ('que i', 51),\n",
       " ('ta es', 51),\n",
       " ('uidi ', 51),\n",
       " ('arte ', 51),\n",
       " ('batur', 51),\n",
       " ('ilone', 51),\n",
       " ('dine ', 51),\n",
       " ('n quo', 51),\n",
       " ('erant', 50),\n",
       " (' egip', 50),\n",
       " ('o et ', 50),\n",
       " (' sepu', 50),\n",
       " ('s qua', 50),\n",
       " (' eam ', 50),\n",
       " ('scend', 50),\n",
       " (' tota', 50),\n",
       " (' ipsa', 50),\n",
       " ('quibu', 50),\n",
       " ('ngitu', 50),\n",
       " ('e quo', 50),\n",
       " ('t mon', 50),\n",
       " ('milia', 50),\n",
       " (' in s', 49),\n",
       " ('tem e', 49),\n",
       " (' ueni', 49),\n",
       " (' illu', 49),\n",
       " (' poss', 49),\n",
       " ('titud', 49),\n",
       " ('aceni', 49),\n",
       " (' in a', 49),\n",
       " ('ibide', 49),\n",
       " ('bidem', 49),\n",
       " ('anis ', 49),\n",
       " ('a ori', 49),\n",
       " (' de i', 49),\n",
       " ('egipt', 48),\n",
       " (' intr', 48),\n",
       " ('erum ', 48),\n",
       " ('in mo', 48),\n",
       " ('a mar', 48),\n",
       " ('inus ', 48),\n",
       " ('ctus ', 48),\n",
       " ('t ter', 48),\n",
       " ('m hab', 48),\n",
       " ('ur et', 48),\n",
       " (' et o', 48),\n",
       " ('ente ', 48),\n",
       " ('stat ', 48),\n",
       " (' prop', 47),\n",
       " (' lapi', 47),\n",
       " (' hec ', 47),\n",
       " ('e que', 47),\n",
       " (' et l', 47),\n",
       " (' quib', 47),\n",
       " ('e per', 47),\n",
       " ('tendi', 47),\n",
       " (' in u', 47),\n",
       " (' ibid', 47),\n",
       " (' edif', 47),\n",
       " ('edifi', 47),\n",
       " ('dific', 47),\n",
       " ('ra au', 47),\n",
       " ('a quo', 46),\n",
       " ('s ad ', 46),\n",
       " ('isse ', 46),\n",
       " ('t ad ', 46),\n",
       " (' de q', 46),\n",
       " (' aqua', 46),\n",
       " ('ocus ', 46),\n",
       " ('ominu', 46),\n",
       " ('cium ', 46),\n",
       " ('ra or', 46),\n",
       " ('t aut', 46),\n",
       " ('tis e', 46),\n",
       " ('e con', 45),\n",
       " (' ante', 45),\n",
       " ('tem i', 45),\n",
       " ('nis e', 45),\n",
       " ('minus', 45),\n",
       " ('ione ', 45),\n",
       " ('i qui', 45),\n",
       " (' pote', 45),\n",
       " (' ab a', 45),\n",
       " ('diceb', 45),\n",
       " ('iceba', 45),\n",
       " ('locus', 45),\n",
       " ('et es', 45),\n",
       " ('t qui', 45),\n",
       " ('ille ', 45),\n",
       " ('est u', 45),\n",
       " ('stian', 44),\n",
       " ('lius ', 44),\n",
       " ('ndum ', 44),\n",
       " ('n mon', 44),\n",
       " ('et si', 44),\n",
       " (' ita ', 44),\n",
       " (' alia', 44),\n",
       " ('secun', 44),\n",
       " ('esse ', 44),\n",
       " ('ntum ', 44),\n",
       " (' faci', 44),\n",
       " ('t ab ', 44),\n",
       " ('cuius', 44),\n",
       " ('dicta', 44),\n",
       " ('istat', 44),\n",
       " ('a aus', 44),\n",
       " ('t ibi', 44),\n",
       " ('t dic', 43),\n",
       " ('istia', 43),\n",
       " ('tem s', 43),\n",
       " ('ue in', 43),\n",
       " ('e qui', 43),\n",
       " ('tribu', 43),\n",
       " ('ores ', 43),\n",
       " ('ebatu', 43),\n",
       " (' cuiu', 43),\n",
       " ('gitur', 43),\n",
       " ('tant ', 43),\n",
       " ('cis c', 43),\n",
       " ('ualli', 43),\n",
       " (' desc', 42),\n",
       " (' quid', 42),\n",
       " ('m con', 42),\n",
       " ('tem c', 42),\n",
       " ('em qu', 42),\n",
       " (' syri', 42),\n",
       " ('s per', 42),\n",
       " ('ecund', 42),\n",
       " ('lilee', 42),\n",
       " ('quant', 42),\n",
       " ('t per', 42),\n",
       " (' lati', 42),\n",
       " ('e de ', 42),\n",
       " (' prim', 42),\n",
       " ('lonem', 42),\n",
       " ('norum', 42),\n",
       " (' dese', 42),\n",
       " ('deser', 42),\n",
       " ('esert', 42),\n",
       " ('lesia', 42),\n",
       " ('rum i', 41),\n",
       " ('ionis', 41),\n",
       " ('s hab', 41),\n",
       " ('t con', 41),\n",
       " ('cebat', 41),\n",
       " ('e dic', 41),\n",
       " ('eucam', 41),\n",
       " ('3 leu', 41),\n",
       " ('incip', 40),\n",
       " ('aria ', 40),\n",
       " ('intra', 40),\n",
       " (' anti', 40),\n",
       " ('lapid', 40),\n",
       " ('et su', 40),\n",
       " ('templ', 40),\n",
       " ('in te', 40),\n",
       " (' cons', 40),\n",
       " ('is de', 40),\n",
       " ('rum a', 40),\n",
       " ('in lo', 40),\n",
       " ('ia et', 40),\n",
       " ('licet', 40),\n",
       " ('icet ', 40),\n",
       " (' camp', 40),\n",
       " ('et di', 40),\n",
       " ('rdane', 40),\n",
       " ('a dic', 40),\n",
       " ('ucam ', 40),\n",
       " ('m usq', 40),\n",
       " (' omne', 40),\n",
       " ('is es', 40),\n",
       " (' 3 le', 40),\n",
       " ('allis', 40),\n",
       " ('orta ', 40),\n",
       " ('terre', 39),\n",
       " ('rum s', 39),\n",
       " ('erram', 39),\n",
       " ('rram ', 39),\n",
       " ('epulc', 39),\n",
       " ('ante ', 39),\n",
       " ('tione', 39),\n",
       " ('unt a', 39),\n",
       " ('in la', 39),\n",
       " ('ilee ', 39),\n",
       " ('n qua', 39),\n",
       " (' medi', 39),\n",
       " ('e qua', 39),\n",
       " ('a ill', 39),\n",
       " ('et ca', 39),\n",
       " ('em es', 39),\n",
       " ('o quo', 39),\n",
       " ('de mo', 39),\n",
       " ('icta ', 39),\n",
       " ('dicun', 39),\n",
       " ('icunt', 39),\n",
       " ('est t', 39),\n",
       " ('e mar', 39),\n",
       " ('iam e', 39),\n",
       " ('cunt ', 39),\n",
       " (' font', 39),\n",
       " ('m ubi', 39),\n",
       " ('t sup', 39),\n",
       " ('ulis ', 38),\n",
       " (' illi', 38),\n",
       " ('post ', 38),\n",
       " ('um ad', 38),\n",
       " (' adhu', 38),\n",
       " ('adhuc', 38),\n",
       " ('dhuc ', 38),\n",
       " ('ionem', 38),\n",
       " ('um su', 38),\n",
       " ('per t', 38),\n",
       " ('t ciu', 38),\n",
       " ('antum', 38),\n",
       " (' hoc ', 38),\n",
       " ('m uer', 38),\n",
       " ('it et', 38),\n",
       " ('ental', 38),\n",
       " (' trib', 38),\n",
       " (' dicu', 38),\n",
       " ('iunt ', 38),\n",
       " ('omnes', 38),\n",
       " ('mnes ', 38),\n",
       " (' ad o', 38),\n",
       " ('tum i', 37),\n",
       " ('osten', 37),\n",
       " ('stend', 37),\n",
       " ('riam ', 37),\n",
       " (' et n', 37),\n",
       " ('i sun', 37),\n",
       " ('ando ', 37),\n",
       " ('est e', 37),\n",
       " (' ab i', 37),\n",
       " ('a qua', 37),\n",
       " ('gnum ', 37),\n",
       " ('a par', 37),\n",
       " ('s sun', 37),\n",
       " ('alis ', 37),\n",
       " ('1 leu', 37),\n",
       " ('o in ', 37),\n",
       " ('munit', 37),\n",
       " ('ualle', 37),\n",
       " (' ille', 37),\n",
       " ('n lon', 37),\n",
       " (' pisc', 37),\n",
       " ('s quo', 36),\n",
       " ('tes e', 36),\n",
       " (' hodi', 36),\n",
       " ('hodie', 36),\n",
       " ('odie ', 36),\n",
       " ('tem a', 36),\n",
       " (' loca', 36),\n",
       " ('t ali', 36),\n",
       " ('s pro', 36),\n",
       " ('s dic', 36),\n",
       " ('longi', 36),\n",
       " ('gitud', 36),\n",
       " ('que s', 36),\n",
       " ('mari ', 36),\n",
       " ('ta et', 36),\n",
       " (' 4 le', 36),\n",
       " ('4 leu', 36),\n",
       " ('maris', 36),\n",
       " ('ictum', 36),\n",
       " ('etur ', 36),\n",
       " ('ceni ', 36),\n",
       " ('ebat ', 36),\n",
       " (' muni', 36),\n",
       " ('um si', 35),\n",
       " ('isti ', 35),\n",
       " ('rum q', 35),\n",
       " (' oste', 35),\n",
       " ('rum p', 35),\n",
       " ('um pe', 35),\n",
       " ('us su', 35),\n",
       " (' in h', 35),\n",
       " ('tempo', 35),\n",
       " ('empor', 35),\n",
       " ('ongit', 35),\n",
       " (' habu', 35),\n",
       " ('ipsa ', 35),\n",
       " ('tur q', 35),\n",
       " ('ur qu', 35),\n",
       " ('t hab', 35),\n",
       " ('tur s', 35),\n",
       " ('ultra', 35),\n",
       " ('ltra ', 35),\n",
       " ('locum', 35),\n",
       " ('ocum ', 35),\n",
       " (' fuer', 35),\n",
       " ('dictu', 35),\n",
       " ('potes', 35),\n",
       " (' uia ', 35),\n",
       " ('rtum ', 35),\n",
       " ('escen', 35),\n",
       " ('tere ', 35),\n",
       " ('tum a', 34),\n",
       " ('m int', 34),\n",
       " ('olis ', 34),\n",
       " ('et ma', 34),\n",
       " ('ius e', 34),\n",
       " ('m mar', 34),\n",
       " ('am de', 34),\n",
       " ('m sed', 34),\n",
       " ('ris e', 34),\n",
       " ('et ha', 34),\n",
       " ('atum ', 34),\n",
       " ('bus i', 34),\n",
       " ('rum u', 34),\n",
       " ('posse', 34),\n",
       " (' situ', 34),\n",
       " ('ellat', 34),\n",
       " ('s mon', 34),\n",
       " ('magna', 34),\n",
       " (' huiu', 34),\n",
       " ('huius', 34),\n",
       " (' 1 le', 34),\n",
       " ('s ciu', 34),\n",
       " ('est m', 34),\n",
       " ('astru', 34),\n",
       " ('tur d', 34),\n",
       " ('erior', 34),\n",
       " ('ifica', 34),\n",
       " (' ultr', 34),\n",
       " ('n lat', 34),\n",
       " ('otest', 34),\n",
       " ('ducit', 34),\n",
       " ('pore ', 34),\n",
       " ('erre ', 33),\n",
       " ('iani ', 33),\n",
       " (' in d', 33),\n",
       " ('t quo', 33),\n",
       " ('nte s', 33),\n",
       " ('a per', 33),\n",
       " ('um se', 33),\n",
       " ('iam s', 33),\n",
       " ('um ue', 33),\n",
       " ('est p', 33),\n",
       " ('s eiu', 33),\n",
       " ('n ter', 33),\n",
       " ('uantu', 33),\n",
       " ('pluri', 33),\n",
       " ('latit', 33),\n",
       " ('atitu', 33),\n",
       " ('tissi', 33),\n",
       " ('mini ', 33),\n",
       " ('ontes', 33),\n",
       " ('m dic', 33),\n",
       " ('unt s', 33),\n",
       " ('um ma', 33),\n",
       " (' uill', 33),\n",
       " ('a ual', 33),\n",
       " ('unt c', 33),\n",
       " ('on et', 33),\n",
       " ('inum ', 33),\n",
       " ('uerun', 33),\n",
       " ('nt qu', 33),\n",
       " ('imum ', 33),\n",
       " ('m mon', 33),\n",
       " ('nde a', 33),\n",
       " (' coll', 33),\n",
       " ('a de ', 33),\n",
       " ('iliar', 33),\n",
       " ('desce', 33),\n",
       " ('em de', 32),\n",
       " ('tem u', 32),\n",
       " ('loca ', 32),\n",
       " ('oris ', 32),\n",
       " ('et te', 32),\n",
       " (' mort', 32),\n",
       " ('tota ', 32),\n",
       " ('a sun', 32),\n",
       " (' alii', 32),\n",
       " ('omnib', 32),\n",
       " ('mnibu', 32),\n",
       " ('i de ', 32),\n",
       " ('circa', 32),\n",
       " ('irca ', 32),\n",
       " ('tur u', 32),\n",
       " ('es su', 32),\n",
       " ('i est', 32),\n",
       " ('um di', 32),\n",
       " (' ab o', 32),\n",
       " ('itant', 32),\n",
       " ('i dic', 32),\n",
       " (' cred', 32),\n",
       " ('danem', 32),\n",
       " ('uerit', 32),\n",
       " ('ilis ', 32),\n",
       " (' de s', 32),\n",
       " ('est l', 32),\n",
       " ('a aqu', 32),\n",
       " ('circu', 32),\n",
       " (' rege', 32),\n",
       " (' ad a', 32),\n",
       " (' duci', 32),\n",
       " ('ucit ', 32),\n",
       " ('ltum ', 32),\n",
       " ('et se', 32),\n",
       " ('mpore', 32),\n",
       " ('o loc', 32),\n",
       " (' ipso', 32),\n",
       " ('rum d', 31),\n",
       " (' proc', 31),\n",
       " ('bus p', 31),\n",
       " ('edes ', 31),\n",
       " (' ad s', 31),\n",
       " ('us di', 31),\n",
       " ('rente', 31),\n",
       " ('abent', 31),\n",
       " ('sset ', 31),\n",
       " ('ebant', 31),\n",
       " (' ad p', 31),\n",
       " ('est d', 31),\n",
       " ('in ea', 31),\n",
       " ('bitan', 31),\n",
       " ('nis i', 31),\n",
       " (' in r', 31),\n",
       " ('ia qu', 31),\n",
       " ('t omn', 31),\n",
       " ('torre', 31),\n",
       " ('orren', 31),\n",
       " (' litt', 31),\n",
       " ('e sun', 31),\n",
       " ('is si', 31),\n",
       " ('test ', 31),\n",
       " (' beat', 31),\n",
       " ('e gal', 31),\n",
       " ('um co', 31),\n",
       " ('ascen', 31),\n",
       " (' daui', 31),\n",
       " ('dauid', 31),\n",
       " ('icit ', 30),\n",
       " ('s mar', 30),\n",
       " ('re et', 30),\n",
       " ('abens', 30),\n",
       " ('bens ', 30),\n",
       " (' nisi', 30),\n",
       " ('nisi ', 30),\n",
       " ('at in', 30),\n",
       " ('t loc', 30),\n",
       " ('et al', 30),\n",
       " ('t pro', 30),\n",
       " ('ta in', 30),\n",
       " ('s ter', 30),\n",
       " ('a ter', 30),\n",
       " (' quar', 30),\n",
       " ('is di', 30),\n",
       " ('de et', 30),\n",
       " ('um re', 30),\n",
       " ('nomin', 30),\n",
       " ('qui e', 30),\n",
       " ('stro ', 30),\n",
       " ('e hab', 30),\n",
       " ('a qui', 30),\n",
       " ('n ea ', 30),\n",
       " ('ant i', 30),\n",
       " ('idam ', 30),\n",
       " ('lis e', 30),\n",
       " ('anem ', 30),\n",
       " ('filii', 30),\n",
       " ('tus i', 30),\n",
       " ('edit ', 30),\n",
       " (' turr', 30),\n",
       " ('us de', 30),\n",
       " (' 2 le', 30),\n",
       " ('2 leu', 30),\n",
       " (' et r', 30),\n",
       " ('cum i', 30),\n",
       " (' late', 30),\n",
       " (' ieru', 30),\n",
       " ('ierus', 30),\n",
       " ('rat i', 30),\n",
       " ('ncipi', 29),\n",
       " ('cit i', 29),\n",
       " ('imus ', 29),\n",
       " ('antiq', 29),\n",
       " ('ntiqu', 29),\n",
       " ('um pr', 29),\n",
       " (' uirg', 29),\n",
       " ('a era', 29),\n",
       " ('orem ', 29),\n",
       " ('dens ', 29),\n",
       " ('s pre', 29),\n",
       " ('et qu', 29),\n",
       " ('inem ', 29),\n",
       " ('prete', 29),\n",
       " ('us pr', 29),\n",
       " ('rra i', 29),\n",
       " ('cere ', 29),\n",
       " ('ere p', 29),\n",
       " (' de m', 29),\n",
       " ('e ter', 29),\n",
       " (' totu', 29),\n",
       " ('otum ', 29),\n",
       " ('m ter', 29),\n",
       " ('e ill', 29),\n",
       " ('ones ', 29),\n",
       " ('iorum', 29),\n",
       " ('s sed', 29),\n",
       " ('ntali', 29),\n",
       " (' phil', 29),\n",
       " ('ue es', 29),\n",
       " ('llatu', 29),\n",
       " ('c est', 29),\n",
       " (' de c', 29),\n",
       " ('as et', 29),\n",
       " ('n qui', 29),\n",
       " (' mihi', 29),\n",
       " ('mihi ', 29),\n",
       " (' isti', 29),\n",
       " ('unde ', 29),\n",
       " ('us ma', 29),\n",
       " (' torr', 29),\n",
       " ('t aqu', 29),\n",
       " (' acho', 29),\n",
       " ('in li', 29),\n",
       " ('situm', 29),\n",
       " (' plan', 29),\n",
       " ('t ind', 29),\n",
       " ('alia ', 29),\n",
       " ('rum c', 29),\n",
       " ('ultum', 29),\n",
       " ('later', 29),\n",
       " ('rdani', 29),\n",
       " ('danis', 29),\n",
       " ('ipso ', 29),\n",
       " ('is ui', 28),\n",
       " ('tiani', 28),\n",
       " ('iuers', 28),\n",
       " ('a san', 28),\n",
       " ('tum s', 28),\n",
       " ('et pa', 28),\n",
       " ('enden', 28),\n",
       " (' pres', 28),\n",
       " (' illo', 28),\n",
       " ('illo ', 28),\n",
       " ('unt p', 28),\n",
       " (' pret', 28),\n",
       " (' comm', 28),\n",
       " ('d dic', 28),\n",
       " ('et pe', 28),\n",
       " ('liis ', 28),\n",
       " ('i quo', 28),\n",
       " ('s ali', 28),\n",
       " ('ita e', 28),\n",
       " (' et b', 28),\n",
       " ('polis', 28),\n",
       " (' fluu', 28),\n",
       " ('ium e', 28),\n",
       " ('ter a', 28),\n",
       " ('multa', 28),\n",
       " ('e mag', 28),\n",
       " ('em se', 28),\n",
       " ('lium ', 28),\n",
       " ('uidam', 28),\n",
       " ('em ad', 28),\n",
       " ('ra aq', 28),\n",
       " ('de ad', 28),\n",
       " ('ius u', 28),\n",
       " ('inist', 28),\n",
       " ('nistr', 28),\n",
       " (' asce', 28),\n",
       " ('pisci', 28),\n",
       " ('bant ', 28),\n",
       " ('auid ', 28),\n",
       " ('ut di', 27),\n",
       " ('i per', 27),\n",
       " ('proce', 27),\n",
       " ('t ill', 27),\n",
       " (' fact', 27),\n",
       " ('reter', 27),\n",
       " ('ation', 27),\n",
       " ('unt m', 27),\n",
       " ('mortu', 27),\n",
       " (' tant', 27),\n",
       " ('uit s', 27),\n",
       " ('tum p', 27),\n",
       " ('s ubi', 27),\n",
       " ('tores', 27),\n",
       " ('bus s', 27),\n",
       " ('regio', 27),\n",
       " ('d in ', 27),\n",
       " ('t cas', 27),\n",
       " (' nomi', 27),\n",
       " ('s ut ', 27),\n",
       " ('quitu', 27),\n",
       " (' inci', 27),\n",
       " (' petr', 27),\n",
       " ('et pr', 27),\n",
       " ('quida', 27),\n",
       " ('liban', 27),\n",
       " (' quem', 27),\n",
       " (' unde', 27),\n",
       " ('m reg', 27),\n",
       " ('o per', 27),\n",
       " ('s ual', 27),\n",
       " ('tis s', 27),\n",
       " ('achon', 27),\n",
       " ('uod d', 27),\n",
       " ('litto', 27),\n",
       " ('ittor', 27),\n",
       " ('tore ', 27),\n",
       " ('tur m', 27),\n",
       " (' isto', 27),\n",
       " ('e ist', 27),\n",
       " ('quand', 27),\n",
       " ('ilia ', 27),\n",
       " ('rius ', 27),\n",
       " ('atere', 27),\n",
       " ('in pe', 27),\n",
       " ('liari', 27),\n",
       " ('t des', 26),\n",
       " ('ransi', 26),\n",
       " ('enti ', 26),\n",
       " ('ti et', 26),\n",
       " ('ulum ', 26),\n",
       " (' eran', 26),\n",
       " ('entis', 26),\n",
       " ('ceden', 26),\n",
       " ('iam i', 26),\n",
       " ('herus', 26),\n",
       " ('illud', 26),\n",
       " ('i con', 26),\n",
       " ('t cum', 26),\n",
       " ('ter e', 26),\n",
       " ('undum', 26),\n",
       " ('tris ', 26),\n",
       " (' hanc', 26),\n",
       " ('hanc ', 26),\n",
       " ('non e', 26),\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_n_gram_frequency(5, zwickau_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db2121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_5_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name):\n",
    "    return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63c7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_6_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name):\n",
    "    return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47a92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_7_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name):\n",
    "    return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ed78fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_8_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name):\n",
    "    return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcb0224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_9_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name):\n",
    "    return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56611e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_10_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name):\n",
    "    return creat_n_gram_frequency_data(corpus_1, corpus_1_name, corpus_2, corpus_2_name, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4648a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_5_frequency = creat_5_gram_frequency_data(\n",
    "    zwickau_corpus,\n",
    "    'zwickau',\n",
    "    london_corpus,\n",
    "    'london'\n",
    ")\n",
    "gram_6_frequency = creat_6_gram_frequency_data(\n",
    "    zwickau_corpus,\n",
    "    'zwickau',\n",
    "    london_corpus,\n",
    "    'london'\n",
    ")\n",
    "gram_7_frequency = creat_7_gram_frequency_data(\n",
    "    zwickau_corpus,\n",
    "    'zwickau',\n",
    "    london_corpus,\n",
    "    'london'\n",
    ")\n",
    "gram_8_frequency = creat_8_gram_frequency_data(\n",
    "    zwickau_corpus,\n",
    "    'zwickau',\n",
    "    london_corpus,\n",
    "    'london'\n",
    ")\n",
    "gram_9_frequency = creat_9_gram_frequency_data(\n",
    "    zwickau_corpus,\n",
    "    'zwickau',\n",
    "    london_corpus,\n",
    "    'london'\n",
    ")\n",
    "gram_10_frequency = creat_10_gram_frequency_data(\n",
    "    zwickau_corpus,\n",
    "    'zwickau',\n",
    "    london_corpus,\n",
    "    'london'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c276861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>word</th>\n",
       "      <th>zwickau</th>\n",
       "      <th>london</th>\n",
       "      <th>version with higher score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_counter</td>\n",
       "      <td>et</td>\n",
       "      <td>1521</td>\n",
       "      <td>1685</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_counter</td>\n",
       "      <td>in</td>\n",
       "      <td>1038</td>\n",
       "      <td>1149</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_counter</td>\n",
       "      <td>est</td>\n",
       "      <td>600</td>\n",
       "      <td>668</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word_counter</td>\n",
       "      <td>de</td>\n",
       "      <td>459</td>\n",
       "      <td>531</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_counter</td>\n",
       "      <td>ad</td>\n",
       "      <td>426</td>\n",
       "      <td>441</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801433</th>\n",
       "      <td>count_vectorizer_10_gram</td>\n",
       "      <td>_dietarum_</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801434</th>\n",
       "      <td>count_vectorizer_10_gram</td>\n",
       "      <td>dietarum_a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801435</th>\n",
       "      <td>count_vectorizer_10_gram</td>\n",
       "      <td>ietarum_am</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801436</th>\n",
       "      <td>count_vectorizer_10_gram</td>\n",
       "      <td>etarum_ame</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801437</th>\n",
       "      <td>count_vectorizer_10_gram</td>\n",
       "      <td>tarum_amen</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801438 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature_name        word  zwickau  london  \\\n",
       "0                   word_counter          et     1521    1685   \n",
       "1                   word_counter          in     1038    1149   \n",
       "2                   word_counter         est      600     668   \n",
       "3                   word_counter          de      459     531   \n",
       "4                   word_counter          ad      426     441   \n",
       "...                          ...         ...      ...     ...   \n",
       "801433  count_vectorizer_10_gram  _dietarum_        0       1   \n",
       "801434  count_vectorizer_10_gram  dietarum_a        0       1   \n",
       "801435  count_vectorizer_10_gram  ietarum_am        0       1   \n",
       "801436  count_vectorizer_10_gram  etarum_ame        0       1   \n",
       "801437  count_vectorizer_10_gram  tarum_amen        0       1   \n",
       "\n",
       "       version with higher score  \n",
       "0                         london  \n",
       "1                         london  \n",
       "2                         london  \n",
       "3                         london  \n",
       "4                         london  \n",
       "...                          ...  \n",
       "801433                    london  \n",
       "801434                    london  \n",
       "801435                    london  \n",
       "801436                    london  \n",
       "801437                    london  \n",
       "\n",
       "[801438 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = [\n",
    "    'feature_name', \n",
    "    'word', \n",
    "    'zwickau', \n",
    "    'london',\n",
    "    'version with higher score'\n",
    "]\n",
    "\n",
    "words_df = pd.DataFrame(\n",
    "    word_freq + gram_5_frequency + gram_6_frequency + gram_7_frequency + gram_8_frequency + gram_9_frequency + gram_10_frequency,\n",
    "    columns=df_columns\n",
    ")\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ebf53ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>word</th>\n",
       "      <th>zwickau</th>\n",
       "      <th>london</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_counter</td>\n",
       "      <td>ad</td>\n",
       "      <td>426</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_name word  zwickau  london\n",
       "4  word_counter   ad      426     441"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df['feature_name'] == 'word_counter']].to_csv('../computed_data/text_to_text/5_gram_zwickau_stats_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc269b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df[words_df['feature_name'] == 'word_counter'].to_csv('../computed_data/text_to_text/count_words/word_counter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c915ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in [\n",
    "    'word_counter',\n",
    "    'count_vectorizer_5_gram',\n",
    "    'count_vectorizer_6_gram',\n",
    "    'count_vectorizer_7_gram',\n",
    "    'count_vectorizer_8_gram',\n",
    "    'count_vectorizer_9_gram',\n",
    "    'count_vectorizer_10_gram'\n",
    "]:\n",
    "    words_df[\n",
    "        words_df['feature_name'] == feature_name\n",
    "    ].to_csv(f'../computed_data/text_to_text/count_words/{feature_name}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
