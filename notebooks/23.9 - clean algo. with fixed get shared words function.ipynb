{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac94cb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef52bf",
   "metadata": {},
   "source": [
    "As I found that I had an issue with get_shared_words - function can return the same word from text1 multiple times even though in text2 it appears only once (cause I didn't deleted it from both texts once match found)\n",
    "\n",
    "This notebook is execution of clean algo with fixed function, in order to be able to compare if there is main difference in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "60b5cb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'similarities.cosine' from '../src/similarities/cosine.py'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import sys\n",
    "import imp\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import data.reader as dataReader\n",
    "import utils.utils as thesisUtils\n",
    "import similarities.cosine as thesisCosineSimilarity\n",
    "import vocabulary.vocabulary as thesisVocabulary\n",
    "import features.model_features as thesisModelFeatures\n",
    "import features.factory as thesisFactoryFeatures\n",
    "import data.corpus_stats as thesisCorpusStats\n",
    "\n",
    "imp.reload(dataReader)\n",
    "imp.reload(thesisUtils)\n",
    "imp.reload(thesisVocabulary)\n",
    "imp.reload(thesisCorpusStats)\n",
    "imp.reload(thesisModelFeatures)\n",
    "imp.reload(thesisFactoryFeatures)\n",
    "imp.reload(thesisCosineSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9def95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_corpus = dataReader.CorpusByNewLine.london()\n",
    "zwickau_corpus = dataReader.CorpusByNewLine.zwickau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2eb4c0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506.3659305993691"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average([ len(\"\".join(i.split())) for i in london_corpus.corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "489e914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresFactory  = thesisFactoryFeatures.FeaturesFactory(\n",
    "    london_corpus = london_corpus,\n",
    "    zwickau_corpus = zwickau_corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f343de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_zwickau_similarities = thesisCosineSimilarity.CrossVersionSimilarity5Gram(london_corpus, zwickau_corpus)\n",
    "# london_zwickau_similarities.calculate()\n",
    "\n",
    "zwickau_london_similarities = thesisCosineSimilarity.CrossVersionSimilarity5Gram(zwickau_corpus, london_corpus)\n",
    "# zwickau_london_similarities.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64fded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# london_zwickau_similarities.save()\n",
    "# zwickau_london_similarities.save()\n",
    "london_zwickau_similarities.load()\n",
    "zwickau_london_similarities.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025c30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_corpus_by_london = dataReader.BurchardCorpus(london_corpus, zwickau_corpus)\n",
    "burchard_corpus_by_zwickau = dataReader.BurchardCorpus(zwickau_corpus, london_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995a8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_leftovers = dataReader.LeftoversCorpus(london_corpus, zwickau_corpus)\n",
    "zwickau_leftovers = dataReader.LeftoversCorpus(zwickau_corpus, london_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "288e57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "print(len(london_leftovers.corpus_for_predictions()))\n",
    "print(len(zwickau_leftovers.corpus_for_predictions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de899f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_p(corpus):\n",
    "    return list(filter(lambda x: len(x.split()) > 20, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3482b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_burchard_corpus_with_predictions(burchard_corpus, wrong_predictions_by_london, wrong_predictions_by_zwickau):\n",
    "    is_burchard = True\n",
    "    temp_corpus = [ [p, is_burchard, is_burchard] for p in burchard_corpus ]\n",
    "    \n",
    "    for prediction in wrong_predictions_by_london:\n",
    "        temp_corpus[prediction.index][1] = False\n",
    "    for prediction in wrong_predictions_by_zwickau:\n",
    "        temp_corpus[prediction.index][2] = False\n",
    "\n",
    "    return temp_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c803d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_leftofvers_long = filter_short_p(london_leftovers.corpus)\n",
    "zwickau_leftofvers_long = filter_short_p(zwickau_leftovers.corpus)\n",
    "burchard_corpus_by_london_corpus_long = filter_short_p(burchard_corpus_by_london.corpus)\n",
    "burchard_corpus_by_zwickau_corpus_long = filter_short_p(burchard_corpus_by_zwickau.corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3761e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "print(len(burchard_corpus_by_london_corpus_long))\n",
    "print(len(burchard_corpus_by_zwickau_corpus_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ccc3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_by_london_VS_zwickau_features_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    burchard_corpus_by_london_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")\n",
    "burchard_by_zwickau_VS_zwickau_features_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_leftofvers_long,\n",
    "    burchard_corpus_by_zwickau_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")\n",
    "burchard_by_london_VS_london_features_df = thesisModelFeatures.create_features_df(\n",
    "    london_leftofvers_long,\n",
    "    None,\n",
    "    burchard_corpus_by_london_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")\n",
    "burchard_by_zwickau_VS_london_features_df = thesisModelFeatures.create_features_df(\n",
    "    london_leftofvers_long,\n",
    "    None,\n",
    "    burchard_corpus_by_zwickau_corpus_long,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5cda1",
   "metadata": {},
   "source": [
    "## london VS zwickau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21323443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 5_gram\n",
      "n_gram_feature_name: 5_gram\n"
     ]
    }
   ],
   "source": [
    "london_vs_zwickau_features_df = featuresFactory.london_VS_zwickau(n_gram = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c62fe12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_vs_zwickau_modesl_experiment = thesisModelFeatures.ModelsExperiment(london_vs_zwickau_features_df, 'london_vs_zwickau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e24f751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: DecisionTreeClassifier\n",
      "Elapsed time to compute the cross validate: 0.067 minutes\n",
      "running: GaussianProcessClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the cross validate: 0.395 minutes\n",
      "running: RandomForestClassifier\n",
      "Elapsed time to compute the cross validate: 0.080 minutes\n",
      "running: MLPClassifier\n",
      "Elapsed time to compute the cross validate: 7.165 minutes\n",
      "running: GaussianNB\n",
      "Elapsed time to compute the cross validate: 0.042 minutes\n",
      "running: KNeighborsClassifier\n",
      "Elapsed time to compute the cross validate: 0.118 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the cross validate: 0.294 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the cross validate: 1.645 minutes\n"
     ]
    }
   ],
   "source": [
    "london_vs_zwickau_modesl_experiment.run_cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b4929ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.644888</td>\n",
       "      <td>0.641815</td>\n",
       "      <td>0.641103</td>\n",
       "      <td>0.643763</td>\n",
       "      <td>0.642272</td>\n",
       "      <td>0.643763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.638522</td>\n",
       "      <td>0.633810</td>\n",
       "      <td>0.626616</td>\n",
       "      <td>0.633978</td>\n",
       "      <td>0.627473</td>\n",
       "      <td>0.633978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.564386</td>\n",
       "      <td>0.562292</td>\n",
       "      <td>0.559406</td>\n",
       "      <td>0.564946</td>\n",
       "      <td>0.561047</td>\n",
       "      <td>0.564946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.563087</td>\n",
       "      <td>0.561845</td>\n",
       "      <td>0.556595</td>\n",
       "      <td>0.561828</td>\n",
       "      <td>0.557048</td>\n",
       "      <td>0.561828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.510956</td>\n",
       "      <td>0.503810</td>\n",
       "      <td>0.482487</td>\n",
       "      <td>0.508280</td>\n",
       "      <td>0.485266</td>\n",
       "      <td>0.508280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.463535</td>\n",
       "      <td>0.466131</td>\n",
       "      <td>0.419225</td>\n",
       "      <td>0.474946</td>\n",
       "      <td>0.425272</td>\n",
       "      <td>0.474946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.347066</td>\n",
       "      <td>0.458690</td>\n",
       "      <td>0.357748</td>\n",
       "      <td>0.472258</td>\n",
       "      <td>0.366915</td>\n",
       "      <td>0.472258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.438806</td>\n",
       "      <td>0.434643</td>\n",
       "      <td>0.418199</td>\n",
       "      <td>0.438925</td>\n",
       "      <td>0.421507</td>\n",
       "      <td>0.438925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "XGBClassifier                     0.644888      0.641815  0.641103  0.643763   \n",
       "DecisionTreeClassifier            0.638522      0.633810  0.626616  0.633978   \n",
       "RandomForestClassifier            0.564386      0.562292  0.559406  0.564946   \n",
       "AdaBoostClassifier                0.563087      0.561845  0.556595  0.561828   \n",
       "KNeighborsClassifier              0.510956      0.503810  0.482487  0.508280   \n",
       "GaussianNB                        0.463535      0.466131  0.419225  0.474946   \n",
       "GaussianProcessClassifier         0.347066      0.458690  0.357748  0.472258   \n",
       "MLPClassifier                     0.438806      0.434643  0.418199  0.438925   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "XGBClassifier                 0.642272  0.643763  \n",
       "DecisionTreeClassifier        0.627473  0.633978  \n",
       "RandomForestClassifier        0.561047  0.564946  \n",
       "AdaBoostClassifier            0.557048  0.561828  \n",
       "KNeighborsClassifier          0.485266  0.508280  \n",
       "GaussianNB                    0.425272  0.474946  \n",
       "GaussianProcessClassifier     0.366915  0.472258  \n",
       "MLPClassifier                 0.421507  0.438925  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_vs_zwickau_modesl_experiment.show_cross_validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c97880ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: DecisionTreeClassifier\n",
      "Elapsed time to compute the greed search cv: 0.516 minutes\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.5316129  0.49516129 0.51526882 0.53537634 0.52892473 0.52225806\n",
      " 0.52892473 0.53215054 0.5316129  0.49516129 0.51526882 0.53537634\n",
      " 0.52892473 0.52225806 0.52892473 0.53215054 0.48548387 0.5116129\n",
      " 0.48526882 0.51505376 0.5183871  0.5183871  0.52806452 0.51172043\n",
      " 0.55150538 0.52494624 0.52817204 0.53505376 0.52526882 0.54182796\n",
      " 0.54505376 0.55172043 0.55150538 0.52494624 0.52817204 0.53505376\n",
      " 0.52526882 0.54182796 0.54505376 0.55172043 0.47215054 0.4855914\n",
      " 0.46591398 0.48903226 0.50204301 0.50172043 0.51505376 0.51827957\n",
      " 0.5116129  0.54795699 0.55462366 0.55139785 0.5516129  0.54806452\n",
      " 0.5383871  0.54505376 0.5116129  0.54795699 0.55462366 0.55139785\n",
      " 0.5516129  0.54806452 0.5383871  0.54505376 0.50505376 0.4916129\n",
      " 0.47193548 0.48182796 0.50473118 0.49172043 0.49516129 0.50827957\n",
      " 0.5311828  0.5544086  0.55763441 0.56763441 0.56096774 0.5544086\n",
      " 0.5383871  0.55150538 0.5311828  0.5544086  0.55763441 0.56763441\n",
      " 0.56096774 0.5544086  0.5383871  0.55150538 0.50182796 0.49182796\n",
      " 0.48204301 0.50182796 0.50526882 0.50516129 0.49526882 0.50516129\n",
      " 0.54430108 0.52774194 0.55419355 0.56086022 0.57064516 0.54763441\n",
      " 0.56763441 0.57096774 0.54430108 0.52774194 0.55419355 0.56086022\n",
      " 0.57064516 0.54763441 0.56763441 0.57096774 0.5216129  0.51193548\n",
      " 0.47903226 0.49215054 0.51215054 0.50215054 0.50849462 0.50860215\n",
      " 0.54752688 0.53129032 0.55741935 0.55741935 0.5744086  0.56451613\n",
      " 0.57419355 0.56741935 0.54752688 0.53129032 0.55741935 0.55741935\n",
      " 0.5744086  0.56451613 0.57419355 0.56741935 0.52150538 0.52483871\n",
      " 0.49247312 0.49892473 0.51204301 0.51526882 0.52172043 0.51182796\n",
      " 0.51150538 0.55397849 0.54731183 0.55430108 0.58053763 0.55451613\n",
      " 0.55774194 0.56752688 0.51150538 0.55397849 0.54731183 0.55430108\n",
      " 0.58053763 0.55451613 0.55774194 0.56752688 0.51795699 0.53462366\n",
      " 0.49247312 0.49569892 0.50215054 0.49204301 0.4988172  0.48892473\n",
      " 0.54419355 0.55086022 0.56043011 0.57397849 0.58387097 0.57075269\n",
      " 0.57731183 0.56763441 0.54419355 0.55086022 0.56043011 0.57397849\n",
      " 0.58387097 0.57075269 0.57731183 0.56763441 0.51473118 0.52516129\n",
      " 0.4988172  0.51537634 0.51526882 0.51204301 0.51870968 0.5055914\n",
      " 0.52784946 0.54419355 0.54408602 0.54741935 0.55763441 0.54473118\n",
      " 0.57430108 0.5611828  0.52784946 0.54419355 0.54408602 0.54741935\n",
      " 0.55763441 0.54473118 0.57430108 0.5611828  0.51096774 0.53483871\n",
      " 0.53182796 0.52215054 0.53860215 0.51225806 0.52860215 0.5316129\n",
      " 0.54150538 0.54139785 0.52806452 0.5283871  0.55784946 0.54462366\n",
      " 0.53494624 0.52193548 0.54150538 0.54139785 0.52806452 0.5283871\n",
      " 0.55784946 0.54462366 0.53494624 0.52193548 0.48215054 0.49849462\n",
      " 0.4983871  0.51182796 0.51494624 0.52150538 0.5216129  0.51494624\n",
      " 0.5316129  0.56075269 0.53129032 0.55129032 0.55763441 0.54473118\n",
      " 0.53172043 0.53827957 0.5316129  0.56075269 0.53129032 0.55129032\n",
      " 0.55763441 0.54473118 0.53172043 0.53827957 0.50516129 0.48548387\n",
      " 0.4855914  0.49860215 0.50193548 0.50193548 0.50193548 0.50516129\n",
      " 0.54430108 0.56075269 0.53784946 0.54462366 0.53150538 0.54150538\n",
      " 0.52817204 0.5316129  0.54430108 0.56075269 0.53784946 0.54462366\n",
      " 0.53150538 0.54150538 0.52817204 0.5316129  0.51526882 0.50139785\n",
      " 0.45537634 0.48505376 0.48849462 0.50193548 0.51494624 0.51182796\n",
      " 0.53784946 0.51462366 0.55107527 0.5411828  0.54806452 0.54806452\n",
      " 0.54806452 0.54483871 0.53784946 0.51462366 0.55107527 0.5411828\n",
      " 0.54806452 0.54806452 0.54806452 0.54483871 0.51172043 0.49193548\n",
      " 0.50204301 0.49860215 0.49860215 0.50516129 0.51193548 0.50526882\n",
      " 0.53806452 0.53795699 0.52473118 0.54129032 0.53806452 0.55096774\n",
      " 0.5611828  0.5511828  0.53806452 0.53795699 0.52473118 0.54129032\n",
      " 0.53806452 0.55096774 0.5611828  0.5511828  0.50580645 0.53182796\n",
      " 0.49537634 0.50860215 0.52860215 0.51849462 0.51172043 0.51526882\n",
      " 0.52827957 0.56096774 0.56408602 0.57086022 0.55774194 0.54784946\n",
      " 0.57387097 0.56731183 0.52827957 0.56096774 0.56408602 0.57086022\n",
      " 0.55774194 0.54784946 0.57387097 0.56731183 0.51849462 0.53817204\n",
      " 0.50215054 0.49225806 0.52505376 0.53473118 0.52795699 0.49849462\n",
      " 0.55419355 0.56419355 0.56774194 0.57075269 0.5644086  0.5411828\n",
      " 0.55086022 0.54451613 0.55419355 0.56419355 0.56774194 0.57075269\n",
      " 0.5644086  0.5411828  0.55086022 0.54451613 0.50849462 0.53473118\n",
      " 0.51215054 0.48548387 0.51860215 0.50516129 0.51494624 0.50849462\n",
      " 0.54096774 0.56086022 0.56731183 0.56408602 0.58064516 0.5444086\n",
      " 0.58075269 0.55107527 0.54096774 0.56086022 0.56731183 0.56408602\n",
      " 0.58064516 0.5444086  0.58075269 0.55107527 0.50473118 0.5416129\n",
      " 0.48913978 0.50247312 0.5188172  0.5055914  0.51182796 0.49193548\n",
      " 0.52129032 0.55473118 0.54806452 0.56129032 0.56451613 0.53817204\n",
      " 0.54784946 0.55462366 0.52129032 0.55473118 0.54806452 0.56129032\n",
      " 0.56451613 0.53817204 0.54784946 0.55462366 0.53408602 0.54784946\n",
      " 0.50215054 0.52494624 0.53827957 0.52182796 0.53483871 0.52526882\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.91381572 0.9541734  0.96957418 0.97800178 0.98020227 0.98313537\n",
      " 0.98973282 0.99156701 0.91381572 0.9541734  0.96957418 0.97800178\n",
      " 0.98020227 0.98313537 0.98973282 0.99156701 0.75029493 0.7832862\n",
      " 0.79172053 0.80895012 0.80198637 0.811156   0.82326815 0.85445217\n",
      " 0.94866273 0.97727052 0.98790131 0.98753501 0.98900426 0.99120475\n",
      " 0.99376885 0.99450145 0.94866273 0.97727052 0.98790131 0.98753501\n",
      " 0.98900426 0.99120475 0.99376885 0.99450145 0.81447021 0.86760935\n",
      " 0.88302763 0.90502182 0.90759265 0.91309928 0.92924208 0.94794764\n",
      " 0.9655341  0.98753501 0.99192793 0.99303221 0.99376751 0.99486775\n",
      " 0.99670195 0.99670195 0.9655341  0.98753501 0.99192793 0.99303221\n",
      " 0.99376751 0.99486775 0.99670195 0.99670195 0.86325011 0.91089609\n",
      " 0.92777015 0.94976702 0.95233382 0.95563456 0.97140298 0.97836942\n",
      " 0.97909799 0.99156566 0.99412977 0.99486506 0.99523271 0.99559901\n",
      " 0.99596531 0.99669926 0.97909799 0.99156566 0.99412977 0.99486506\n",
      " 0.99523271 0.99559901 0.99596531 0.99669926 0.89696321 0.94426444\n",
      " 0.96150345 0.9757959  0.97616758 0.98313402 0.98679972 0.99046676\n",
      " 0.98680107 0.99266726 0.99523002 0.99596531 0.99523136 0.9963343\n",
      " 0.9974332  0.99633296 0.98680107 0.99266726 0.99523002 0.99596531\n",
      " 0.99523136 0.9963343  0.9974332  0.99633296 0.92410984 0.96443116\n",
      " 0.98129713 0.99009777 0.99266322 0.99413246 0.99633565 0.99743455\n",
      " 0.99010181 0.99303221 0.99412977 0.99559766 0.99559766 0.9974332\n",
      " 0.99743186 0.99706556 0.99010181 0.99303221 0.99412977 0.99559766\n",
      " 0.99559766 0.9974332  0.99743186 0.99706556 0.93766026 0.97872764\n",
      " 0.99046272 0.99413246 0.99486775 0.9967006  0.9981685  0.9992674\n",
      " 0.99449741 0.99449741 0.99523136 0.99633296 0.99633161 0.9974332\n",
      " 0.9977995  0.9974332  0.99449741 0.99449741 0.99523136 0.99633296\n",
      " 0.99633161 0.9974332  0.9977995  0.9974332  0.95342868 0.98496418\n",
      " 0.99486641 0.99669926 0.99889975 0.9992674  0.9996337  0.9996337\n",
      " 0.99523136 0.99523136 0.99669656 0.9967006  0.99706556 0.99780085\n",
      " 0.9977995  0.9974332  0.99523136 0.99523136 0.99669656 0.9967006\n",
      " 0.99706556 0.99780085 0.9977995  0.9974332  0.96553814 0.99009912\n",
      " 0.9970669  0.99853211 0.99926605 0.9996337  0.9996337  1.\n",
      " 0.99669926 0.99633026 0.99743051 0.99779816 0.99743186 0.99816715\n",
      " 0.99853345 0.9977995  0.99669926 0.99633026 0.99743051 0.99779816\n",
      " 0.99743186 0.99816715 0.99853345 0.9977995  0.97617297 0.99486237\n",
      " 0.99889975 0.9996337  0.9996337  1.         1.         1.\n",
      " 0.90282401 0.94719888 0.96076815 0.96847527 0.97360483 0.97800716\n",
      " 0.98240008 0.98863661 0.90282401 0.94719888 0.96076815 0.96847527\n",
      " 0.97360483 0.97800716 0.98240008 0.98863661 0.74112934 0.77303248\n",
      " 0.77852429 0.79464286 0.78732224 0.79905193 0.8063914  0.83978938\n",
      " 0.93949984 0.97249919 0.98313537 0.98643477 0.98643611 0.99120206\n",
      " 0.99230231 0.99560305 0.93949984 0.97249919 0.98313537 0.98643477\n",
      " 0.98643611 0.99120206 0.99230231 0.99560305 0.80421784 0.85478345\n",
      " 0.87129525 0.89219053 0.89183096 0.89880548 0.9233732  0.94207875\n",
      " 0.95857035 0.98496687 0.99193062 0.99303491 0.99266861 0.99413381\n",
      " 0.99523271 0.995968   0.95857035 0.98496687 0.99193062 0.99303491\n",
      " 0.99266861 0.99413381 0.99523271 0.995968   0.85737988 0.90868886\n",
      " 0.92300555 0.94389679 0.95379902 0.954906   0.96774133 0.97470238\n",
      " 0.9772611  0.98826357 0.99229557 0.99339717 0.99486506 0.99523406\n",
      " 0.99670195 0.99670195 0.9772611  0.98826357 0.99229557 0.99339717\n",
      " 0.99486506 0.99523406 0.99670195 0.99670195 0.8841427  0.94169899\n",
      " 0.958569   0.97359675 0.97433339 0.98130252 0.98497226 0.98826627\n",
      " 0.98240008 0.98936517 0.99156028 0.99412977 0.99339986 0.99486506\n",
      " 0.9974332  0.9967006  0.98240008 0.98936517 0.99156028 0.99412977\n",
      " 0.99339986 0.99486506 0.9974332  0.9967006  0.91311679 0.9615021\n",
      " 0.97690422 0.98790266 0.98826627 0.99157105 0.99376885 0.9963343\n",
      " 0.98313672 0.99083441 0.99413111 0.99376616 0.99413515 0.99486775\n",
      " 0.99706825 0.9967006  0.98313672 0.99083441 0.99413111 0.99376616\n",
      " 0.99413515 0.99486775 0.99706825 0.9967006  0.93620718 0.97323449\n",
      " 0.98717141 0.99450011 0.9937702  0.99670195 0.99743455 0.9989011\n",
      " 0.98789997 0.99229827 0.99376481 0.99266591 0.99376616 0.99340121\n",
      " 0.99706825 0.99596666 0.98789997 0.99229827 0.99376481 0.99266591\n",
      " 0.99376616 0.99340121 0.99706825 0.99596666 0.94207875 0.98020093\n",
      " 0.99046676 0.99596531 0.9974332  0.9985348  0.9996337  0.9996337\n",
      " 0.98863122 0.99302952 0.99376481 0.99413246 0.99376616 0.9952354\n",
      " 0.99743455 0.99633296 0.98863122 0.99302952 0.99376481 0.99413246\n",
      " 0.99376616 0.9952354  0.99743455 0.99633296 0.9534408  0.98643477\n",
      " 0.99450145 0.99816715 0.9989011  0.9996337  0.9996337  0.9996337\n",
      " 0.99193601 0.99413111 0.99523136 0.99560036 0.99486641 0.99596666\n",
      " 0.9981658  0.99780085 0.99193601 0.99413111 0.99523136 0.99560036\n",
      " 0.99486641 0.99596666 0.9981658  0.99780085 0.96553679 0.99230231\n",
      " 0.99633565 0.9992674  0.9992674  1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the greed search cv: 7.607 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the greed search cv: 35.071 minutes\n"
     ]
    }
   ],
   "source": [
    "london_vs_zwickau_modesl_experiment.run_greed_search_cv_for_n_best_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "727ffc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660752688172043\n",
      "DecisionTreeClassifier(max_depth=6)\n",
      "0.5838709677419355\n",
      "RandomForestClassifier(max_depth=11, n_estimators=250, random_state=0)\n",
      "0.6770967741935484\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.4, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=5,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "for i in london_vs_zwickau_modesl_experiment.greed_search_cv_results:\n",
    "    print(i.best_score_)\n",
    "    print(i.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b3dd3016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.4, 'max_depth': 3, 'min_child_weight': 5}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_vs_zwickau_modesl_experiment.greed_search_cv_results[2].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0c774",
   "metadata": {},
   "source": [
    "## burchard VS zwickau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99022598",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_london_VS_zwickau_models_experiment = thesisModelFeatures.ModelsExperiment(burchard_by_london_VS_zwickau_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0059af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: DecisionTreeClassifier\n",
      "Elapsed time to compute the cross validate: 0.157 minutes\n",
      "running: GaussianProcessClassifier\n",
      "Elapsed time to compute the cross validate: 0.885 minutes\n",
      "running: RandomForestClassifier\n",
      "Elapsed time to compute the cross validate: 0.119 minutes\n",
      "running: GaussianNB\n",
      "Elapsed time to compute the cross validate: 0.071 minutes\n",
      "running: KNeighborsClassifier\n",
      "Elapsed time to compute the cross validate: 0.076 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the cross validate: 0.658 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the cross validate: 2.041 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_london_VS_zwickau_models_experiment.run_cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f8ad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.833020</td>\n",
       "      <td>0.808810</td>\n",
       "      <td>0.814038</td>\n",
       "      <td>0.825546</td>\n",
       "      <td>0.821450</td>\n",
       "      <td>0.825546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.783148</td>\n",
       "      <td>0.772262</td>\n",
       "      <td>0.773547</td>\n",
       "      <td>0.782521</td>\n",
       "      <td>0.780704</td>\n",
       "      <td>0.782521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.740203</td>\n",
       "      <td>0.702976</td>\n",
       "      <td>0.702336</td>\n",
       "      <td>0.731092</td>\n",
       "      <td>0.717339</td>\n",
       "      <td>0.731092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.693169</td>\n",
       "      <td>0.688214</td>\n",
       "      <td>0.687327</td>\n",
       "      <td>0.699496</td>\n",
       "      <td>0.696937</td>\n",
       "      <td>0.699496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.792409</td>\n",
       "      <td>0.634167</td>\n",
       "      <td>0.608110</td>\n",
       "      <td>0.690756</td>\n",
       "      <td>0.637669</td>\n",
       "      <td>0.690756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.642882</td>\n",
       "      <td>0.550833</td>\n",
       "      <td>0.490248</td>\n",
       "      <td>0.616134</td>\n",
       "      <td>0.532242</td>\n",
       "      <td>0.616134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.602404</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.457501</td>\n",
       "      <td>0.584454</td>\n",
       "      <td>0.499864</td>\n",
       "      <td>0.584454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "XGBClassifier                     0.833020      0.808810  0.814038  0.825546   \n",
       "AdaBoostClassifier                0.783148      0.772262  0.773547  0.782521   \n",
       "RandomForestClassifier            0.740203      0.702976  0.702336  0.731092   \n",
       "DecisionTreeClassifier            0.693169      0.688214  0.687327  0.699496   \n",
       "GaussianProcessClassifier         0.792409      0.634167  0.608110  0.690756   \n",
       "KNeighborsClassifier              0.642882      0.550833  0.490248  0.616134   \n",
       "GaussianNB                        0.602404      0.520476  0.457501  0.584454   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "XGBClassifier                 0.821450  0.825546  \n",
       "AdaBoostClassifier            0.780704  0.782521  \n",
       "RandomForestClassifier        0.717339  0.731092  \n",
       "DecisionTreeClassifier        0.696937  0.699496  \n",
       "GaussianProcessClassifier     0.637669  0.690756  \n",
       "KNeighborsClassifier          0.532242  0.616134  \n",
       "GaussianNB                    0.499864  0.584454  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_by_london_VS_zwickau_models_experiment.show_cross_validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "429ec9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.71092437 0.71663866 0.72243697 0.72529412 0.72243697 0.7310084\n",
      " 0.72815126 0.73386555 0.71092437 0.71663866 0.72243697 0.72529412\n",
      " 0.72243697 0.7310084  0.72815126 0.73386555 0.58747899 0.58168067\n",
      " 0.58168067 0.58168067 0.58168067 0.58168067 0.58168067 0.58168067\n",
      " 0.69092437 0.73092437 0.72815126 0.72815126 0.71957983 0.72529412\n",
      " 0.73386555 0.73386555 0.69092437 0.73092437 0.72815126 0.72815126\n",
      " 0.71957983 0.72529412 0.73386555 0.73386555 0.60764706 0.59033613\n",
      " 0.58168067 0.58453782 0.58168067 0.58168067 0.58168067 0.58168067\n",
      " 0.6994958  0.72529412 0.70529412 0.7310084  0.7310084  0.73672269\n",
      " 0.73957983 0.73672269 0.6994958  0.72529412 0.70529412 0.7310084\n",
      " 0.7310084  0.73672269 0.73957983 0.73672269 0.60747899 0.60168067\n",
      " 0.59882353 0.59596639 0.59882353 0.59310924 0.58739496 0.58739496\n",
      " 0.68235294 0.71672269 0.71092437 0.7194958  0.72521008 0.72815126\n",
      " 0.72815126 0.72815126 0.68235294 0.71672269 0.71092437 0.7194958\n",
      " 0.72521008 0.72815126 0.72815126 0.72815126 0.61058824 0.60193277\n",
      " 0.60176471 0.5902521  0.59596639 0.59882353 0.60168067 0.59596639\n",
      " 0.70252101 0.69378151 0.71663866 0.72529412 0.72815126 0.73957983\n",
      " 0.74243697 0.7510084  0.70252101 0.69378151 0.71663866 0.72529412\n",
      " 0.72815126 0.73957983 0.74243697 0.7510084  0.61327731 0.62176471\n",
      " 0.61310924 0.60168067 0.61310924 0.61882353 0.61596639 0.61310924\n",
      " 0.67655462 0.70806723 0.70521008 0.7110084  0.73394958 0.74243697\n",
      " 0.75109244 0.74823529 0.67655462 0.70806723 0.70521008 0.7110084\n",
      " 0.73394958 0.74243697 0.75109244 0.74823529 0.61638655 0.62184874\n",
      " 0.64176471 0.63033613 0.62747899 0.62739496 0.61882353 0.61596639\n",
      " 0.68235294 0.69663866 0.70521008 0.72521008 0.73092437 0.74529412\n",
      " 0.7510084  0.74537815 0.68235294 0.69663866 0.70521008 0.72521008\n",
      " 0.73092437 0.74529412 0.7510084  0.74537815 0.61655462 0.62487395\n",
      " 0.64495798 0.6305042  0.64487395 0.64201681 0.64495798 0.6392437\n",
      " 0.7110084  0.71378151 0.7110084  0.71386555 0.72823529 0.73672269\n",
      " 0.73680672 0.73394958 0.7110084  0.71378151 0.7110084  0.71386555\n",
      " 0.72823529 0.73672269 0.73680672 0.73394958 0.64798319 0.63647059\n",
      " 0.65941176 0.6305042  0.63344538 0.65361345 0.66218487 0.64789916\n",
      " 0.67369748 0.71941176 0.72529412 0.71957983 0.71672269 0.7310084\n",
      " 0.73957983 0.73672269 0.67369748 0.71941176 0.72529412 0.71957983\n",
      " 0.71672269 0.7310084  0.73957983 0.73672269 0.63630252 0.63647059\n",
      " 0.65084034 0.64218487 0.64789916 0.64798319 0.65932773 0.6507563\n",
      " 0.69378151 0.7194958  0.7194958  0.72235294 0.7310084  0.74529412\n",
      " 0.7394958  0.73378151 0.69378151 0.7194958  0.7194958  0.72235294\n",
      " 0.7310084  0.74529412 0.7394958  0.73378151 0.57882353 0.58168067\n",
      " 0.58168067 0.58168067 0.58168067 0.58168067 0.58168067 0.58168067\n",
      " 0.70521008 0.72243697 0.7310084  0.73957983 0.73957983 0.73672269\n",
      " 0.74529412 0.74529412 0.70521008 0.72243697 0.7310084  0.73957983\n",
      " 0.73957983 0.73672269 0.74529412 0.74529412 0.57596639 0.58168067\n",
      " 0.5902521  0.58739496 0.58453782 0.58453782 0.58168067 0.58168067\n",
      " 0.7110084  0.71092437 0.72235294 0.73092437 0.73672269 0.73386555\n",
      " 0.74243697 0.74235294 0.7110084  0.71092437 0.72235294 0.73092437\n",
      " 0.73672269 0.73386555 0.74243697 0.74235294 0.57890756 0.5902521\n",
      " 0.59882353 0.59310924 0.59882353 0.59310924 0.5902521  0.5902521\n",
      " 0.71663866 0.73386555 0.7510084  0.7510084  0.74815126 0.74815126\n",
      " 0.74815126 0.7510084  0.71663866 0.73386555 0.7510084  0.7510084\n",
      " 0.74815126 0.74815126 0.74815126 0.7510084  0.60193277 0.60747899\n",
      " 0.60739496 0.60453782 0.60168067 0.60168067 0.59882353 0.59596639\n",
      " 0.68226891 0.6994958  0.72521008 0.73378151 0.73378151 0.73957983\n",
      " 0.73957983 0.74529412 0.68226891 0.6994958  0.72521008 0.73378151\n",
      " 0.73378151 0.73957983 0.73957983 0.74529412 0.59327731 0.61033613\n",
      " 0.61310924 0.60176471 0.60739496 0.6102521  0.6102521  0.6102521\n",
      " 0.71092437 0.71386555 0.71386555 0.72243697 0.72243697 0.73672269\n",
      " 0.7310084  0.73957983 0.71092437 0.71386555 0.71386555 0.72243697\n",
      " 0.72243697 0.73672269 0.7310084  0.73957983 0.61647059 0.64201681\n",
      " 0.6389916  0.62453782 0.63890756 0.6302521  0.62747899 0.61310924\n",
      " 0.71386555 0.71957983 0.72243697 0.72243697 0.7310084  0.72815126\n",
      " 0.73957983 0.74529412 0.71386555 0.71957983 0.72243697 0.72243697\n",
      " 0.7310084  0.72815126 0.73957983 0.74529412 0.61647059 0.65915966\n",
      " 0.64764706 0.63319328 0.64176471 0.64168067 0.6389916  0.63907563\n",
      " 0.72235294 0.71663866 0.73663866 0.74235294 0.74235294 0.73663866\n",
      " 0.74235294 0.73663866 0.72235294 0.71663866 0.73663866 0.74235294\n",
      " 0.74235294 0.73663866 0.74235294 0.73663866 0.63647059 0.65647059\n",
      " 0.64495798 0.65058824 0.65638655 0.65058824 0.64773109 0.64495798\n",
      " 0.73378151 0.74235294 0.75092437 0.74521008 0.74529412 0.73663866\n",
      " 0.74243697 0.73672269 0.73378151 0.74235294 0.75092437 0.74521008\n",
      " 0.74529412 0.73663866 0.74243697 0.73672269 0.61647059 0.65941176\n",
      " 0.66226891 0.65932773 0.65647059 0.66218487 0.64781513 0.65361345\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.90385603 0.91913558 0.91754221 0.91945304 0.92327267 0.9239086\n",
      " 0.92454858 0.92550298 0.90385603 0.91913558 0.91754221 0.91945304\n",
      " 0.92327267 0.9239086  0.92454858 0.92550298 0.66475887 0.63643009\n",
      " 0.62369528 0.61287029 0.61541705 0.6115964  0.6071378  0.60108584\n",
      " 0.95733798 0.96848246 0.97230614 0.97421595 0.97580528 0.97453341\n",
      " 0.97453139 0.97262259 0.95733798 0.96848246 0.97230614 0.97421595\n",
      " 0.97580528 0.97453341 0.97453139 0.97262259 0.74721666 0.72621474\n",
      " 0.71634617 0.7013851  0.70329795 0.70265797 0.70138611 0.68642301\n",
      " 0.98248913 0.99140228 0.99426853 0.99394904 0.9968163  0.99617834\n",
      " 0.99490648 0.99617935 0.98248913 0.99140228 0.99426853 0.99394904\n",
      " 0.9968163  0.99617834 0.99490648 0.99617935 0.81821858 0.81089981\n",
      " 0.80835608 0.79816904 0.80326256 0.80070974 0.79689314 0.79243858\n",
      " 0.99140734 0.99649884 0.99968153 1.         0.99936306 1.\n",
      " 1.         1.         0.99140734 0.99649884 0.99968153 1.\n",
      " 0.99936306 1.         1.         1.         0.87871499 0.88762107\n",
      " 0.89080578 0.87680315 0.8809362  0.88380042 0.88316449 0.88093823\n",
      " 0.99586088 0.99936306 0.99936306 1.         1.         1.\n",
      " 1.         1.         0.99586088 0.99936306 0.99936306 1.\n",
      " 1.         1.         1.         1.         0.92073097 0.93027702\n",
      " 0.94205743 0.93983621 0.94206653 0.94747245 0.94842989 0.94842685\n",
      " 0.99840865 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99840865 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95129107 0.96306845\n",
      " 0.97167122 0.97262663 0.97549489 0.97835608 0.98058235 0.98312911\n",
      " 0.99872713 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99872713 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96689212 0.98026287\n",
      " 0.98949752 0.99045496 0.99363563 0.99458801 0.99522495 0.99522596\n",
      " 0.99904459 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99904459 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98439996 0.99267718\n",
      " 0.99840764 0.99904459 0.99904459 0.99968153 0.9990456  0.9990456\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98790011 0.99681529\n",
      " 0.99936407 0.99936306 0.99936306 1.         1.         0.99936306\n",
      " 0.90067334 0.90926297 0.90990395 0.90830957 0.91085836 0.91627338\n",
      " 0.91245273 0.91468102 0.90067334 0.90926297 0.90990395 0.90830957\n",
      " 0.91085836 0.91627338 0.91245273 0.91468102 0.64215347 0.61955616\n",
      " 0.61255181 0.60299767 0.60268021 0.60299869 0.59694672 0.59280861\n",
      " 0.94524618 0.95638358 0.95702153 0.96020827 0.96211505 0.96434536\n",
      " 0.962752   0.96498029 0.94524618 0.95638358 0.95702153 0.96020827\n",
      " 0.96211505 0.96434536 0.962752   0.96498029 0.70901527 0.70011323\n",
      " 0.69661308 0.67846628 0.68356081 0.67878273 0.67400768 0.66222728\n",
      " 0.97771307 0.98535335 0.98885451 0.99172076 0.99108584 0.99013042\n",
      " 0.99204024 0.99108482 0.97771307 0.98535335 0.98885451 0.99172076\n",
      " 0.99108584 0.99013042 0.99204024 0.99108482 0.78893337 0.78575675\n",
      " 0.77971489 0.7653857  0.77238297 0.77174906 0.77429785 0.7637893\n",
      " 0.9894955  0.99522596 0.99809018 0.99840865 0.99936306 0.99936306\n",
      " 0.99936306 0.99872713 0.9894955  0.99522596 0.99809018 0.99840865\n",
      " 0.99936306 0.99936306 0.99936306 0.99872713 0.85005358 0.85482459\n",
      " 0.85960368 0.84718835 0.85292084 0.8545142  0.85419472 0.84815186\n",
      " 0.99522495 0.9990456  0.99936306 0.99968153 0.99968153 1.\n",
      " 1.         1.         0.99522495 0.9990456  0.99936306 0.99968153\n",
      " 0.99968153 1.         1.         1.         0.89017086 0.9041745\n",
      " 0.90226671 0.90290264 0.90449095 0.90831665 0.91086442 0.91118188\n",
      " 0.99808917 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99808917 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.93346173 0.94397129\n",
      " 0.94715499 0.94810939 0.95320291 0.95671216 0.95989384 0.95766758\n",
      " 0.99904459 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99904459 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95702153 0.96530179\n",
      " 0.97358002 0.97294207 0.97995046 0.98122333 0.984404   0.98599434\n",
      " 0.99968153 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99968153 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97039632 0.98122232\n",
      " 0.99013345 0.99236073 0.99427358 0.99586392 0.99650187 0.99618239\n",
      " 0.99936306 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99936306 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98153776 0.99013345\n",
      " 0.99554443 0.99745425 0.99936407 0.99968153 0.99904661 0.99936407\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the greed search cv: 13.180 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the greed search cv: 58.082 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the greed search cv: 59.349 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_london_VS_zwickau_models_experiment.run_greed_search_cv_for_n_best_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "544deca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7510924369747899\n",
      "RandomForestClassifier(max_depth=9, n_estimators=400, random_state=0)\n",
      "0.856890756302521\n",
      "AdaBoostClassifier(learning_rate=1, n_estimators=2000)\n",
      "0.8399159663865545\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.4, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=5,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "for i in burchard_by_london_VS_zwickau_models_experiment.greed_search_cv_results:\n",
    "    print(i.best_score_)\n",
    "    print(i.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7cc93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_zwickau_VS_zwickau_models_experiment = thesisModelFeatures.ModelsExperiment(burchard_by_zwickau_VS_zwickau_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30f37831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: DecisionTreeClassifier\n",
      "Elapsed time to compute the cross validate: 0.138 minutes\n",
      "running: GaussianProcessClassifier\n",
      "Elapsed time to compute the cross validate: 0.872 minutes\n",
      "running: RandomForestClassifier\n",
      "Elapsed time to compute the cross validate: 0.118 minutes\n",
      "running: GaussianNB\n",
      "Elapsed time to compute the cross validate: 0.068 minutes\n",
      "running: KNeighborsClassifier\n",
      "Elapsed time to compute the cross validate: 0.070 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the cross validate: 0.652 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the cross validate: 1.918 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_zwickau_VS_zwickau_models_experiment.run_cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cd6071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.830416</td>\n",
       "      <td>0.813095</td>\n",
       "      <td>0.817459</td>\n",
       "      <td>0.825546</td>\n",
       "      <td>0.823580</td>\n",
       "      <td>0.825546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.779524</td>\n",
       "      <td>0.782360</td>\n",
       "      <td>0.791008</td>\n",
       "      <td>0.789328</td>\n",
       "      <td>0.791008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.726609</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0.717216</td>\n",
       "      <td>0.724958</td>\n",
       "      <td>0.723798</td>\n",
       "      <td>0.724958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.740095</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.687324</td>\n",
       "      <td>0.716639</td>\n",
       "      <td>0.702652</td>\n",
       "      <td>0.716639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.790594</td>\n",
       "      <td>0.624881</td>\n",
       "      <td>0.595643</td>\n",
       "      <td>0.682185</td>\n",
       "      <td>0.626282</td>\n",
       "      <td>0.682185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.648487</td>\n",
       "      <td>0.550714</td>\n",
       "      <td>0.491053</td>\n",
       "      <td>0.616134</td>\n",
       "      <td>0.532939</td>\n",
       "      <td>0.616134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.642063</td>\n",
       "      <td>0.532381</td>\n",
       "      <td>0.474211</td>\n",
       "      <td>0.595882</td>\n",
       "      <td>0.514955</td>\n",
       "      <td>0.595882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "XGBClassifier                     0.830416      0.813095  0.817459  0.825546   \n",
       "AdaBoostClassifier                0.793551      0.779524  0.782360  0.791008   \n",
       "DecisionTreeClassifier            0.726609      0.719167  0.717216  0.724958   \n",
       "RandomForestClassifier            0.740095      0.685714  0.687324  0.716639   \n",
       "GaussianProcessClassifier         0.790594      0.624881  0.595643  0.682185   \n",
       "KNeighborsClassifier              0.648487      0.550714  0.491053  0.616134   \n",
       "GaussianNB                        0.642063      0.532381  0.474211  0.595882   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "XGBClassifier                 0.823580  0.825546  \n",
       "AdaBoostClassifier            0.789328  0.791008  \n",
       "DecisionTreeClassifier        0.723798  0.724958  \n",
       "RandomForestClassifier        0.702652  0.716639  \n",
       "GaussianProcessClassifier     0.626282  0.682185  \n",
       "KNeighborsClassifier          0.532939  0.616134  \n",
       "GaussianNB                    0.514955  0.595882  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_by_zwickau_VS_zwickau_models_experiment.show_cross_validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78876aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: DecisionTreeClassifier\n",
      "Elapsed time to compute the greed search cv: 0.921 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the greed search cv: 53.156 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the greed search cv: 55.258 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_zwickau_VS_zwickau_models_experiment.run_greed_search_cv_for_n_best_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "309dc642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7652941176470588\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=90)\n",
      "0.8253781512605041\n",
      "AdaBoostClassifier(learning_rate=1, n_estimators=500)\n",
      "0.8427731092436973\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=3,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "for i in burchard_by_zwickau_VS_zwickau_models_experiment.greed_search_cv_results:\n",
    "    print(i.best_score_)\n",
    "    print(i.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a69a79f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.0, 'max_depth': 5, 'min_child_weight': 3}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_by_zwickau_VS_zwickau_models_experiment.greed_search_cv_results[2].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15697b5",
   "metadata": {},
   "source": [
    "## burchard vs london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48526d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_london_VS_london_models_experiment = thesisModelFeatures.ModelsExperiment(burchard_by_london_VS_london_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c47969e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: DecisionTreeClassifier\n",
      "Elapsed time to compute the cross validate: 0.156 minutes\n",
      "running: GaussianProcessClassifier\n",
      "Elapsed time to compute the cross validate: 0.967 minutes\n",
      "running: RandomForestClassifier\n",
      "Elapsed time to compute the cross validate: 0.121 minutes\n",
      "running: GaussianNB\n",
      "Elapsed time to compute the cross validate: 0.073 minutes\n",
      "running: KNeighborsClassifier\n",
      "Elapsed time to compute the cross validate: 0.077 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the cross validate: 0.709 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the cross validate: 2.071 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_london_VS_london_models_experiment.run_cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3822367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.757065</td>\n",
       "      <td>0.729881</td>\n",
       "      <td>0.728194</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.737307</td>\n",
       "      <td>0.747222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.769375</td>\n",
       "      <td>0.703661</td>\n",
       "      <td>0.696442</td>\n",
       "      <td>0.730556</td>\n",
       "      <td>0.709580</td>\n",
       "      <td>0.730556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.690439</td>\n",
       "      <td>0.682649</td>\n",
       "      <td>0.681939</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.688885</td>\n",
       "      <td>0.691667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.799217</td>\n",
       "      <td>0.627946</td>\n",
       "      <td>0.587528</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.612606</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.623941</td>\n",
       "      <td>0.622113</td>\n",
       "      <td>0.620596</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.628084</td>\n",
       "      <td>0.630556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.608815</td>\n",
       "      <td>0.568393</td>\n",
       "      <td>0.545137</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.565224</td>\n",
       "      <td>0.602778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.589018</td>\n",
       "      <td>0.556905</td>\n",
       "      <td>0.538614</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.554849</td>\n",
       "      <td>0.580556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "XGBClassifier                     0.757065      0.729881  0.728194  0.747222   \n",
       "RandomForestClassifier            0.769375      0.703661  0.696442  0.730556   \n",
       "AdaBoostClassifier                0.690439      0.682649  0.681939  0.691667   \n",
       "GaussianProcessClassifier         0.799217      0.627946  0.587528  0.675000   \n",
       "DecisionTreeClassifier            0.623941      0.622113  0.620596  0.630556   \n",
       "GaussianNB                        0.608815      0.568393  0.545137  0.602778   \n",
       "KNeighborsClassifier              0.589018      0.556905  0.538614  0.580556   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "XGBClassifier                 0.737307  0.747222  \n",
       "RandomForestClassifier        0.709580  0.730556  \n",
       "AdaBoostClassifier            0.688885  0.691667  \n",
       "GaussianProcessClassifier     0.612606  0.675000  \n",
       "DecisionTreeClassifier        0.628084  0.630556  \n",
       "GaussianNB                    0.565224  0.602778  \n",
       "KNeighborsClassifier          0.554849  0.580556  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_by_london_VS_london_models_experiment.show_cross_validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ac4667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.7        0.73333333 0.75       0.75833333 0.75555556 0.74722222\n",
      " 0.75277778 0.74722222 0.7        0.73333333 0.75       0.75833333\n",
      " 0.75555556 0.74722222 0.75277778 0.74722222 0.56666667 0.56666667\n",
      " 0.56388889 0.56388889 0.56388889 0.56388889 0.56388889 0.56388889\n",
      " 0.72777778 0.75277778 0.73611111 0.75555556 0.75833333 0.76111111\n",
      " 0.76111111 0.75833333 0.72777778 0.75277778 0.73611111 0.75555556\n",
      " 0.75833333 0.76111111 0.76111111 0.75833333 0.57777778 0.57777778\n",
      " 0.57222222 0.56944444 0.56666667 0.56388889 0.56388889 0.56388889\n",
      " 0.73333333 0.76388889 0.75       0.76388889 0.76944444 0.775\n",
      " 0.76944444 0.75833333 0.73333333 0.76388889 0.75       0.76388889\n",
      " 0.76944444 0.775      0.76944444 0.75833333 0.57777778 0.58611111\n",
      " 0.575      0.575      0.56944444 0.57222222 0.56944444 0.56388889\n",
      " 0.70555556 0.73333333 0.74444444 0.74722222 0.74166667 0.74722222\n",
      " 0.75555556 0.75       0.70555556 0.73333333 0.74444444 0.74722222\n",
      " 0.74166667 0.74722222 0.75555556 0.75       0.58333333 0.59166667\n",
      " 0.59166667 0.58055556 0.575      0.56944444 0.57222222 0.56666667\n",
      " 0.73888889 0.74722222 0.76388889 0.76944444 0.76388889 0.76388889\n",
      " 0.76388889 0.75555556 0.73888889 0.74722222 0.76388889 0.76944444\n",
      " 0.76388889 0.76388889 0.76388889 0.75555556 0.58611111 0.59444444\n",
      " 0.59444444 0.59166667 0.58611111 0.58333333 0.58055556 0.575\n",
      " 0.73333333 0.74444444 0.75555556 0.75555556 0.75833333 0.75\n",
      " 0.76111111 0.74722222 0.73333333 0.74444444 0.75555556 0.75555556\n",
      " 0.75833333 0.75       0.76111111 0.74722222 0.60833333 0.63055556\n",
      " 0.60833333 0.61388889 0.6        0.59444444 0.59166667 0.58888889\n",
      " 0.74166667 0.74722222 0.76111111 0.75833333 0.76666667 0.77222222\n",
      " 0.76388889 0.76944444 0.74166667 0.74722222 0.76111111 0.75833333\n",
      " 0.76666667 0.77222222 0.76388889 0.76944444 0.625      0.625\n",
      " 0.61666667 0.63333333 0.62777778 0.62777778 0.62777778 0.61111111\n",
      " 0.73611111 0.76388889 0.76944444 0.76388889 0.76388889 0.77777778\n",
      " 0.76388889 0.77222222 0.73611111 0.76388889 0.76944444 0.76388889\n",
      " 0.76388889 0.77777778 0.76388889 0.77222222 0.59444444 0.625\n",
      " 0.62222222 0.61944444 0.63055556 0.63333333 0.63333333 0.625\n",
      " 0.73055556 0.75       0.75       0.75       0.76944444 0.76111111\n",
      " 0.76388889 0.76944444 0.73055556 0.75       0.75       0.75\n",
      " 0.76944444 0.76111111 0.76388889 0.76944444 0.62222222 0.65\n",
      " 0.625      0.61944444 0.63333333 0.63611111 0.63055556 0.625\n",
      " 0.68888889 0.71944444 0.73888889 0.73333333 0.73055556 0.72777778\n",
      " 0.73611111 0.73333333 0.68888889 0.71944444 0.73888889 0.73333333\n",
      " 0.73055556 0.72777778 0.73611111 0.73333333 0.56944444 0.56388889\n",
      " 0.56666667 0.56388889 0.56388889 0.56388889 0.56388889 0.56388889\n",
      " 0.70555556 0.73055556 0.74444444 0.76111111 0.76111111 0.76111111\n",
      " 0.76944444 0.76388889 0.70555556 0.73055556 0.74444444 0.76111111\n",
      " 0.76111111 0.76111111 0.76944444 0.76388889 0.58888889 0.575\n",
      " 0.56666667 0.56388889 0.56666667 0.56388889 0.56388889 0.56388889\n",
      " 0.68888889 0.72777778 0.76111111 0.75277778 0.75       0.75555556\n",
      " 0.75277778 0.74722222 0.68888889 0.72777778 0.76111111 0.75277778\n",
      " 0.75       0.75555556 0.75277778 0.74722222 0.58888889 0.58055556\n",
      " 0.57777778 0.57777778 0.57222222 0.56944444 0.56666667 0.56666667\n",
      " 0.70555556 0.74444444 0.73888889 0.74722222 0.74166667 0.75555556\n",
      " 0.75277778 0.76111111 0.70555556 0.74444444 0.73888889 0.74722222\n",
      " 0.74166667 0.75555556 0.75277778 0.76111111 0.59722222 0.59722222\n",
      " 0.58611111 0.58055556 0.575      0.56944444 0.57222222 0.56944444\n",
      " 0.73333333 0.76111111 0.75277778 0.76944444 0.76111111 0.75555556\n",
      " 0.76111111 0.75833333 0.73333333 0.76111111 0.75277778 0.76944444\n",
      " 0.76111111 0.75555556 0.76111111 0.75833333 0.61666667 0.61111111\n",
      " 0.59166667 0.58888889 0.58611111 0.57777778 0.57777778 0.56944444\n",
      " 0.7        0.75       0.76111111 0.76666667 0.76111111 0.75833333\n",
      " 0.77222222 0.76111111 0.7        0.75       0.76111111 0.76666667\n",
      " 0.76111111 0.75833333 0.77222222 0.76111111 0.63611111 0.62777778\n",
      " 0.625      0.60833333 0.6        0.60277778 0.59444444 0.58888889\n",
      " 0.725      0.75277778 0.74444444 0.75555556 0.75277778 0.75833333\n",
      " 0.76388889 0.76388889 0.725      0.75277778 0.74444444 0.75555556\n",
      " 0.75277778 0.75833333 0.76388889 0.76388889 0.61944444 0.63055556\n",
      " 0.61111111 0.61944444 0.61388889 0.60833333 0.62222222 0.60555556\n",
      " 0.73888889 0.76388889 0.76111111 0.75833333 0.75555556 0.75\n",
      " 0.76666667 0.76666667 0.73888889 0.76388889 0.76111111 0.75833333\n",
      " 0.75555556 0.75       0.76666667 0.76666667 0.61666667 0.63611111\n",
      " 0.625      0.63888889 0.625      0.62222222 0.625      0.625\n",
      " 0.7        0.73611111 0.75277778 0.75277778 0.75       0.74722222\n",
      " 0.76111111 0.75555556 0.7        0.73611111 0.75277778 0.75277778\n",
      " 0.75       0.74722222 0.76111111 0.75555556 0.63611111 0.63888889\n",
      " 0.63888889 0.64722222 0.65       0.63888889 0.63055556 0.63611111\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.92901235 0.9404321  0.94722222 0.94783951 0.94907407 0.95185185\n",
      " 0.95246914 0.94938272 0.92901235 0.9404321  0.94722222 0.94783951\n",
      " 0.94907407 0.95185185 0.95246914 0.94938272 0.67037037 0.67191358\n",
      " 0.64660494 0.63148148 0.62469136 0.62067901 0.60740741 0.60524691\n",
      " 0.96296296 0.975      0.98148148 0.98209877 0.9808642  0.98395062\n",
      " 0.98518519 0.98549383 0.96296296 0.975      0.98148148 0.98209877\n",
      " 0.9808642  0.98395062 0.98518519 0.98549383 0.75864198 0.75802469\n",
      " 0.75308642 0.74228395 0.73487654 0.72561728 0.72191358 0.71666667\n",
      " 0.98487654 0.9941358  0.99598765 0.99660494 0.99691358 0.99845679\n",
      " 0.99876543 0.99938272 0.98487654 0.9941358  0.99598765 0.99660494\n",
      " 0.99691358 0.99845679 0.99876543 0.99938272 0.83395062 0.85555556\n",
      " 0.85740741 0.85061728 0.85246914 0.84783951 0.85277778 0.84506173\n",
      " 0.99351852 0.99938272 1.         1.         1.         1.\n",
      " 1.         1.         0.99351852 0.99938272 1.         1.\n",
      " 1.         1.         1.         1.         0.88240741 0.90462963\n",
      " 0.91759259 0.92314815 0.925      0.92746914 0.93333333 0.93302469\n",
      " 0.99814815 0.99969136 0.99969136 1.         1.         1.\n",
      " 1.         1.         0.99814815 0.99969136 0.99969136 1.\n",
      " 1.         1.         1.         1.         0.92901235 0.95493827\n",
      " 0.96481481 0.97006173 0.97222222 0.96882716 0.975      0.97407407\n",
      " 0.99907407 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99907407 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95308642 0.97191358\n",
      " 0.9808642  0.98302469 0.98487654 0.98549383 0.98888889 0.98919753\n",
      " 0.99938272 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99938272 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.9691358  0.98611111\n",
      " 0.99074074 0.99320988 0.99351852 0.9941358  0.99444444 0.99660494\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97654321 0.99259259\n",
      " 0.9941358  0.99722222 0.99722222 0.99753086 0.99753086 0.99845679\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98888889 0.99475309\n",
      " 0.99753086 0.99814815 0.99845679 0.99876543 0.99938272 0.99969136\n",
      " 0.91944444 0.92685185 0.93055556 0.92839506 0.93024691 0.93209877\n",
      " 0.93271605 0.93179012 0.91944444 0.92685185 0.93055556 0.92839506\n",
      " 0.93024691 0.93209877 0.93271605 0.93179012 0.64722222 0.65216049\n",
      " 0.62716049 0.61388889 0.60617284 0.59938272 0.59290123 0.59259259\n",
      " 0.94969136 0.96604938 0.97345679 0.97407407 0.97592593 0.97654321\n",
      " 0.97932099 0.97716049 0.94969136 0.96604938 0.97345679 0.97407407\n",
      " 0.97592593 0.97654321 0.97932099 0.97716049 0.73148148 0.74259259\n",
      " 0.72469136 0.7095679  0.7        0.69506173 0.68518519 0.68055556\n",
      " 0.97685185 0.98641975 0.99197531 0.99104938 0.99197531 0.99351852\n",
      " 0.99598765 0.99537037 0.97685185 0.98641975 0.99197531 0.99104938\n",
      " 0.99197531 0.99351852 0.99598765 0.99537037 0.80648148 0.82222222\n",
      " 0.82376543 0.82376543 0.81759259 0.81512346 0.81790123 0.80617284\n",
      " 0.98919753 0.9962963  0.99753086 0.99814815 0.99907407 0.99969136\n",
      " 1.         1.         0.98919753 0.9962963  0.99753086 0.99814815\n",
      " 0.99907407 0.99969136 1.         1.         0.86728395 0.87901235\n",
      " 0.88981481 0.89783951 0.90339506 0.89814815 0.90802469 0.90308642\n",
      " 0.99598765 0.99969136 1.         1.         1.         1.\n",
      " 1.         1.         0.99598765 0.99969136 1.         1.\n",
      " 1.         1.         1.         1.         0.91080247 0.93240741\n",
      " 0.94567901 0.95092593 0.95833333 0.95709877 0.96512346 0.96419753\n",
      " 0.99907407 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99907407 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.94197531 0.95864198\n",
      " 0.97222222 0.97777778 0.98209877 0.9808642  0.98364198 0.9845679\n",
      " 0.99907407 0.99969136 1.         1.         1.         1.\n",
      " 1.         1.         0.99907407 0.99969136 1.         1.\n",
      " 1.         1.         1.         1.         0.96481481 0.97716049\n",
      " 0.98487654 0.98734568 0.98950617 0.98981481 0.99290123 0.99475309\n",
      " 0.99969136 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969136 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97345679 0.98919753\n",
      " 0.99197531 0.99382716 0.9941358  0.99475309 0.99537037 0.99660494\n",
      " 0.99969136 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969136 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98333333 0.99290123\n",
      " 0.99506173 0.99691358 0.99845679 0.99814815 0.99907407 0.99907407\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the greed search cv: 12.648 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the greed search cv: 57.761 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the greed search cv: 62.064 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_london_VS_london_models_experiment.run_greed_search_cv_for_n_best_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a681db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n",
      "RandomForestClassifier(max_depth=11, n_estimators=300, random_state=0)\n",
      "0.75\n",
      "AdaBoostClassifier(learning_rate=0.5, n_estimators=300)\n",
      "0.763888888888889\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.1, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=3,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "for i in burchard_by_london_VS_london_models_experiment.greed_search_cv_results:\n",
    "    print(i.best_score_)\n",
    "    print(i.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddb94166",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_zwickau_VS_london_models_experiment = thesisModelFeatures.ModelsExperiment(burchard_by_zwickau_VS_london_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "916c78a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: DecisionTreeClassifier\n",
      "Elapsed time to compute the cross validate: 0.139 minutes\n",
      "running: GaussianProcessClassifier\n",
      "Elapsed time to compute the cross validate: 0.968 minutes\n",
      "running: RandomForestClassifier\n",
      "Elapsed time to compute the cross validate: 0.122 minutes\n",
      "running: GaussianNB\n",
      "Elapsed time to compute the cross validate: 0.072 minutes\n",
      "running: KNeighborsClassifier\n",
      "Elapsed time to compute the cross validate: 0.076 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the cross validate: 0.712 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the cross validate: 2.086 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_zwickau_VS_london_models_experiment.run_cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8de31153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.735060</td>\n",
       "      <td>0.733672</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.744240</td>\n",
       "      <td>0.758333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.741122</td>\n",
       "      <td>0.724732</td>\n",
       "      <td>0.724051</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>0.732281</td>\n",
       "      <td>0.738889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.728461</td>\n",
       "      <td>0.723244</td>\n",
       "      <td>0.722036</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.727778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.799119</td>\n",
       "      <td>0.627708</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.612687</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.625776</td>\n",
       "      <td>0.623125</td>\n",
       "      <td>0.620956</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.629611</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.602903</td>\n",
       "      <td>0.575506</td>\n",
       "      <td>0.551375</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.572094</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.589629</td>\n",
       "      <td>0.555446</td>\n",
       "      <td>0.535763</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.551626</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "RandomForestClassifier            0.779559      0.735060  0.733672  0.758333   \n",
       "XGBClassifier                     0.741122      0.724732  0.724051  0.738889   \n",
       "AdaBoostClassifier                0.728461      0.723244  0.722036  0.727778   \n",
       "GaussianProcessClassifier         0.799119      0.627708  0.587600  0.675000   \n",
       "DecisionTreeClassifier            0.625776      0.623125  0.620956  0.633333   \n",
       "GaussianNB                        0.602903      0.575506  0.551375  0.611111   \n",
       "KNeighborsClassifier              0.589629      0.555446  0.535763  0.577778   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "RandomForestClassifier        0.744240  0.758333  \n",
       "XGBClassifier                 0.732281  0.738889  \n",
       "AdaBoostClassifier            0.726689  0.727778  \n",
       "GaussianProcessClassifier     0.612687  0.675000  \n",
       "DecisionTreeClassifier        0.629611  0.633333  \n",
       "GaussianNB                    0.572094  0.611111  \n",
       "KNeighborsClassifier          0.551626  0.577778  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_by_zwickau_VS_london_models_experiment.show_cross_validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c4f0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.70555556 0.74166667 0.73888889 0.74444444 0.73888889 0.73888889\n",
      " 0.75       0.74722222 0.70555556 0.74166667 0.73888889 0.74444444\n",
      " 0.73888889 0.73888889 0.75       0.74722222 0.58888889 0.57222222\n",
      " 0.56944444 0.56388889 0.56388889 0.56388889 0.56388889 0.56388889\n",
      " 0.69444444 0.725      0.72777778 0.74444444 0.73611111 0.74444444\n",
      " 0.75555556 0.75277778 0.69444444 0.725      0.72777778 0.74444444\n",
      " 0.73611111 0.74444444 0.75555556 0.75277778 0.60833333 0.58611111\n",
      " 0.58055556 0.56944444 0.56388889 0.56666667 0.56388889 0.56666667\n",
      " 0.7        0.73333333 0.74444444 0.74722222 0.75       0.75\n",
      " 0.76111111 0.75833333 0.7        0.73333333 0.74444444 0.74722222\n",
      " 0.75       0.75       0.76111111 0.75833333 0.61388889 0.60833333\n",
      " 0.59444444 0.58055556 0.575      0.58055556 0.57222222 0.56666667\n",
      " 0.71666667 0.74166667 0.74444444 0.76666667 0.76388889 0.76111111\n",
      " 0.76388889 0.77222222 0.71666667 0.74166667 0.74444444 0.76666667\n",
      " 0.76388889 0.76111111 0.76388889 0.77222222 0.63888889 0.61666667\n",
      " 0.60555556 0.58333333 0.59444444 0.59166667 0.58611111 0.58611111\n",
      " 0.70833333 0.725      0.75       0.75555556 0.76111111 0.76944444\n",
      " 0.76388889 0.76666667 0.70833333 0.725      0.75       0.75555556\n",
      " 0.76111111 0.76944444 0.76388889 0.76666667 0.63055556 0.62222222\n",
      " 0.61388889 0.61111111 0.60833333 0.60555556 0.6        0.6\n",
      " 0.725      0.73333333 0.74166667 0.75       0.75833333 0.75555556\n",
      " 0.76666667 0.775      0.725      0.73333333 0.74166667 0.75\n",
      " 0.75833333 0.75555556 0.76666667 0.775      0.65833333 0.64444444\n",
      " 0.64722222 0.62777778 0.60555556 0.61111111 0.60555556 0.60277778\n",
      " 0.725      0.73611111 0.74722222 0.75       0.74722222 0.74444444\n",
      " 0.75555556 0.75555556 0.725      0.73611111 0.74722222 0.75\n",
      " 0.74722222 0.74444444 0.75555556 0.75555556 0.66111111 0.65\n",
      " 0.64722222 0.625      0.61944444 0.61944444 0.61388889 0.61111111\n",
      " 0.74166667 0.73888889 0.75       0.75833333 0.75277778 0.76111111\n",
      " 0.76111111 0.76111111 0.74166667 0.73888889 0.75       0.75833333\n",
      " 0.75277778 0.76111111 0.76111111 0.76111111 0.66944444 0.65833333\n",
      " 0.64444444 0.63333333 0.63333333 0.625      0.62777778 0.62222222\n",
      " 0.72777778 0.75555556 0.75833333 0.75833333 0.75555556 0.75833333\n",
      " 0.76666667 0.75833333 0.72777778 0.75555556 0.75833333 0.75833333\n",
      " 0.75555556 0.75833333 0.76666667 0.75833333 0.65       0.66944444\n",
      " 0.65833333 0.63888889 0.63055556 0.62777778 0.625      0.625\n",
      " 0.70277778 0.72777778 0.73055556 0.73055556 0.73055556 0.725\n",
      " 0.74166667 0.74166667 0.70277778 0.72777778 0.73055556 0.73055556\n",
      " 0.73055556 0.725      0.74166667 0.74166667 0.6        0.57777778\n",
      " 0.56666667 0.56388889 0.56388889 0.56388889 0.56388889 0.56388889\n",
      " 0.71111111 0.74444444 0.74444444 0.75277778 0.74722222 0.74722222\n",
      " 0.75277778 0.75277778 0.71111111 0.74444444 0.74444444 0.75277778\n",
      " 0.74722222 0.74722222 0.75277778 0.75277778 0.60833333 0.58611111\n",
      " 0.57777778 0.56388889 0.56666667 0.56388889 0.56666667 0.56388889\n",
      " 0.71111111 0.75555556 0.75555556 0.75555556 0.75277778 0.74444444\n",
      " 0.75       0.75833333 0.71111111 0.75555556 0.75555556 0.75555556\n",
      " 0.75277778 0.74444444 0.75       0.75833333 0.63055556 0.59444444\n",
      " 0.58055556 0.57777778 0.57777778 0.57222222 0.57222222 0.56666667\n",
      " 0.725      0.74722222 0.75       0.75       0.74722222 0.74166667\n",
      " 0.75       0.75277778 0.725      0.74722222 0.75       0.75\n",
      " 0.74722222 0.74166667 0.75       0.75277778 0.62777778 0.63055556\n",
      " 0.61111111 0.59444444 0.58888889 0.58333333 0.58333333 0.58055556\n",
      " 0.75       0.74722222 0.74722222 0.76388889 0.75277778 0.75555556\n",
      " 0.76666667 0.76666667 0.75       0.74722222 0.74722222 0.76388889\n",
      " 0.75277778 0.75555556 0.76666667 0.76666667 0.62222222 0.61944444\n",
      " 0.60833333 0.60277778 0.60277778 0.59444444 0.59722222 0.59722222\n",
      " 0.72777778 0.74722222 0.75555556 0.77222222 0.76666667 0.76388889\n",
      " 0.75833333 0.76944444 0.72777778 0.74722222 0.75555556 0.77222222\n",
      " 0.76666667 0.76388889 0.75833333 0.76944444 0.64722222 0.63888889\n",
      " 0.63333333 0.60833333 0.61388889 0.60833333 0.60555556 0.60277778\n",
      " 0.73333333 0.75277778 0.76388889 0.76666667 0.76388889 0.76111111\n",
      " 0.76944444 0.76944444 0.73333333 0.75277778 0.76388889 0.76666667\n",
      " 0.76388889 0.76111111 0.76944444 0.76944444 0.64444444 0.65277778\n",
      " 0.66111111 0.625      0.62777778 0.63055556 0.63333333 0.625\n",
      " 0.74166667 0.75277778 0.76666667 0.77222222 0.76666667 0.76388889\n",
      " 0.75555556 0.76944444 0.74166667 0.75277778 0.76666667 0.77222222\n",
      " 0.76666667 0.76388889 0.75555556 0.76944444 0.63611111 0.64444444\n",
      " 0.66111111 0.63888889 0.64166667 0.63888889 0.63888889 0.63055556\n",
      " 0.73888889 0.74166667 0.75277778 0.76388889 0.76388889 0.76666667\n",
      " 0.77222222 0.76111111 0.73888889 0.74166667 0.75277778 0.76388889\n",
      " 0.76388889 0.76666667 0.77222222 0.76111111 0.63888889 0.65555556\n",
      " 0.66944444 0.65       0.63055556 0.64166667 0.64166667 0.63888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.92932099 0.93487654 0.93888889 0.9367284  0.94104938 0.94567901\n",
      " 0.94814815 0.94259259 0.92932099 0.93487654 0.93888889 0.9367284\n",
      " 0.94104938 0.94567901 0.94814815 0.94259259 0.72283951 0.68209877\n",
      " 0.66265432 0.64166667 0.63055556 0.62376543 0.61450617 0.60555556\n",
      " 0.96481481 0.97561728 0.97716049 0.98148148 0.98209877 0.98425926\n",
      " 0.98549383 0.98302469 0.96481481 0.97561728 0.97716049 0.98148148\n",
      " 0.98209877 0.98425926 0.98549383 0.98302469 0.79691358 0.77839506\n",
      " 0.76574074 0.74660494 0.74567901 0.73302469 0.72222222 0.71419753\n",
      " 0.98549383 0.99259259 0.9941358  0.99537037 0.99753086 0.99814815\n",
      " 0.99814815 0.99814815 0.98549383 0.99259259 0.9941358  0.99537037\n",
      " 0.99753086 0.99814815 0.99814815 0.99814815 0.85401235 0.85709877\n",
      " 0.85339506 0.85       0.85185185 0.84969136 0.84660494 0.8382716\n",
      " 0.99382716 0.99783951 0.99814815 0.99907407 1.         1.\n",
      " 1.         1.         0.99382716 0.99783951 0.99814815 0.99907407\n",
      " 1.         1.         1.         1.         0.89876543 0.9191358\n",
      " 0.92777778 0.92746914 0.93549383 0.93765432 0.93981481 0.9345679\n",
      " 0.99814815 0.99938272 1.         1.         1.         1.\n",
      " 1.         1.         0.99814815 0.99938272 1.         1.\n",
      " 1.         1.         1.         1.         0.93487654 0.94876543\n",
      " 0.95925926 0.96388889 0.96851852 0.9691358  0.97469136 0.97345679\n",
      " 0.99938272 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99938272 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95308642 0.97191358\n",
      " 0.97654321 0.98333333 0.98487654 0.98703704 0.98734568 0.98888889\n",
      " 0.99969136 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969136 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96635802 0.98333333\n",
      " 0.98950617 0.99197531 0.99598765 0.99444444 0.99567901 0.99506173\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.9808642  0.99135802\n",
      " 0.99506173 0.99660494 0.99722222 0.99783951 0.99783951 0.99876543\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98888889 0.99660494\n",
      " 0.99722222 0.99876543 0.99876543 0.99907407 0.99907407 0.99938272\n",
      " 0.9117284  0.91975309 0.92191358 0.92037037 0.92376543 0.92623457\n",
      " 0.92808642 0.92253086 0.9117284  0.91975309 0.92191358 0.92037037\n",
      " 0.92376543 0.92623457 0.92808642 0.92253086 0.70216049 0.66203704\n",
      " 0.64537037 0.62222222 0.61666667 0.60648148 0.59722222 0.58858025\n",
      " 0.95555556 0.96358025 0.96790123 0.9632716  0.96944444 0.96975309\n",
      " 0.97160494 0.97222222 0.95555556 0.96358025 0.96790123 0.9632716\n",
      " 0.96944444 0.96975309 0.97160494 0.97222222 0.77716049 0.75\n",
      " 0.7382716  0.71759259 0.70895062 0.70061728 0.68580247 0.68055556\n",
      " 0.97839506 0.98364198 0.98734568 0.98950617 0.99104938 0.99290123\n",
      " 0.99351852 0.99351852 0.97839506 0.98364198 0.98734568 0.98950617\n",
      " 0.99104938 0.99290123 0.99351852 0.99351852 0.8345679  0.83240741\n",
      " 0.83024691 0.81635802 0.82006173 0.81296296 0.8095679  0.80277778\n",
      " 0.99135802 0.99537037 0.99598765 0.99691358 0.99876543 0.99907407\n",
      " 1.         1.         0.99135802 0.99537037 0.99598765 0.99691358\n",
      " 0.99876543 0.99907407 1.         1.         0.88919753 0.89722222\n",
      " 0.89969136 0.90277778 0.90895062 0.90925926 0.91018519 0.90493827\n",
      " 0.99567901 0.99876543 0.99938272 1.         1.         1.\n",
      " 1.         1.         0.99567901 0.99876543 0.99938272 1.\n",
      " 1.         1.         1.         1.         0.91697531 0.93888889\n",
      " 0.94814815 0.94537037 0.95555556 0.95895062 0.96203704 0.96049383\n",
      " 0.99814815 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99814815 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.93981481 0.96419753\n",
      " 0.97006173 0.97469136 0.97623457 0.97808642 0.98302469 0.98117284\n",
      " 0.99876543 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99876543 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96111111 0.97685185\n",
      " 0.9845679  0.98641975 0.98858025 0.98981481 0.99197531 0.99166667\n",
      " 0.99938272 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99938272 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97314815 0.98765432\n",
      " 0.99351852 0.99382716 0.99660494 0.99660494 0.99722222 0.99722222\n",
      " 0.99969136 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969136 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98395062 0.99382716\n",
      " 0.99506173 0.99722222 0.99814815 0.99938272 0.99969136 0.99907407\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the greed search cv: 12.516 minutes\n",
      "running: AdaBoostClassifier\n",
      "Elapsed time to compute the greed search cv: 57.366 minutes\n",
      "running: XGBClassifier\n",
      "Elapsed time to compute the greed search cv: 62.370 minutes\n"
     ]
    }
   ],
   "source": [
    "burchard_by_zwickau_VS_london_models_experiment.run_greed_search_cv_for_n_best_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39958117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7750000000000001\n",
      "RandomForestClassifier(max_depth=9, n_estimators=500, random_state=0)\n",
      "0.775\n",
      "AdaBoostClassifier(learning_rate=0.5, n_estimators=300)\n",
      "0.763888888888889\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.1, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "for i in burchard_by_zwickau_VS_london_models_experiment.greed_search_cv_results:\n",
    "    print(i.best_score_)\n",
    "    print(i.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637c8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c53232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_london_VS_zwickau_models_experiment.get_n_best_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t= burchard_by_london_VS_zwickau_models_experiment.show_cross_validate_results().index[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debc5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_names = burchard_by_london_VS_zwickau_models_experiment.show_cross_validate_results().index[:3]\n",
    "best_models = []\n",
    "\n",
    "for m, name, greed_search_cv_params in burchard_by_london_VS_zwickau_models_experiment.models:\n",
    "    if name in best_models_names: best_models.append(m)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f67748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, classifier_name, greed_search_cv_params in best_models:\n",
    "    print(classifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in burchard_by_london_VS_zwickau_models_experiment.greed_search_cv_results:\n",
    "    print(i.best_score_)\n",
    "    print(i.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1df4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334d4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490786d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbfedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_london_VS_zwickau_models_results = thesisModelFeatures.run_models(\n",
    "    burchard_by_london_VS_zwickau_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce7b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_london_VS_zwickau_models_results[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321690b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'XGBClassifiers' in burchard_by_london_VS_zwickau_models_results[0].sort_values(by=['accuracy'], ascending=False).index[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_zwickau_VS_zwickau_models_results = thesisModelFeatures.run_models(\n",
    "    burchard_by_zwickau_VS_zwickau_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e284a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_zwickau_VS_zwickau_models_results[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d95e8",
   "metadata": {},
   "source": [
    "## burchard VS london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_london_VS_london_models_results = thesisModelFeatures.run_models(\n",
    "    burchard_by_london_VS_london_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3267710",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_london_VS_london_models_results[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_zwickau_VS_london_models_results = thesisModelFeatures.run_models(\n",
    "    burchard_by_zwickau_VS_london_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a633aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_by_zwickau_VS_london_models_results[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac55ed",
   "metadata": {},
   "source": [
    "## burchard VS zwickau greed search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc160c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_london_VS_zwickau_greed_rearch_results = []\n",
    "# for cls in [\n",
    "#     'KNeighborsClassifier', \n",
    "#     'AdaBoostClassifier', \n",
    "#     'XGBClassifier'\n",
    "# ]:\n",
    "#     grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_by_london_VS_zwickau_features_df, [cls])\n",
    "#     burchard_by_london_VS_zwickau_greed_rearch_results.append([cls, grid_search_cv_result[1][0].best_score_, grid_search_cv_result[1][0].best_estimator_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_london_VS_zwickau_greed_rearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6032ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_zwickau_VS_zwickau_greed_rearch_results = []\n",
    "# for cls in [\n",
    "#     'KNeighborsClassifier', \n",
    "#     'AdaBoostClassifier', \n",
    "#     'XGBClassifier'\n",
    "# ]:\n",
    "#     grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_by_zwickau_VS_zwickau_features_df, [cls])\n",
    "#     burchard_by_zwickau_VS_zwickau_greed_rearch_results.append([cls, grid_search_cv_result[1][0].best_score_, grid_search_cv_result[1][0].best_estimator_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e38b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_zwickau_VS_zwickau_greed_rearch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503771f",
   "metadata": {},
   "source": [
    "## burchard VS london greed search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c09d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_london_VS_london_greed_rearch_results = []\n",
    "# for cls in [\n",
    "#     'KNeighborsClassifier', \n",
    "#     'AdaBoostClassifier', \n",
    "#     'XGBClassifier'\n",
    "# ]:\n",
    "#     grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_by_london_VS_london_features_df, [cls])\n",
    "#     burchard_by_london_VS_london_greed_rearch_results.append([cls, grid_search_cv_result[1][0].best_score_, grid_search_cv_result[1][0].best_estimator_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_london_VS_london_greed_rearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64598c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burchard_by_zwickau_VS_london_greed_rearch_results = []\n",
    "# for cls in [\n",
    "#     'KNeighborsClassifier', \n",
    "#     'AdaBoostClassifier', \n",
    "#     'XGBClassifier'\n",
    "# ]:\n",
    "#     grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_by_zwickau_VS_london_features_df, [cls])\n",
    "#     burchard_by_zwickau_VS_london_greed_rearch_results.append([cls, grid_search_cv_result[1][0].best_score_, grid_search_cv_result[1][0].best_estimator_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db8ade",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = thesisModelFeatures.Model(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54de87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = thesisModelFeatures.Model(AdaBoostClassifier(learning_rate=1, n_estimators=2000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
