{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53454b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ad0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q decorator==5.0.9\n",
    "!pip install -q ipywidgets\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import re\n",
    "import imp\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib as dl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bab224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q cltk==1.0.22\n",
    "%pip install -q strsim\n",
    "%pip install -q leven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868bbc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features.model_features' from '../src/features/model_features.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing local modules\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import text_cleanup.text_cleanup as thesisCleanUp\n",
    "import preprocessing.text_preprocessing as thesisTextPreprocessing\n",
    "import data.reader as thesisDataReader\n",
    "import utils.utils as thesisUtils\n",
    "import features.tf_idf.n_gram as thesisTfIdfNgramFeatures\n",
    "import features.count_vectorizer.n_gram as thesisCountVectorizerNgramFeatures\n",
    "import similarities.cosine as thesisCosineSimilarities\n",
    "import similarities.levenshtein as thesisLevenshteinSimilarities\n",
    "import vocabulary.vocabulary as thesisVocabulary\n",
    "import features.lexical as thesisLexicalFeatures\n",
    "import similarities.cosine as thesisCosineSimilarity\n",
    "import text_cleanup.text_cleanup as thesisTextCleanUp\n",
    "import p_aligment.p_aligment as thesisPAligment\n",
    "import features.model_features as thesisModelFeatures\n",
    "\n",
    "imp.reload(thesisTfIdfNgramFeatures)\n",
    "imp.reload(thesisLexicalFeatures)\n",
    "imp.reload(thesisCosineSimilarity)\n",
    "imp.reload(thesisCleanUp)\n",
    "imp.reload(thesisTextPreprocessing)\n",
    "imp.reload(thesisDataReader)\n",
    "imp.reload(thesisUtils)\n",
    "\n",
    "imp.reload(thesisVocabulary)\n",
    "imp.reload(thesisCosineSimilarities)\n",
    "imp.reload(thesisTextCleanUp)\n",
    "imp.reload(thesisCountVectorizerNgramFeatures)\n",
    "imp.reload(thesisPAligment)\n",
    "imp.reload(thesisLevenshteinSimilarities)\n",
    "imp.reload(thesisModelFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd1a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_poorly_similar_with_chops_corpus_without_word_processing = thesisVocabulary.create_pre_proceed_corpus_from_processed_corpus(\n",
    "    thesisDataReader.get_london_poorly_similar_with_chops_corpus(),\n",
    "    thesisVocabulary.create_london_pre_post_processing_map()\n",
    ")\n",
    "zwickau_poorly_similar_with_chops_corpus_without_word_processing = thesisVocabulary.create_pre_proceed_corpus_from_processed_corpus(\n",
    "    thesisDataReader.get_zwickau_poorly_similar_with_chops_corpus(),\n",
    "    thesisVocabulary.create_zwickau_pre_post_processing_map()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50121765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_poorly_similar_with_chops_corpus_without_word_processing_long_p = list(filter(lambda x: len(x.split()) > 20, london_poorly_similar_with_chops_corpus_without_word_processing))\n",
    "len(london_poorly_similar_with_chops_corpus_without_word_processing_long_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa06758b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p = list(filter(lambda x: len(x.split()) > 20, zwickau_poorly_similar_with_chops_corpus_without_word_processing))\n",
    "len(zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0ab5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "burchard_candidate_version_based_london_without_word_processing = thesisVocabulary.create_pre_proceed_corpus_from_processed_corpus(\n",
    "    thesisDataReader.get_burchard_candidate_version_based_on_strongly_similar_zwickau_base(),\n",
    "    thesisVocabulary.create_zwickau_pre_post_processing_map()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f47bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(burchard_candidate_version_based_london_without_word_processing))\n",
    "burchard_candidate_version_based_london_without_word_processing_long_p = list(filter(lambda x: len(x.split()) > 20, burchard_candidate_version_based_london_without_word_processing))\n",
    "len(burchard_candidate_version_based_london_without_word_processing_long_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b02249f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df = thesisModelFeatures.create_features_df(\n",
    "    london_poorly_similar_with_chops_corpus_without_word_processing_long_p,\n",
    "    None,\n",
    "    burchard_candidate_version_based_london_without_word_processing_long_p,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d78d6ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>corpus_version_label</th>\n",
       "      <th>a</th>\n",
       "      <th>a</th>\n",
       "      <th>a b</th>\n",
       "      <th>a be</th>\n",
       "      <th>a c</th>\n",
       "      <th>a ca</th>\n",
       "      <th>a ce</th>\n",
       "      <th>a ch</th>\n",
       "      <th>...</th>\n",
       "      <th>zuri</th>\n",
       "      <th>zurio</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyd</th>\n",
       "      <th>zyda</th>\n",
       "      <th>zyda</th>\n",
       "      <th>zyp</th>\n",
       "      <th>zyph</th>\n",
       "      <th>zyph</th>\n",
       "      <th>inner_mean_cosine_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>202.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.050451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>203.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.044633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>204.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.043195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>205.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.035188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>206.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.045660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 51292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  corpus_version_label         a   a    a b   a be   a c   a ca  \\\n",
       "0      0.0                   0.0  0.018325  0.0   0.0    0.0   0.0    0.0   \n",
       "1      1.0                   0.0  0.010313  0.0   0.0    0.0   0.0    0.0   \n",
       "2      2.0                   0.0  0.009518  0.0   0.0    0.0   0.0    0.0   \n",
       "3      3.0                   0.0  0.000000  0.0   0.0    0.0   0.0    0.0   \n",
       "4      4.0                   0.0  0.057770  0.0   0.0    0.0   0.0    0.0   \n",
       "..     ...                   ...       ...  ...   ...    ...   ...    ...   \n",
       "359  202.0                   2.0  0.050451  0.0   0.0    0.0   0.0    0.0   \n",
       "360  203.0                   2.0  0.044633  0.0   0.0    0.0   0.0    0.0   \n",
       "361  204.0                   2.0  0.043195  0.0   0.0    0.0   0.0    0.0   \n",
       "362  205.0                   2.0  0.035188  0.0   0.0    0.0   0.0    0.0   \n",
       "363  206.0                   2.0  0.045660  0.0   0.0    0.0   0.0    0.0   \n",
       "\n",
       "      a ce   a ch  ...  zuri  zurio   zy  zyd  zyda  zyda   zyp  zyph  zyph   \\\n",
       "0      0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "1      0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "2      0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "3      0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "4      0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "..     ...    ...  ...   ...    ...  ...  ...   ...    ...  ...   ...    ...   \n",
       "359    0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "360    0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "361    0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "362    0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "363    0.0    0.0  ...   0.0    0.0  0.0  0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "\n",
       "     inner_mean_cosine_similarity_score  \n",
       "0                              0.078201  \n",
       "1                              0.090889  \n",
       "2                              0.105741  \n",
       "3                              0.108059  \n",
       "4                              0.080353  \n",
       "..                                  ...  \n",
       "359                            0.229550  \n",
       "360                            0.154216  \n",
       "361                            0.250562  \n",
       "362                            0.203420  \n",
       "363                            0.158157  \n",
       "\n",
       "[364 rows x 51292 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945dfb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n",
      "running: AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_london_tf_idf_2_5_cosine_results_long_p = thesisModelFeatures.run_models(burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c9b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.784533</td>\n",
       "      <td>0.746458</td>\n",
       "      <td>0.745451</td>\n",
       "      <td>0.763138</td>\n",
       "      <td>0.753996</td>\n",
       "      <td>0.763138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.781945</td>\n",
       "      <td>0.742827</td>\n",
       "      <td>0.742405</td>\n",
       "      <td>0.760586</td>\n",
       "      <td>0.751301</td>\n",
       "      <td>0.760586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.743787</td>\n",
       "      <td>0.741458</td>\n",
       "      <td>0.740183</td>\n",
       "      <td>0.744820</td>\n",
       "      <td>0.744525</td>\n",
       "      <td>0.744820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.771257</td>\n",
       "      <td>0.716964</td>\n",
       "      <td>0.715679</td>\n",
       "      <td>0.741592</td>\n",
       "      <td>0.727058</td>\n",
       "      <td>0.741592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.701835</td>\n",
       "      <td>0.694405</td>\n",
       "      <td>0.691387</td>\n",
       "      <td>0.700375</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.700375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.794566</td>\n",
       "      <td>0.656696</td>\n",
       "      <td>0.634717</td>\n",
       "      <td>0.700150</td>\n",
       "      <td>0.656152</td>\n",
       "      <td>0.700150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.667649</td>\n",
       "      <td>0.620030</td>\n",
       "      <td>0.604490</td>\n",
       "      <td>0.656532</td>\n",
       "      <td>0.623857</td>\n",
       "      <td>0.656532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.588007</td>\n",
       "      <td>0.575655</td>\n",
       "      <td>0.558166</td>\n",
       "      <td>0.601877</td>\n",
       "      <td>0.576242</td>\n",
       "      <td>0.601877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.284347</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.362497</td>\n",
       "      <td>0.568694</td>\n",
       "      <td>0.412394</td>\n",
       "      <td>0.568694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "GaussianProcessClassifier         0.784533      0.746458  0.745451  0.763138   \n",
       "MLPClassifier                     0.781945      0.742827  0.742405  0.760586   \n",
       "AdaBoostClassifier                0.743787      0.741458  0.740183  0.744820   \n",
       "RandomForestClassifier            0.771257      0.716964  0.715679  0.741592   \n",
       "DecisionTreeClassifier            0.701835      0.694405  0.691387  0.700375   \n",
       "SVM_RBF                           0.794566      0.656696  0.634717  0.700150   \n",
       "GaussianNB                        0.667649      0.620030  0.604490  0.656532   \n",
       "KNeighborsClassifier              0.588007      0.575655  0.558166  0.601877   \n",
       "SVM_linear                        0.284347      0.500000  0.362497  0.568694   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "GaussianProcessClassifier     0.753996  0.763138  \n",
       "MLPClassifier                 0.751301  0.760586  \n",
       "AdaBoostClassifier            0.744525  0.744820  \n",
       "RandomForestClassifier        0.727058  0.741592  \n",
       "DecisionTreeClassifier        0.697376  0.700375  \n",
       "SVM_RBF                       0.656152  0.700150  \n",
       "GaussianNB                    0.623857  0.656532  \n",
       "KNeighborsClassifier          0.576242  0.601877  \n",
       "SVM_linear                    0.412394  0.568694  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_london_tf_idf_2_5_cosine_results_long_p[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22406261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.779954954954955\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7304804804804805\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7715465465465465\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.73866366 0.75503003 0.75487988 0.76599099 0.76591592 0.76036036\n",
      " 0.76051051 0.76043544 0.73866366 0.75503003 0.75487988 0.76599099\n",
      " 0.76591592 0.76036036 0.76051051 0.76043544 0.5795045  0.56869369\n",
      " 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.7716967  0.76884384 0.76328829 0.76328829 0.76036036 0.76328829\n",
      " 0.74962462 0.75487988 0.7716967  0.76884384 0.76328829 0.76328829\n",
      " 0.76036036 0.76328829 0.74962462 0.75487988 0.57972973 0.57972973\n",
      " 0.58235736 0.5768018  0.56869369 0.5740991  0.5713964  0.5713964\n",
      " 0.78265766 0.76891892 0.76861862 0.76876877 0.77702703 0.7743994\n",
      " 0.77162162 0.76876877 0.78265766 0.76891892 0.76861862 0.76876877\n",
      " 0.77702703 0.7743994  0.77162162 0.76876877 0.58783784 0.58791291\n",
      " 0.59054054 0.58776276 0.5795045  0.5768018  0.5768018  0.5740991\n",
      " 0.74714715 0.77702703 0.77147147 0.76599099 0.77424925 0.77432432\n",
      " 0.76614114 0.76869369 0.74714715 0.77702703 0.77147147 0.76599099\n",
      " 0.77424925 0.77432432 0.76614114 0.76869369 0.59316817 0.5987988\n",
      " 0.60968468 0.59864865 0.59031532 0.59031532 0.58498498 0.58220721\n",
      " 0.74722222 0.75765766 0.76884384 0.76321321 0.76051051 0.77424925\n",
      " 0.77154655 0.77695195 0.74722222 0.75765766 0.76884384 0.76321321\n",
      " 0.76051051 0.77424925 0.77154655 0.77695195 0.60960961 0.6042042\n",
      " 0.61786787 0.62057057 0.60683183 0.59864865 0.59857357 0.58498498\n",
      " 0.78828829 0.7716967  0.76869369 0.76869369 0.77432432 0.7743994\n",
      " 0.7743994  0.77154655 0.78828829 0.7716967  0.76869369 0.76869369\n",
      " 0.77432432 0.7743994  0.7743994  0.77154655 0.64226727 0.62057057\n",
      " 0.61509009 0.60945946 0.60668168 0.60412913 0.59864865 0.59572072\n",
      " 0.7713964  0.77402402 0.7740991  0.77695195 0.78528529 0.79354354\n",
      " 0.78528529 0.7798048  0.7713964  0.77402402 0.7740991  0.77695195\n",
      " 0.78528529 0.79354354 0.78528529 0.7798048  0.63423423 0.63168168\n",
      " 0.61786787 0.61501502 0.61493994 0.61779279 0.61493994 0.60405405\n",
      " 0.73048048 0.77177177 0.7771021  0.78536036 0.7990991  0.78543544\n",
      " 0.78536036 0.78250751 0.73048048 0.77177177 0.7771021  0.78536036\n",
      " 0.7990991  0.78543544 0.78536036 0.78250751 0.6533033  0.64797297\n",
      " 0.63438438 0.63956456 0.6286036  0.63138138 0.62875375 0.63153153\n",
      " 0.75533033 0.77147147 0.77154655 0.78798799 0.78798799 0.78536036\n",
      " 0.7771021  0.7798048  0.75533033 0.77147147 0.77154655 0.78798799\n",
      " 0.78798799 0.78536036 0.7771021  0.7798048  0.62057057 0.64249249\n",
      " 0.64241742 0.6533033  0.64782282 0.64504505 0.63971471 0.63160661\n",
      " 0.71366366 0.75773273 0.7524024  0.76321321 0.76328829 0.76328829\n",
      " 0.76336336 0.76058559 0.71366366 0.75773273 0.7524024  0.76321321\n",
      " 0.76328829 0.76328829 0.76336336 0.76058559 0.57417417 0.56869369\n",
      " 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369 0.56869369\n",
      " 0.75202703 0.77687688 0.76591592 0.76599099 0.76328829 0.76599099\n",
      " 0.75773273 0.76599099 0.75202703 0.77687688 0.76591592 0.76599099\n",
      " 0.76328829 0.76599099 0.75773273 0.76599099 0.57965465 0.57417417\n",
      " 0.5713964  0.5713964  0.5713964  0.5713964  0.5713964  0.5713964\n",
      " 0.74414414 0.76606607 0.77702703 0.76591592 0.77162162 0.76884384\n",
      " 0.76328829 0.75773273 0.74414414 0.76606607 0.77702703 0.76591592\n",
      " 0.77162162 0.76884384 0.76328829 0.75773273 0.59872372 0.5768018\n",
      " 0.57957958 0.58498498 0.5740991  0.5768018  0.5768018  0.5740991\n",
      " 0.74954955 0.7716967  0.77424925 0.76876877 0.77162162 0.76884384\n",
      " 0.76591592 0.76876877 0.74954955 0.7716967  0.77424925 0.76876877\n",
      " 0.77162162 0.76884384 0.76591592 0.76876877 0.59857357 0.59039039\n",
      " 0.60127628 0.5957958  0.59301802 0.58761261 0.58220721 0.58490991\n",
      " 0.76043544 0.76884384 0.76321321 0.76036036 0.76313814 0.76599099\n",
      " 0.76051051 0.77162162 0.76043544 0.76884384 0.76321321 0.76036036\n",
      " 0.76313814 0.76599099 0.76051051 0.77162162 0.62334835 0.60405405\n",
      " 0.60938438 0.61231231 0.60405405 0.59301802 0.59039039 0.58768769\n",
      " 0.71929429 0.77154655 0.76599099 0.75788288 0.76058559 0.75765766\n",
      " 0.77154655 0.77417417 0.71929429 0.77154655 0.76599099 0.75788288\n",
      " 0.76058559 0.75765766 0.77154655 0.77417417 0.6259009  0.62897898\n",
      " 0.63145646 0.62327327 0.61486486 0.60397898 0.60127628 0.5984985\n",
      " 0.73325826 0.78258258 0.77417417 0.76591592 0.76313814 0.76869369\n",
      " 0.76599099 0.77702703 0.73325826 0.78258258 0.77417417 0.76591592\n",
      " 0.76313814 0.76869369 0.76599099 0.77702703 0.63678679 0.63423423\n",
      " 0.63693694 0.63130631 0.62297297 0.60938438 0.61223724 0.61493994\n",
      " 0.73325826 0.76321321 0.77117117 0.77672673 0.77687688 0.77965465\n",
      " 0.78228228 0.78235736 0.73325826 0.76321321 0.77117117 0.77672673\n",
      " 0.77687688 0.77965465 0.78228228 0.78235736 0.62882883 0.66433934\n",
      " 0.65045045 0.63933934 0.63385886 0.63408408 0.63138138 0.63678679\n",
      " 0.7496997  0.77965465 0.77417417 0.78791291 0.7713964  0.77695195\n",
      " 0.77695195 0.76599099 0.7496997  0.77965465 0.77417417 0.78791291\n",
      " 0.7713964  0.77695195 0.77695195 0.76599099 0.62875375 0.6533033\n",
      " 0.66426426 0.65045045 0.64504505 0.64782282 0.6478979  0.65345345\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.93162341 0.94872175 0.94658481 0.94414112 0.94505482 0.95054822\n",
      " 0.95207727 0.94902383 0.93162341 0.94872175 0.94658481 0.94414112\n",
      " 0.94505482 0.95054822 0.95207727 0.94902383 0.66972104 0.63917916\n",
      " 0.63339767 0.62697751 0.62606288 0.62575613 0.6117103  0.60560808\n",
      " 0.96886421 0.97710711 0.98260051 0.98412769 0.98626371 0.98779276\n",
      " 0.98962482 0.99054132 0.96886421 0.97710711 0.98260051 0.98412769\n",
      " 0.98626371 0.98779276 0.98962482 0.99054132 0.73746923 0.72769076\n",
      " 0.72557153 0.72159693 0.71701723 0.71914858 0.70542161 0.70328653\n",
      " 0.98748695 0.99237059 0.99572705 0.99694935 0.99755818 0.99786399\n",
      " 0.99877956 0.99816887 0.98748695 0.99237059 0.99572705 0.99694935\n",
      " 0.99755818 0.99786399 0.99877956 0.99816887 0.80951835 0.818054\n",
      " 0.81897237 0.82417114 0.81867028 0.82081096 0.82141605 0.82020866\n",
      " 0.99420172 0.99695122 0.99939024 0.99969512 0.99969512 0.99969512\n",
      " 0.99969512 1.         0.99420172 0.99695122 0.99939024 0.99969512\n",
      " 0.99969512 0.99969512 0.99969512 1.         0.86232285 0.88765757\n",
      " 0.9044501  0.90597542 0.91391344 0.91025957 0.91116767 0.91178302\n",
      " 0.99847375 0.99969512 1.         1.         1.         1.\n",
      " 1.         1.         0.99847375 0.99969512 1.         1.\n",
      " 1.         1.         1.         1.         0.91361695 0.93802305\n",
      " 0.9435295  0.95055475 0.9548277  0.96123294 0.96398057 0.96581264\n",
      " 0.99877956 0.99969512 1.         1.         1.         1.\n",
      " 1.         1.         0.99877956 0.99969512 1.         1.\n",
      " 1.         1.         1.         1.         0.93711494 0.96306314\n",
      " 0.96733982 0.97497016 0.97954986 0.98290445 0.98076844 0.9832112\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96000783 0.97832569\n",
      " 0.9832112  0.98779089 0.98901227 0.99084434 0.98992877 0.98962482\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97374692 0.9899269\n",
      " 0.99267547 0.99450753 0.99420079 0.99511822 0.9963396  0.99481334\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98412769 0.99297848\n",
      " 0.99694935 0.99786399 0.99755818 0.99664168 0.99694935 0.99786492\n",
      " 0.92460935 0.93559801 0.9352894  0.93193667 0.93621149 0.93712333\n",
      " 0.9389526  0.93742168 0.92460935 0.93559801 0.9352894  0.93193667\n",
      " 0.93621149 0.93712333 0.9389526  0.93742168 0.65506172 0.62513799\n",
      " 0.62056388 0.61537536 0.61018684 0.60835105 0.599807   0.59401152\n",
      " 0.96031644 0.96978258 0.97435388 0.97313623 0.97924498 0.98138006\n",
      " 0.98382095 0.98382095 0.96031644 0.96978258 0.97435388 0.97313623\n",
      " 0.97924498 0.98138006 0.98382095 0.98382095 0.71946185 0.70267025\n",
      " 0.70267491 0.6901544  0.69595827 0.69412434 0.67978575 0.67306538\n",
      " 0.98442791 0.98839972 0.9908434  0.99298035 0.99359103 0.99603472\n",
      " 0.99756004 0.99694935 0.98442791 0.98839972 0.9908434  0.99298035\n",
      " 0.99359103 0.99603472 0.99756004 0.99694935 0.79486462 0.79334303\n",
      " 0.79670694 0.7951751  0.79151376 0.79304841 0.78784963 0.78662825\n",
      " 0.99023458 0.99603379 0.9981698  0.99939024 0.99908537 0.99939024\n",
      " 0.99969512 1.         0.99023458 0.99603379 0.9981698  0.99939024\n",
      " 0.99908537 0.99939024 0.99969512 1.         0.84828168 0.86781905\n",
      " 0.87698497 0.87698777 0.88279071 0.88218002 0.88218002 0.88462277\n",
      " 0.99664354 0.99908537 0.99969512 1.         1.         1.\n",
      " 1.         1.         0.99664354 0.99908537 0.99969512 1.\n",
      " 1.         1.         1.         1.         0.89652327 0.91788804\n",
      " 0.92429981 0.93467778 0.93895073 0.94749944 0.9508531  0.94963265\n",
      " 0.99816887 0.99969512 1.         1.         1.         1.\n",
      " 1.         1.         0.99816887 0.99969512 1.         1.\n",
      " 1.         1.         1.         1.         0.92459816 0.9499366\n",
      " 0.95696465 0.96245618 0.96825632 0.97161278 0.97558365 0.97832942\n",
      " 0.99908443 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99908443 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.95146658 0.9722216\n",
      " 0.97527504 0.9807731  0.98473932 0.98595696 0.98778996 0.98809391\n",
      " 0.99969512 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969512 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96520381 0.98138379\n",
      " 0.98596535 0.9871858  0.99023644 0.99115201 0.99267733 0.99267733\n",
      " 0.99969512 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99969512 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.97863802 0.98901413\n",
      " 0.99206571 0.99420172 0.9945066  0.99511729 0.99664261 0.99633773\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799099099099099\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6921171171171172\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.6427927927927928\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.8132882882882884\n"
     ]
    }
   ],
   "source": [
    "resp = []\n",
    "for cls in ['SVC', 'DecisionTreeClassifier', 'GaussianProcessClassifier', 'RandomForestClassifier', 'GaussianNB', 'KNeighborsClassifier', 'AdaBoostClassifier']:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_london_features_tfidf_2_5_gram_cosine_similarity_long_p_df, [cls])\n",
    "    resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16350c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.779954954954955],\n",
       " ['DecisionTreeClassifier', 0.7304804804804805],\n",
       " ['GaussianProcessClassifier', 0.7715465465465465],\n",
       " ['RandomForestClassifier', 0.799099099099099],\n",
       " ['GaussianNB', 0.6921171171171172],\n",
       " ['KNeighborsClassifier', 0.6427927927927928],\n",
       " ['AdaBoostClassifier', 0.8132882882882884]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b65a3",
   "metadata": {},
   "source": [
    "# burchard candidate vs zwickau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cc2559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram_feature_name: 2_5_gram\n",
      "n_gram_feature_name: 2_5_gram\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df = thesisModelFeatures.create_features_df(\n",
    "    None,\n",
    "    zwickau_poorly_similar_with_chops_corpus_without_word_processing_long_p,\n",
    "    burchard_candidate_version_based_london_without_word_processing_long_p,\n",
    "    n_gram = (2,5),\n",
    "    features = { 'tfidf', 'inner_mean_cosine_similarity_score' }\n",
    "#     burchard_version_with_original_london_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59324d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>corpus_version_label</th>\n",
       "      <th>a</th>\n",
       "      <th>a</th>\n",
       "      <th>a a</th>\n",
       "      <th>a ac</th>\n",
       "      <th>a al</th>\n",
       "      <th>a ap</th>\n",
       "      <th>a b</th>\n",
       "      <th>a be</th>\n",
       "      <th>...</th>\n",
       "      <th>zra q</th>\n",
       "      <th>zrae</th>\n",
       "      <th>zrael</th>\n",
       "      <th>zrah</th>\n",
       "      <th>zrahe</th>\n",
       "      <th>zu</th>\n",
       "      <th>zur</th>\n",
       "      <th>zuri</th>\n",
       "      <th>zurio</th>\n",
       "      <th>inner_mean_cosine_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053559</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>202.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>203.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.043982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>204.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.042789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>205.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.034867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>206.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 49302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  corpus_version_label         a        a    a a   a ac   a al  \\\n",
       "0      0.0                   1.0  0.009894  0.000000   0.0    0.0    0.0   \n",
       "1      1.0                   1.0  0.038350  0.018460   0.0    0.0    0.0   \n",
       "2      2.0                   1.0  0.053559  0.014502   0.0    0.0    0.0   \n",
       "3      3.0                   1.0  0.033982  0.000000   0.0    0.0    0.0   \n",
       "4      4.0                   1.0  0.032807  0.023688   0.0    0.0    0.0   \n",
       "..     ...                   ...       ...       ...   ...    ...    ...   \n",
       "368  202.0                   2.0  0.049717  0.000000   0.0    0.0    0.0   \n",
       "369  203.0                   2.0  0.043982  0.000000   0.0    0.0    0.0   \n",
       "370  204.0                   2.0  0.042789  0.000000   0.0    0.0    0.0   \n",
       "371  205.0                   2.0  0.034867  0.000000   0.0    0.0    0.0   \n",
       "372  206.0                   2.0  0.044836  0.000000   0.0    0.0    0.0   \n",
       "\n",
       "      a ap   a b   a be  ...  zra q  zrae  zrael  zrah  zrahe   zu  zur  zuri  \\\n",
       "0      0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "1      0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "2      0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "3      0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "4      0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "..     ...   ...    ...  ...    ...   ...    ...   ...    ...  ...  ...   ...   \n",
       "368    0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "369    0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "370    0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "371    0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "372    0.0   0.0    0.0  ...    0.0   0.0    0.0   0.0    0.0  0.0  0.0   0.0   \n",
       "\n",
       "     zurio  inner_mean_cosine_similarity_score  \n",
       "0      0.0                            0.089736  \n",
       "1      0.0                            0.169794  \n",
       "2      0.0                            0.110581  \n",
       "3      0.0                            0.117864  \n",
       "4      0.0                            0.086517  \n",
       "..     ...                                 ...  \n",
       "368    0.0                            0.229550  \n",
       "369    0.0                            0.154216  \n",
       "370    0.0                            0.250562  \n",
       "371    0.0                            0.203420  \n",
       "372    0.0                            0.158157  \n",
       "\n",
       "[373 rows x 49302 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c03183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: SVM_RBF\n",
      "running: DecisionTreeClassifier\n",
      "running: GaussianProcessClassifier\n",
      "running: RandomForestClassifier\n",
      "running: MLPClassifier\n",
      "running: GaussianNB\n",
      "running: KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p = thesisModelFeatures.run_models(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd76f3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.773153</td>\n",
       "      <td>0.768804</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.772048</td>\n",
       "      <td>0.771116</td>\n",
       "      <td>0.772048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.730173</td>\n",
       "      <td>0.706387</td>\n",
       "      <td>0.703710</td>\n",
       "      <td>0.717994</td>\n",
       "      <td>0.709452</td>\n",
       "      <td>0.717994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.704656</td>\n",
       "      <td>0.697908</td>\n",
       "      <td>0.696279</td>\n",
       "      <td>0.705192</td>\n",
       "      <td>0.701543</td>\n",
       "      <td>0.705192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.716966</td>\n",
       "      <td>0.697377</td>\n",
       "      <td>0.695280</td>\n",
       "      <td>0.704694</td>\n",
       "      <td>0.699559</td>\n",
       "      <td>0.704694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.718600</td>\n",
       "      <td>0.698141</td>\n",
       "      <td>0.696228</td>\n",
       "      <td>0.704694</td>\n",
       "      <td>0.700232</td>\n",
       "      <td>0.704694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_RBF</th>\n",
       "      <td>0.690624</td>\n",
       "      <td>0.659172</td>\n",
       "      <td>0.652617</td>\n",
       "      <td>0.675107</td>\n",
       "      <td>0.660509</td>\n",
       "      <td>0.675107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.623158</td>\n",
       "      <td>0.536409</td>\n",
       "      <td>0.481018</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.505011</td>\n",
       "      <td>0.576671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_linear</th>\n",
       "      <td>0.277489</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.356870</td>\n",
       "      <td>0.554979</td>\n",
       "      <td>0.396217</td>\n",
       "      <td>0.554979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.471402</td>\n",
       "      <td>0.501161</td>\n",
       "      <td>0.430343</td>\n",
       "      <td>0.543812</td>\n",
       "      <td>0.458742</td>\n",
       "      <td>0.543812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision_macro  recall_macro  f1_macro  f1_micro  \\\n",
       "AdaBoostClassifier                0.773153      0.768804  0.768519  0.772048   \n",
       "RandomForestClassifier            0.730173      0.706387  0.703710  0.717994   \n",
       "DecisionTreeClassifier            0.704656      0.697908  0.696279  0.705192   \n",
       "GaussianProcessClassifier         0.716966      0.697377  0.695280  0.704694   \n",
       "MLPClassifier                     0.718600      0.698141  0.696228  0.704694   \n",
       "SVM_RBF                           0.690624      0.659172  0.652617  0.675107   \n",
       "GaussianNB                        0.623158      0.536409  0.481018  0.576671   \n",
       "SVM_linear                        0.277489      0.500000  0.356870  0.554979   \n",
       "KNeighborsClassifier              0.471402      0.501161  0.430343  0.543812   \n",
       "\n",
       "                           f1_weighted  accuracy  \n",
       "AdaBoostClassifier            0.771116  0.772048  \n",
       "RandomForestClassifier        0.709452  0.717994  \n",
       "DecisionTreeClassifier        0.701543  0.705192  \n",
       "GaussianProcessClassifier     0.699559  0.704694  \n",
       "MLPClassifier                 0.700232  0.704694  \n",
       "SVM_RBF                       0.660509  0.675107  \n",
       "GaussianNB                    0.505011  0.576671  \n",
       "SVM_linear                    0.396217  0.554979  \n",
       "KNeighborsClassifier          0.458742  0.543812  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_tf_idf_2_5_cosine_results_long_p[0].sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b96d1d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing classifiers: ['SVC']\n",
      "running: SVC\n",
      "0.6967283072546231\n",
      "testing classifiers: ['DecisionTreeClassifier']\n",
      "running: DecisionTreeClassifier\n",
      "0.7371977240398293\n",
      "testing classifiers: ['GaussianProcessClassifier']\n",
      "running: GaussianProcessClassifier\n",
      "0.7046941678520626\n",
      "testing classifiers: ['RandomForestClassifier']\n",
      "running: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.68847795 0.69146515 0.69679943 0.69672831 0.70483642 0.71009957\n",
      " 0.71820768 0.71002845 0.68847795 0.69146515 0.69679943 0.69672831\n",
      " 0.70483642 0.71009957 0.71820768 0.71002845 0.57901849 0.57908962\n",
      " 0.56024182 0.5628734  0.5628734  0.55753912 0.56031294 0.56301565\n",
      " 0.68584637 0.68577525 0.70206259 0.69395448 0.69921764 0.70199147\n",
      " 0.70725462 0.70177809 0.68584637 0.68577525 0.70206259 0.69395448\n",
      " 0.69921764 0.70199147 0.70725462 0.70177809 0.59487909 0.59231863\n",
      " 0.5841394  0.57091038 0.5601707  0.5628734  0.56024182 0.56031294\n",
      " 0.6913229  0.69943101 0.7101707  0.71002845 0.72610242 0.7098862\n",
      " 0.71266003 0.71273115 0.6913229  0.69943101 0.7101707  0.71002845\n",
      " 0.72610242 0.7098862  0.71266003 0.71273115 0.5628734  0.57887624\n",
      " 0.57617354 0.58399716 0.578734   0.56536273 0.57069701 0.55746799\n",
      " 0.69118065 0.68321479 0.69665718 0.71280228 0.70995733 0.70725462\n",
      " 0.72062589 0.71536273 0.69118065 0.68321479 0.69665718 0.71280228\n",
      " 0.70995733 0.70725462 0.72062589 0.71536273 0.57624467 0.58428165\n",
      " 0.58940256 0.59466572 0.60540541 0.59736842 0.59217639 0.58968706\n",
      " 0.68876245 0.68876245 0.6940256  0.71009957 0.69665718 0.71813656\n",
      " 0.71536273 0.72069701 0.68876245 0.68876245 0.6940256  0.71009957\n",
      " 0.69665718 0.71813656 0.71536273 0.72069701 0.60291607 0.60561878\n",
      " 0.59480797 0.5972973  0.59473684 0.60547653 0.60810811 0.61621622\n",
      " 0.68328592 0.69416785 0.70206259 0.69665718 0.70746799 0.70746799\n",
      " 0.71820768 0.72076814 0.68328592 0.69416785 0.70206259 0.69665718\n",
      " 0.70746799 0.70746799 0.71820768 0.72076814 0.59765292 0.61109531\n",
      " 0.61372688 0.61351351 0.61891892 0.62418208 0.61614509 0.61621622\n",
      " 0.69644381 0.69409673 0.70483642 0.71550498 0.71009957 0.72354196\n",
      " 0.71813656 0.72617354 0.69644381 0.69409673 0.70483642 0.71550498\n",
      " 0.71009957 0.72354196 0.71813656 0.72617354 0.60085349 0.60540541\n",
      " 0.61102418 0.61870555 0.62140825 0.61635846 0.62951636 0.62418208\n",
      " 0.68328592 0.69672831 0.71002845 0.70739687 0.71806543 0.72610242\n",
      " 0.73421053 0.7341394  0.68328592 0.69672831 0.71002845 0.70739687\n",
      " 0.71806543 0.72610242 0.73421053 0.7341394  0.62403983 0.62119488\n",
      " 0.62119488 0.62396871 0.62119488 0.63463727 0.6185633  0.63229018\n",
      " 0.69644381 0.71009957 0.71002845 0.70199147 0.70725462 0.69928876\n",
      " 0.71536273 0.70739687 0.69644381 0.71009957 0.71002845 0.70199147\n",
      " 0.70725462 0.69928876 0.71536273 0.70739687 0.59736842 0.61614509\n",
      " 0.61614509 0.63221906 0.63477952 0.63755334 0.63485064 0.64032717\n",
      " 0.68072546 0.69416785 0.68058321 0.69644381 0.69637269 0.71002845\n",
      " 0.70462304 0.71806543 0.68072546 0.69416785 0.68058321 0.69644381\n",
      " 0.69637269 0.71002845 0.70462304 0.71806543 0.56834993 0.57894737\n",
      " 0.56294452 0.5655761  0.5655761  0.56031294 0.56031294 0.56031294\n",
      " 0.69139403 0.69381223 0.7098862  0.7098862  0.70177809 0.69644381\n",
      " 0.71009957 0.71806543 0.69139403 0.69381223 0.7098862  0.7098862\n",
      " 0.70177809 0.69644381 0.71009957 0.71806543 0.57617354 0.57901849\n",
      " 0.57091038 0.57091038 0.57631579 0.56031294 0.56301565 0.56578947\n",
      " 0.6913229  0.71038407 0.69935989 0.70469417 0.70462304 0.69651494\n",
      " 0.71009957 0.71536273 0.6913229  0.71038407 0.69935989 0.70469417\n",
      " 0.70462304 0.69651494 0.71009957 0.71536273 0.58435277 0.58165007\n",
      " 0.58157895 0.58150782 0.58691323 0.57091038 0.56813656 0.57091038\n",
      " 0.68584637 0.70739687 0.69103841 0.70995733 0.70199147 0.70455192\n",
      " 0.71543385 0.71536273 0.68584637 0.70739687 0.69103841 0.70995733\n",
      " 0.70199147 0.70455192 0.71543385 0.71536273 0.61358464 0.58933144\n",
      " 0.58954481 0.60284495 0.59224751 0.57880512 0.58165007 0.57894737\n",
      " 0.71543385 0.71792319 0.71806543 0.71813656 0.71543385 0.70732575\n",
      " 0.71273115 0.71266003 0.71543385 0.71792319 0.71806543 0.71813656\n",
      " 0.71543385 0.70732575 0.71273115 0.71266003 0.56813656 0.58406828\n",
      " 0.58136558 0.58940256 0.58684211 0.58954481 0.59210526 0.58677098\n",
      " 0.69943101 0.69118065 0.71522048 0.71799431 0.71266003 0.71792319\n",
      " 0.72069701 0.71536273 0.69943101 0.69118065 0.71522048 0.71799431\n",
      " 0.71266003 0.71792319 0.72069701 0.71536273 0.59779516 0.59743954\n",
      " 0.61095306 0.60817923 0.6002845  0.60035562 0.60284495 0.6029872\n",
      " 0.70476529 0.71543385 0.7044808  0.7101707  0.71543385 0.70199147\n",
      " 0.70476529 0.70469417 0.70476529 0.71543385 0.7044808  0.7101707\n",
      " 0.71543385 0.70199147 0.70476529 0.70469417 0.59246088 0.59736842\n",
      " 0.59473684 0.59743954 0.59758179 0.60035562 0.59480797 0.60825036\n",
      " 0.70227596 0.69395448 0.69651494 0.69928876 0.71266003 0.7125889\n",
      " 0.7098862  0.7098862  0.70227596 0.69395448 0.69651494 0.69928876\n",
      " 0.71266003 0.7125889  0.7098862  0.7098862  0.60576102 0.6\n",
      " 0.6188478  0.64295875 0.62951636 0.62681366 0.6215505  0.62681366\n",
      " 0.71834993 0.71536273 0.70462304 0.71543385 0.72624467 0.72339972\n",
      " 0.72069701 0.70995733 0.71834993 0.71536273 0.70462304 0.71543385\n",
      " 0.72624467 0.72339972 0.72069701 0.70995733 0.60312945 0.60554765\n",
      " 0.62688478 0.63243243 0.62169275 0.62446657 0.62418208 0.63513514\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sasha.kruglyak/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the train scores are non-finite: [0.93506308 0.94935412 0.9553145  0.95799396 0.95889215 0.95770256\n",
      " 0.95889126 0.95978856 0.93506308 0.94935412 0.9553145  0.95799396\n",
      " 0.95889215 0.95770256 0.95889126 0.95978856 0.7199849  0.72238095\n",
      " 0.72386461 0.71225569 0.70122335 0.69912669 0.68512971 0.67232321\n",
      " 0.96842484 0.98063966 0.98302061 0.98480899 0.98540423 0.98778785\n",
      " 0.98927683 0.99016969 0.96842484 0.98063966 0.98302061 0.98480899\n",
      " 0.98540423 0.98778785 0.98927683 0.99016969 0.80368959 0.82246535\n",
      " 0.83675551 0.83764303 0.83109186 0.83287225 0.83496446 0.82960732\n",
      " 0.98719083 0.99463575 0.99672353 0.99702026 0.99731876 0.99821162\n",
      " 0.99821162 0.997914   0.98719083 0.99463575 0.99672353 0.99702026\n",
      " 0.99731876 0.99821162 0.99821162 0.997914   0.86773454 0.89842839\n",
      " 0.91837864 0.92523276 0.92196606 0.92553305 0.92702026 0.92851724\n",
      " 0.9943408  0.99761727 0.99851102 0.99880864 0.99880864 0.99970238\n",
      " 0.99940387 0.99970149 0.9943408  0.99761727 0.99851102 0.99880864\n",
      " 0.99880864 0.99970238 0.99940387 0.99970149 0.91033582 0.94549485\n",
      " 0.95800284 0.96038468 0.96515014 0.96544865 0.97229566 0.97617093\n",
      " 0.99850924 0.99940476 1.         1.         1.         1.\n",
      " 1.         1.         0.99850924 0.99940476 1.         1.\n",
      " 1.         1.         1.         1.         0.94250355 0.97319385\n",
      " 0.98540601 0.98778785 0.99046908 0.99106432 0.99225569 0.99523454\n",
      " 0.99940387 0.99970238 1.         1.         1.         1.\n",
      " 1.         1.         0.99940387 0.99970238 1.         1.\n",
      " 1.         1.         1.         1.         0.96841773 0.98719172\n",
      " 0.99404495 0.99821162 0.99851013 0.99851102 0.99940387 0.99910714\n",
      " 0.99940387 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99940387 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.978551   0.99493692\n",
      " 0.99821429 0.99880952 0.99910625 0.99970238 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.99106343 0.99910714\n",
      " 1.         1.         0.99970238 1.         1.         1.\n",
      " 0.99880775 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99880775 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.99046464 0.99940299\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.93297441 0.94757196 0.94846748 0.95323472 0.95502043 0.9547237\n",
      " 0.95293888 0.95532072 0.93297441 0.94757196 0.94846748 0.95323472\n",
      " 0.95502043 0.9547237  0.95293888 0.95532072 0.69764037 0.70361141\n",
      " 0.70033138 0.68007196 0.67679282 0.66873845 0.6577221  0.64431237\n",
      " 0.959793   0.97498134 0.97616915 0.97795665 0.9797468  0.98272566\n",
      " 0.98272566 0.98182925 0.959793   0.97498134 0.97616915 0.97795665\n",
      " 0.9797468  0.98272566 0.98272566 0.98182925 0.78343728 0.79208689\n",
      " 0.80280206 0.80488539 0.80249556 0.80487118 0.80219972 0.79475924\n",
      " 0.98182658 0.9910661  0.99314677 0.99344527 0.9946393  0.99553127\n",
      " 0.99672353 0.99702114 0.98182658 0.9910661  0.99314677 0.99344527\n",
      " 0.9946393  0.99553127 0.99672353 0.99702114 0.8439108  0.87668355\n",
      " 0.89545131 0.90110874 0.89574805 0.89365672 0.89931681 0.89664268\n",
      " 0.99225124 0.99702203 0.99850924 0.99821162 0.99821162 0.99850924\n",
      " 0.99880775 0.99940476 0.99225124 0.99702203 0.99850924 0.99821162\n",
      " 0.99821162 0.99850924 0.99880775 0.99940476 0.89693763 0.93418088\n",
      " 0.94430704 0.94847459 0.95234542 0.95443053 0.95621713 0.95860075\n",
      " 0.99553127 0.99940476 0.99940476 0.99970238 0.99970238 0.99970238\n",
      " 1.         1.         0.99553127 0.99940476 0.99940476 0.99970238\n",
      " 0.99970238 0.99970238 1.         1.         0.92999733 0.96276652\n",
      " 0.97230366 0.97766436 0.9758742  0.98033937 0.98034115 0.9818328\n",
      " 0.99761727 0.99970238 0.99940476 0.99970238 0.99970238 0.99970238\n",
      " 1.         1.         0.99761727 0.99970238 0.99940476 0.99970238\n",
      " 0.99970238 0.99970238 1.         1.         0.95054282 0.98153163\n",
      " 0.98987118 0.99106432 0.99047086 0.99166045 0.99642235 0.99493603\n",
      " 0.99821251 0.99940476 0.99970238 1.         0.99970238 1.\n",
      " 1.         1.         0.99821251 0.99940476 0.99970238 1.\n",
      " 0.99970238 1.         1.         1.         0.97169865 0.99047086\n",
      " 0.99553394 0.99612829 0.99642679 0.99761638 0.99910625 0.99970238\n",
      " 0.99880686 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99880686 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98003376 0.99553305\n",
      " 0.99732054 0.99880864 0.99940476 0.99880864 0.99970149 1.\n",
      " 0.99970149 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99970149 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98420842 0.99731787\n",
      " 0.99910625 0.99940387 0.99970238 1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7342105263157894\n",
      "testing classifiers: ['GaussianNB']\n",
      "running: GaussianNB\n",
      "0.5819345661450925\n",
      "testing classifiers: ['KNeighborsClassifier']\n",
      "running: KNeighborsClassifier\n",
      "0.5650782361308677\n",
      "testing classifiers: ['AdaBoostClassifier']\n",
      "running: AdaBoostClassifier\n",
      "0.8527738264580369\n"
     ]
    }
   ],
   "source": [
    "burchard_zwickau_greed_rearch_resp = []\n",
    "for cls in ['SVC', 'DecisionTreeClassifier', 'GaussianProcessClassifier', 'RandomForestClassifier', 'GaussianNB', 'KNeighborsClassifier', 'AdaBoostClassifier']:\n",
    "    grid_search_cv_result = thesisModelFeatures.run_grid_search_cv(burchard_zwickau_features_tfidf_2_5_gram_cosine_similarity_long_p_df, [cls])\n",
    "    burchard_zwickau_greed_rearch_resp.append([cls, grid_search_cv_result[1][0].best_score_])\n",
    "    print(grid_search_cv_result[1][0].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161ce910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SVC', 0.6967283072546231],\n",
       " ['DecisionTreeClassifier', 0.7371977240398293],\n",
       " ['GaussianProcessClassifier', 0.7046941678520626],\n",
       " ['RandomForestClassifier', 0.7342105263157894],\n",
       " ['GaussianNB', 0.5819345661450925],\n",
       " ['KNeighborsClassifier', 0.5650782361308677],\n",
       " ['AdaBoostClassifier', 0.8527738264580369]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burchard_zwickau_greed_rearch_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579289d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
